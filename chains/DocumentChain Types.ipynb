{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5490ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import tiktoken\n",
    "import unstructured\n",
    "from langchain import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OPENAI_API_KEY = '...'\n",
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d300f1",
   "metadata": {},
   "source": [
    "### Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Load the PDF\n",
    "job_loader = PyPDFLoader(\"../data/example.pdf\")\n",
    "pages = job_loader.load_and_split()\n",
    "\n",
    "# Concatenate the text from all pages\n",
    "document_text = \"\".join([page.page_content for page in pages])\n",
    "\n",
    "# Create a list of Document object\n",
    "job_doc = [Document(page_content=document_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document(s)\n",
      "You have roughly 10285 words in your docs\n",
      "\n",
      "Preview: \n",
      "WORKING PAPER\n",
      "GPTs are GPTs: An Early Look at the Labor Market Impact Potential\n",
      "of Large Language Models\n",
      "Tyna Eloundou1, Sam Manning1,2, Pamela Mishkin\u00001, and Daniel Rock3\n",
      "1OpenAI\n",
      "2OpenResearch\n",
      "3University of Pennsylvania\n",
      "August 22, 2023\n",
      "Abstract\n",
      "We investigate the potential implications of large language models (LLMs), such as Generative Pre-\n",
      "trained Transformers (GPTs), on the U.S\n"
     ]
    }
   ],
   "source": [
    "def doc_summary(docs):\n",
    "    print (f'You have {len(docs)} document(s)')\n",
    "    \n",
    "    num_words = sum([len(doc.page_content.split(' ')) for doc in docs])\n",
    "    \n",
    "    print (f'You have roughly {num_words} words in your docs')\n",
    "doc_summary(job_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6515044",
   "metadata": {},
   "source": [
    "### Summarize: Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "020b276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"stuff\", verbose=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3e3add98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"WORKING PAPER\n",
      "GPTs are GPTs: An Early Look at the Labor Market Impact Potential\n",
      "of Large Language Models\n",
      "Tyna Eloundou1, Sam Manning1,2, Pamela Mishkin\u00001, and Daniel Rock3\n",
      "1OpenAI\n",
      "2OpenResearch\n",
      "3University of Pennsylvania\n",
      "August 22, 2023\n",
      "Abstract\n",
      "We investigate the potential implications of large language models (LLMs), such as Generative Pre-\n",
      "trained Transformers (GPTs), on the U.S. labor market, focusing on the increased capabilities arising from\n",
      "LLM-powered software compared to LLMs on their own. Using a new rubric, we assess occupations based\n",
      "on their alignment with LLM capabilities, integrating both human expertise and GPT-4 classiﬁcations.\n",
      "Our ﬁndings reveal that around 80% of the U.S. workforce could have at least 10% of their work tasks\n",
      "aﬀected by the introduction of LLMs, while approximately 19% of workers may see at least 50% of their\n",
      "tasks impacted. We do not make predictions about the development or adoption timeline of such LLMs.\n",
      "The projected eﬀects span all wage levels, with higher-income jobs potentially facing greater exposure to\n",
      "LLM capabilities and LLM-powered software. Signiﬁcantly, these impacts are not restricted to industries\n",
      "with higher recent productivity growth. Our analysis suggests that, with access to an LLM, about 15%\n",
      "of all worker tasks in the US could be completed signiﬁcantly faster at the same level of quality. When\n",
      "incorporating software and tooling built on top of LLMs, this share increases to between 47 and 56%\n",
      "of all tasks. This ﬁnding implies that LLM-powered software will have a substantial eﬀect on scaling\n",
      "the economic impacts of the underlying models. We conclude that LLMs such as GPTs exhibit traits of\n",
      "general-purpose technologies, indicating that they could have considerable economic, social, and policy\n",
      "implications.\n",
      "1 Introduction\n",
      "As shown in Figure 1, recent years, months, and weeks have seen remarkable progress in the ﬁeld of generative\n",
      "AI and large language models (LLMs). While the public often associates LLMs with various iterations of the\n",
      "Generative Pre-trained Transformer (GPT), LLMs can be trained using a range of architectures, and are not\n",
      "limited to transformer-based models (Devlin et al., 2019). LLMs can process and produce various forms of\n",
      "sequential data, including assembly language, protein sequences and chess games, extending beyond natural\n",
      "language applications alone. In this paper, we use LLMs and GPTs somewhat interchangeably, and specify in\n",
      "our rubric that these should be considered similar to the GPT-family of models available via ChatGPT or\n",
      "the OpenAI Playground (which at the time of labeling included models in the GPT-3.5 family but not in the\n",
      "GPT-4 family). We examine LLMs with text- and code-generating abilities, use the term \"generative AI\" to\n",
      "additionally include modalities such as images or audio, and use \"LLM-powered software\" to cover tools built\n",
      "on top of LLMs or that combine LLMs with other generative AI models.\n",
      "\u0000Corresponding author (pamela@openai.com). Authors contributed equally and are listed alphabetically.arXiv:2303.10130v5  [econ.GN]  21 Aug 2023WORKING PAPER\n",
      "Figure 1: Taken directly from GPT-4 Technical Report (OpenAI, 2023b). To get a sense of how quickly\n",
      "model capabilities are progressing – consider the jump in exam performance between GPT-3.5 and GPT-4\n",
      "(OpenAI, 2023b).\n",
      "Our study is motivated less by the progress of these models alone though, and more by the breadth,\n",
      "scale, and capabilities we’ve seen in the complementary technologies developed around them. The role of\n",
      "complementary technologies remains to be seen, but maximizing the impact of LLMs appears contingent\n",
      "on integrating them with larger systems (Bresnahan, 2019; Agrawal et al., 2021). While the focus of our\n",
      "discussion is primarily on the generative capabilities of LLMs, it is important to note that these models can\n",
      "also be utilized for various tasks beyond text generation. For example, embeddings from LLMs can be used\n",
      "for custom search applications, and LLMs can perform tasks such as summarization and classiﬁcation where\n",
      "the context may be largely contained in the prompt.\n",
      "To complement predictions of technology’s impacts on work and provide a framework for understanding\n",
      "the evolving landscape of language models and their associated technologies, we propose a new rubric\n",
      "for assessing LLM capabilities and their potential eﬀects on jobs. This rubric (A.1) measures the overall\n",
      "exposure of tasks to LLMs, following the spirit of prior work on quantifying exposure to machine learning\n",
      "(Brynjolfsson et al., 2018; Felten et al., 2018; Webb, 2020). We deﬁne exposure as a proxy for potential\n",
      "economic impact without distinguishing between labor-augmenting or labor-displacing eﬀects. We employ\n",
      "human annotators and GPT-4 itself as a classiﬁer to apply this rubric to occupational data in the U.S. economy,\n",
      "primarily sourced from the O*NET database. 12\n",
      "To construct our primary exposure dataset, we collected both human annotations and GPT-4 classiﬁcations,\n",
      "using a prompt tuned for agreement with a sample of labels from the authors. We observe similar agreement\n",
      "1This is distinct from recent social science research that makes use of LLMs to simulate human behavior (Horton, 2023; Sorensen\n",
      "et al., 2022)\n",
      "2While our exposure rubric does not necessarily tie the concept of language models to any particular model, we were strongly\n",
      "motivated by our observed capabilities of GPT-4 and the suite of capabilities we saw in development with OpenAI’s launch partners\n",
      "(OpenAI, 2023b).WORKING PAPER\n",
      "levels in GPT-4 responses and between human and machine evaluations, when aggregated to the task level.\n",
      "This exposure measure reﬂects an estimate of the technical capacity to make human labor more eﬃcient;\n",
      "however, social, economic, regulatory, and other determinants imply that technical feasibility does not\n",
      "guarantee labor productivity or automation outcomes. Our analysis indicates that approximately 19% of jobs\n",
      "have at least 50% of their tasks exposed when considering both current model capabilities and anticipated\n",
      "tools built upon them. Human assessments suggest that only 3% of U.S. workers have over half of their tasks\n",
      "exposed to LLMs when considering existing language and code capabilities without additional software or\n",
      "modalities. Accounting for other generative models and complementary technologies, our human estimates\n",
      "indicate that up to 49% of workers could have half or more of their tasks exposed to LLMs.\n",
      "Our ﬁndings consistently show across both human and GPT-4 annotations that most occupations exhibit\n",
      "some degree of exposure to LLMs, with varying exposure levels across diﬀerent types of work. Occupations\n",
      "with higher wages generally present with higher exposure, a result contrary to similar evaluations of overall\n",
      "exposure to machine learning (Brynjolfsson et al., 2023). When regressing exposure measures on skillsets\n",
      "using O*NET’s skill rubric, we discover that roles heavily reliant on science and critical thinking skills show\n",
      "a negative correlation with exposure, while programming and writing skills are positively associated with\n",
      "LLM exposure. Following Autor et al. (2022a), we examine barriers to entry by \"Job Zones\" and ﬁnd that\n",
      "occupational exposure to LLMs weakly increases with the diﬃculty of job preparation. In other words,\n",
      "workers facing higher (lower) barriers to entry in their jobs tend to experience more (less) exposure to LLMs.\n",
      "We further compare our measurements to previous eﬀorts documenting the distribution of automation\n",
      "exposure in the economy and ﬁnd broadly consistent results. Most other technology exposure measures we\n",
      "examine are statistically signiﬁcantly correlated with our preferred exposure measure, while measures of\n",
      "manual routineness and robotics exposure show negative correlations. The variance explained by these earlier\n",
      "eﬀorts (Acemoglu and Autor, 2011a; Frey and Osborne, 2017; Brynjolfsson et al., 2018; Felten et al., 2018;\n",
      "Webb, 2020; Brynjolfsson et al., 2023), along with wage controls, ranges from 60 to 72%, indicating that 28\n",
      "to 40% of the variation in our AI exposure measure remains unaccounted for by previous technology exposure\n",
      "measurements.\n",
      "We analyze exposure by industry and discover that information processing industries (4-digit NAICS)\n",
      "exhibit high exposure, while manufacturing, agriculture, and mining demonstrate lower exposure. The\n",
      "connection between productivity growth in the past decade and overall LLM exposure appears weak, suggesting\n",
      "a potential optimistic case that future productivity gains from LLMs may not exacerbate possible cost disease\n",
      "eﬀects (Baumol, 2012; Aghion et al., 2018). 3\n",
      "Our analysis indicates that the impacts of LLMs like GPT-4, are likely to be pervasive. While LLMs\n",
      "have consistently improved in capabilities over time, their growing economic eﬀect is expected to persist and\n",
      "increase even if we halt the development of new capabilities today. We also ﬁnd that the potential impact of\n",
      "LLMs expands signiﬁcantly when we take into account the development of complementary technologies.\n",
      "Collectively, these characteristics imply that Generative Pre-trained Transformers (GPTs) are general-purpose\n",
      "technologies (GPTs). 4(Bresnahan and Trajtenberg, 1995; Lipsey et al., 2005).\n",
      "(Goldfarb et al., 2023) argue that machine learning as a broad category is likely a general-purpose\n",
      "technology. Our evidence supports a wider impact, as even subsets of machine learning software meet thetechnology. Our evidence supports a wider impact, as even subsets of machine learning software meet the\n",
      "criteria for general-purpose technology status independently. This paper’s primary contributions are to provide\n",
      "a set of measurements of LLM impact potential and to demonstrate the use case of applying LLMs to develop\n",
      "such measurements eﬃciently and at scale. Additionally, we showcase the general-purpose potential of LLMs.\n",
      "If \"GPTs are GPTs,\" the eventual trajectory of LLM development and application may be challenging for\n",
      "3Baumol’s cost disease is a theory that explains why the cost of labor-intensive services, such as healthcare and education,\n",
      "increases over time. This happens because wages for skilled workers in other industries increase, but there is no corresponding\n",
      "increase in productivity or eﬃciency in these service industries. Therefore, the cost of labor in these industries becomes relatively\n",
      "more expensive compared to other goods and services in the economy.\n",
      "4For the remainder of the paper we spell out general-purpose technologies when it is used outside of stating \"GPTs are GPTs.\"WORKING PAPER\n",
      "policymakers to predict and regulate. As with other general-purpose technologies, much of these algorithms’\n",
      "potential will emerge across a broad range of economically valuable use cases, including the creation of new\n",
      "types of work (Acemoglu and Restrepo, 2018; Autor et al., 2022a). Our research serves to measure what is\n",
      "technically feasible now, but necessarily will miss the evolving impact potential of the LLMs over time.\n",
      "The paper is structured as follows: Section 2 reviews relevant prior work, Section 3 discusses methods\n",
      "and data collection, Section 4 presents summary statistics and results, Section 5 relates our measurements to\n",
      "earlier eﬀorts, Section 6 discusses the results, and Section 7 oﬀers concluding remarks.\n",
      "2 Literature Review\n",
      "2.1 The Advancement of Large Language Models\n",
      "In recent years, generative AI models have gained signiﬁcant attention from both the artiﬁcial intelligence\n",
      "(AI) research community and the general public, due to their ability to tackle a wide array of complex\n",
      "language-based tasks. The progress in these models’ abilities has been fueled by multiple factors, including\n",
      "increased model parameter count, greater training data volume, and enhanced training conﬁgurations (Brown\n",
      "et al., 2020; Radford et al., 2019; Hernandez et al., 2021; Kaplan et al., 2020). Broad, state-of-the-art LLMs,\n",
      "such as LaMDA (Thoppilan et al., 2022) and GPT-4 (OpenAI, 2023b), excel in diverse applications like\n",
      "translation, classiﬁcation, creative writing, and code generation—capabilities that previously demanded\n",
      "specialized, task-speciﬁc models developed by expert engineers using domain-speciﬁc data.\n",
      "Concurrently, researchers have improved the steerability, reliability, and utility of these models using\n",
      "methods like ﬁne-tuning and reinforcement learning with human feedback (Ouyang et al., 2022; Bai et al.,\n",
      "2022). These advancements enhance the models’ ability to discern user intent, rendering them more\n",
      "user-friendly and practical. Moreover, recent studies reveal the potential of LLMs to program and control\n",
      "other digital tools, such as APIs, search engines, and even other generative AI systems (Schick et al., 2023;\n",
      "Mialon et al., 2023; Chase, 2022). This enables seamless integration of individual components for better\n",
      "utility, performance, and generalization. At their limit, these trends suggest a world where LLMs may be\n",
      "capable of executing any task typically performed at a computer.\n",
      "Generative AI models have mostly been deployed as modular specialists, performing speciﬁc tasks such as\n",
      "generating images from captions or transcribing text from speech. However, we argue that it is essential to view\n",
      "LLMs as versatile building blocks for creating additional tools. Developing these tools and integrating them\n",
      "into systems will require time and possibly signiﬁcant reconﬁguration of existing processes across various\n",
      "industries. Nevertheless, we are already witnessing emerging adoption trends. Despite their limitations,\n",
      "LLMs are increasingly being integrated into specialized applications in ﬁelds like writing assistance, coding,\n",
      "and legal research. These specialized applications then allow businesses and individuals to adopt LLMs into\n",
      "their workﬂows.\n",
      "We emphasize the signiﬁcance of these complementary technologies, partly because out-of-the-box\n",
      "general-purpose LLMs may continue to be unreliable for various tasks due to issues such as factual inaccuracies,\n",
      "inherent biases, privacy concerns, and disinformation risks (Abid et al., 2021; Schramowski et al., 2022;\n",
      "Goldstein et al., 2023; OpenAI, 2023a). However, specialized workﬂows—including tooling, software, or\n",
      "human-in-the-loop systems—can help address these shortcomings by incorporating domain-speciﬁc expertise.\n",
      "For example, Casetext oﬀers LLM-based legal research tools that provide lawyers with quicker and more\n",
      "accurate legal research results, utilizing embeddings and summarization to counter the risk that GPT-4 couldaccurate legal research results, utilizing embeddings and summarization to counter the risk that GPT-4 could\n",
      "provide inaccurate details about a legal case or set of documents. GitHub Copilot is a coding assistant that\n",
      "employs LLMs to generate code snippets and auto-complete code, which users can then accept or reject based\n",
      "on their expertise. In other words, while it’s true that on its own GPT-4 does not \"know what time it is,\" it’s\n",
      "easy enough to give it a watch.WORKING PAPER\n",
      "Furthermore, a positive feedback loop may emerge as LLMs surpass a speciﬁc performance threshold,\n",
      "allowing them to assist in building the very tooling that enhances their usefulness and usability across various\n",
      "contexts. This could lower the cost and engineering expertise required to create such tools, potentially\n",
      "accelerating LLM adoption and integration even further (Chen et al., 2021; Peng et al., 2023). LLMs can also\n",
      "become valuable assets in machine learning model development—serving as coding assistants for researchers,\n",
      "data labeling services, or synthetic data generators. There is potential for such models to contribute to\n",
      "economic decision-making at the task level, for instance, by reﬁning methods for task and sub-task allocation\n",
      "between humans and machines (Singla et al., 2015; Shahaf and Horvitz, 2010). As LLMs advance over time\n",
      "and better align with user preferences, we can anticipate continuous improvement in performance. However, it\n",
      "is essential to recognize that these trends also bring a variety of serious risks. (Khlaaf et al., 2022; Weidinger\n",
      "et al., 2022; Solaiman et al., 2019)\n",
      "2.2 The Economic Impacts of Automation Technologies\n",
      "A large and growing body of literature addresses the labor market impacts of AI and automation technologies.\n",
      "The concept of skill-biased technological change and the task model of automation—often considered\n",
      "the standard framework for understanding technology’s inﬂuence on labor—originated from research\n",
      "demonstrating that technological progress raises the demand for skilled workers over unskilled workers (Katz\n",
      "and Murphy, 1992). Numerous studies have built upon this concept, exploring the eﬀects of technological\n",
      "change and automation on workers within a task-based framework (Autor et al., 2003; Acemoglu and Autor,\n",
      "2011b; Acemoglu and Restrepo, 2018). This strand of research has shown that workers involved in routine and\n",
      "repetitive tasks are at a higher risk of technology-driven displacement, a phenomenon known as routine-biased\n",
      "technological change. More recent studies have distinguished between technology’s task-displacement and\n",
      "task-reinstatement eﬀects (where new technology increases the need for a wider array of labor-intensive tasks)\n",
      "(Acemoglu and Restrepo, 2018, 2019). Several studies have shown that automation technologies have resulted\n",
      "in wage inequality in the US, driven by relative wage declines for workers specializing in routine tasks (Autor\n",
      "et al., 2006; Van Reenen, 2011; Acemoglu and Restrepo, 2022b).\n",
      "Prior research has employed various approaches to estimate the overlap between AI capabilities and\n",
      "the tasks and activities workers undertake in diﬀerent occupations. These methods include mapping patent\n",
      "descriptions to worker task descriptions (Webb, 2020; Meindl et al., 2021), linking AI capabilities to\n",
      "occupational abilities documented in the O*NET database (Felten et al., 2018, 2023), aligning AI task\n",
      "benchmark evaluations with worker tasks via cognitive abilities (Tolan et al., 2021), labeling automation\n",
      "potential for a subset of US occupations and using machine learning classiﬁers to estimate this potential for\n",
      "all other US occupations (Frey and Osborne, 2017), modeling task-level automation and aggregating the\n",
      "results to occupation-level insights (Arntz et al., 2017), collecting expert forecasts (Grace et al., 2018), and\n",
      "most relevantly to this paper, devising a new rubric to assess worker activities for their suitability for machine\n",
      "learning (Brynjolfsson et al., 2018, 2023). Some of these approaches have found exposure to AI technologies\n",
      "at the task-level tends to be diversiﬁed within occupation. Considering each job as a bundle of tasks, it would\n",
      "be rare to ﬁnd any occupation for which AI tools could do nearly all of the work. (Autor et al., 2022a) ﬁnds as\n",
      "well that automation and augmentation exposures tend to be positively correlated. There is also a growing setwell that automation and augmentation exposures tend to be positively correlated. There is also a growing set\n",
      "of studies examining speciﬁc economic impacts and opportunities for LLMs (Bommasani et al., 2021; Felten\n",
      "et al., 2023; Korinek, 2023; Mollick and Mollick, 2022; Noy and Zhang, 2023; Peng et al., 2023). Alongside\n",
      "this work, our measurements help characterize the broader potential relevance of language models to the\n",
      "labor market.\n",
      "General-purpose technologies (e.g. printing, the steam engine) are characterized by widespread prolifera-\n",
      "tion, continuous improvement, and the generation of complementary innovations (Bresnahan and Trajtenberg,\n",
      "1995; Lipsey et al., 2005). Their far-reaching consequences, which unfold over decades, are diﬃcult to\n",
      "anticipate, particularly in relation to labor demand (Bessen, 2018; Korinek and Stiglitz, 2018; Acemoglu et al.,WORKING PAPER\n",
      "2020; Benzell et al., 2021). The realization of general purpose technologies’ full potential requires extensive\n",
      "co-invention (Bresnahan and Trajtenberg, 1995; Bresnahan et al., 1996, 2002; Lipsey et al., 2005; Dixon et al.,\n",
      "2021), a costly and time-consuming process involving the discovery of new business procedures (David, 1990;\n",
      "Bresnahan, 1999; Frey, 2019; Brynjolfsson et al., 2021; Feigenbaum and Gross, 2021). Consequently, many\n",
      "studies of machine learning technologies focus on systems-level adoption, arguing that organizational systems\n",
      "may require redesign to eﬀectively take advantage of novel machine learning advancements (Bresnahan,\n",
      "2019; Agrawal et al., 2021; Goldfarb et al., 2023). Appropriately designed systems can yield considerable\n",
      "business value and improve ﬁrm performance (Rock, 2019; Babina et al., 2021; Zolas et al., 2021), with AI\n",
      "tools facilitating the discovery process (Cockburn et al., 2018; Cheng et al., 2022). By employing task-level\n",
      "information to assess whether LLMs fulﬁll the criteria of a general purpose technology, we seek to merge the\n",
      "two perspectives for understanding the technology-labor relationship.\n",
      "We attempt to build on these diverse literature streams in several ways. Echoing (Felten et al., 2023), we\n",
      "focus our analysis on the impact of LLMs, rather than addressing machine learning or automation technologies\n",
      "more broadly. Additionally, we propose a novel method that employs LLMs, speciﬁcally GPT-4, to assess tasks\n",
      "for exposure and automation potential, thereby bolstering human scoring eﬀorts. Subsequently, we aggregate\n",
      "our ﬁndings to occupations and industries, capturing the overall potential exposure in the contemporary U.S.\n",
      "labor market.\n",
      "3 Methods and Data Collection\n",
      "3.1 Data on Activities and Tasks Performed by Occupation in the US\n",
      "We use the O*NET 27.2 database (O*NET, 2023), which contains information on 1,016 occupations, including\n",
      "their respective Detailed Work Activities (DWAs) and tasks. A DWA is a comprehensive action that is part of\n",
      "completing task, such as \"Study scripts to determine project requirements.\" A task, on the other hand, is an\n",
      "occupation-speciﬁc unit of work that may be associated with zero, one, or multiple DWAs. We oﬀer a sample\n",
      "of tasks and DWAs in Table 1. The two datasets we use consist of:\n",
      "•19,265 tasks, consisting of a \"task description\" and a corresponding occupation, and\n",
      "•2,087 DWAs, where most DWAs are connected to one or more tasks, and tasks may be associated with\n",
      "one or more DWAs, though some tasks lack any associated DWAs.\n",
      "3.2 Data on Wages, Employment, and Demographics\n",
      "We obtain employment and wage data from the 2020 and 2021 Occupational Employment series provided by\n",
      "the Bureau of Labor Statistics. This dataset encompasses occupational titles, the number of workers in each\n",
      "occupation, and occupation-level employment projections for 2031, typical education required for entry in an\n",
      "occupation and on-the-job training required to attain competency in an occupation (BLS, 2022). We use the\n",
      "BLS-recommended crosswalk to O*NET (BLS, 2023b) to link the O*NET task and DWA dataset and the\n",
      "BLS Labor Force Demographics (BLS, 2023a), which is derived from the Current Population Survey (CPS).\n",
      "Both of these data sources are collected by the U.S. government and primarily capture workers who are not\n",
      "self-employed, are documented, and are working in the so-called formal economy.\n",
      "3.3 Exposure\n",
      "We present our results based on an exposure rubric, in which we deﬁne exposure as a measure of whether\n",
      "access to an LLM or LLM-powered system would reduce the time required for a human to perform a speciﬁcWORKING PAPER\n",
      "Task ID Occupation Title DWAs Task Description\n",
      "14675 Computer Systems\n",
      "Engineers/ArchitectsMonitor computer system performance\n",
      "to ensure proper operation.Monitor system operation to detect potential\n",
      "problems.\n",
      "18310 Acute Care Nurses Operate diagnostic or therapeutic\n",
      "medical instruments or equipment.\n",
      "Prepare medical supplies or equipment\n",
      "for use.Set up, operate, or monitor invasive equipment\n",
      "and devices, such as colostomy or tracheotomy\n",
      "equipment, mechanical ventilators, catheters,\n",
      "gastrointestinal tubes, and central lines.\n",
      "4668.0 Gambling Cage\n",
      "WorkersExecute sales or other ﬁnancial\n",
      "transactions.Cash checks and process credit card advances\n",
      "for patrons.\n",
      "15709 Online Merchants Execute sales or other ﬁnancial\n",
      "transactions.Deliver e-mail conﬁrmation of completed\n",
      "transactions and shipment.\n",
      "6529 Kindergarten\n",
      "Teachers, Except\n",
      "Special Education– Involve parent volunteers and older students in\n",
      "children’s activities to facilitate involvement in\n",
      "focused, complex play.\n",
      "6568 Elementary School\n",
      "Teachers, Except\n",
      "Special Education– Involve parent volunteers and older students in\n",
      "children’s activities to facilitate involvement in\n",
      "focused, complex play.\n",
      "Table 1: Sample of occupations, tasks, and Detailed Work Activities from the O*NET database. We see\n",
      "that aggregating over activities alone is imprecise, as evidenced by the fact that we’d expect Gambling Cage\n",
      "Workers to complete the given DWA in person, using some physicality while we’d expect Online Merchants\n",
      "to complete the same activity solely with a computer.\n",
      "DWA or complete a task by at least 50 percent. Though GPT-4 has vision capabilities OpenAI (2023b) and\n",
      "\"LLM\" is often used to refer to a much wider range of modalities, vision and image capabilities were only\n",
      "included in our deﬁnition of LLM-powered software. We provide a summary of our rubric below, while the\n",
      "complete rubric can be found in A.1. When we have labels for DWAs, we ﬁrst aggregate them to the task\n",
      "level before aggregating to the occupation level.\n",
      "No exposure (E0) if:\n",
      "•using the described LLM results in no or minimal reduction in the time required to\n",
      "complete the activity or task while maintaining equivalent qualityaor\n",
      "•using the described LLM results in a decrease in the quality of the activity/task output.\n",
      "Direct exposure (E1) if:\n",
      "•using the described LLM via ChatGPT or the OpenAI playground can decrease the time\n",
      "required to complete the DWA or task by at least half (50%).\n",
      "LLM+ Exposed (E2) if:\n",
      "•access to the described LLM alone would not reduce the time required to complete the\n",
      "activity/task by at least half, but\n",
      "•additional software could be developed on top of the LLM that could reduce the time it\n",
      "takes to complete the speciﬁc activity/task with quality by at least half. Among these\n",
      "systems, we count access to image generation systems.b\n",
      "aEquivalent quality means that a third party, typically the recipient of the output, would not notice or\n",
      "care about LLM assistance.\n",
      "bIn practice, as can be seen in the full rubric in Appendix A.1, we categorize access to image capabilities\n",
      "separately (E3) to facilitate annotation, though we combine E2 and E3 for all analyses.Summary of exposure rubric\n",
      "We set the exposure threshold at a potential 50% reduction in time required to complete a speciﬁc DWAWORKING PAPER\n",
      "or task while maintaining consistent quality. We anticipate that adoption will be highest and most immediate\n",
      "for applications that realize a considerable increase in productivity. Although this threshold is somewhat\n",
      "arbitrary, it was selected for ease of interpretation by annotators. Moreover, regardless of the chosen threshold,\n",
      "we guessed that the real-world reduction in task time would likely be slightly or signiﬁcantly lower than our\n",
      "estimates, leading us to opt for a relatively high threshold. In our own validation labeling, we found that this\n",
      "corresponded closely to whether an LLM or LLM-powered software could perform the core part of a task or\n",
      "nearly the entire task.\n",
      "Comparison WWeighting Agreement Pearson’s\n",
      "GPT-4, Rubric 1; Human UE1 80.8% 0.223\n",
      "VE1 + .5*E2 65.6% 0.591\n",
      "ZE1 + E2 82.1% 0.654\n",
      "GPT-4, Rubric 2; Human UE1 81.8% 0.221\n",
      "VE1 + .5*E2 65.6% 0.538\n",
      "ZE1 + E2 79.5% 0.589\n",
      "GPT-4, Rubric 1; GPT-4, Rubric 2 UE1 91.1% 0.611\n",
      "VE1 + .5*E2 76.0% 0.705\n",
      "ZE1 + E2 82.4% 0.680\n",
      "Table 2: Model and human comparison of agreement and Pearson’s correlation scores. The agreement score\n",
      "is determined by looking at how often the two groups agree on the annotation (e.g. E0, E1 or E2). In the\n",
      "paper we use GPT-4, Rubric 1. Core tasks are given twice the weight at the occupation-level as supplemental\n",
      "tasks. All weights sum to one.\n",
      "We then collected both human and GPT-4-generated annotations using the exposure rubric, which underlie\n",
      "the bulk of the analyses in this paper.\n",
      "•Human Ratings: We obtained human annotations by applying the rubric to each O*NET Detailed\n",
      "Worker Activity (DWA) and a subset of all O*NET tasks and then aggregated those DWA and task\n",
      "scores 5at the task and occupation levels. The authors personally labeled a large sample of tasks and\n",
      "DWAs and enlisted experienced human annotators who have reviewed GPT-3, GPT-3.5 and GPT-4\n",
      "outputs as part of OpenAI’s alignment work (Ouyang et al., 2022).\n",
      "•GPT-4 Ratings: We administered a similar rubric to an early version of GPT-4 (OpenAI, 2023b) but on\n",
      "all task/occupation pairs rather than DWAs. We made slight modiﬁcations to the rubric (which was\n",
      "used as a \"prompt\" to the model in this case) to enhance agreement with a set of human labels. Full\n",
      "agreement rates are given in Table 2.\n",
      "We construct three primary measures for our dependent variable of interest: (i) U, corresponding to E1 in\n",
      "the exposure rubric above, anticipated to represent the lower bound of the proportion of exposed tasks within\n",
      "an occupation, (ii) V, which is the sum of E1 and 0.5*E2, where the 0.5 weight on E2 is intended to account\n",
      "for exposure when deploying the technology via complementary tools and applications necessitates additional\n",
      "investment, and (iii) Z, the sum of E1 and E2, an upper bound of exposure that provides an assessment of\n",
      "maximal exposure to an LLLM and LLM-powered software. We summarize agreement between annotation\n",
      "groups and measures in Table 2. For the remainder of the analysis, if not speciﬁed, the reader may assume that\n",
      "5The authors annotated DWAs that clearly required a high degree of physicality or manual dexterity, and the contracted annotators\n",
      "labeled the remaining activities, along with a subset of tasks including those without associated DWAs and those for which there was\n",
      "no clear task-level annotation after aggregating the DWA annotations.WORKING PAPER\n",
      "we refer to Vexposure – meaning all tasks directly exposed via tools like ChatGPT or the OpenAI Playground\n",
      "are considered twice as exposed as tasks requiring some complementary innovation.\n",
      "3.4 Limitations of our methodology\n",
      "3.4.1 Subjective human judgments\n",
      "A fundamental limitation of our approach lies in the subjectivity of the labeling. In our study, we employ\n",
      "annotators who are familiar with LLM capabilities. However, this group is not occupationally diverse,\n",
      "potentially leading to biased judgments regarding LLMs’ reliability and eﬀectiveness in performing tasks\n",
      "within unfamiliar occupations. We acknowledge that obtaining high-quality labels for each task in an\n",
      "occupation requires workers engaged in those occupations or, at a minimum, possessing in-depth knowledge\n",
      "of the diverse tasks within those occupations. This represents an important area for future work in validating\n",
      "these results.\n",
      "3.4.2 Measuring LLMs with GPT-4\n",
      "Recent research indicates that GPT-4 serves as an eﬀective discriminator, capable of applying intricate\n",
      "taxonomies and responding to changes in wording and emphasis (OpenAI, 2023b). The outcomes of GPT-4\n",
      "task classiﬁcation are sensitive to alterations in the rubric’s wording, the prompt’s order and composition, the\n",
      "presence or absence of speciﬁc examples in the rubric, the level of detail provided, and the deﬁnitions given\n",
      "for key terms. Iterating on the prompt, based on observed outcomes in a small validation set, can enhance the\n",
      "agreement between model outputs and the rubric’s intent. Consequently, there are slight diﬀerences between\n",
      "the rubric presented to humans and the one used for GPT-4. This decision was made deliberately to guide\n",
      "the model towards reasonable labels without excessively inﬂuencing human annotators. As a result, we use\n",
      "multiple annotation sources, but none should be considered the deﬁnitive ground truth relative to the others.\n",
      "In this analysis, we present results from human annotators as our primary results. Further improvement and\n",
      "innovation in crafting eﬀective rubrics for LLM classiﬁcation remains possible. Still, we observe a high\n",
      "degree of agreement between human ratings and GPT-4 ratings at the occupation level concerning overall\n",
      "exposure to LLM systems (see Table 2, Figure 2).\n",
      "3.4.3 Additional Weaknesses\n",
      "•Validity of task-based framework. It is unclear to what extent occupations can be entirely broken\n",
      "down into tasks, and whether this approach systematically omits certain categories of skills or tasks\n",
      "that are tacitly required for competent performance of a job. Additionally, tasks can be composed of\n",
      "sub-tasks, some of which are more automatable than others. Some tasks may function as pre-cursor to\n",
      "other tasks, such that the completion of downstream tasks is dependent on precursor tasks. If indeed,\n",
      "the task-based breakdown is not a valid representation of how most work in an occupation is performed,\n",
      "our exposure analysis would largely be invalidated.\n",
      "•Lack of expertise and task interpretation. Human annotators were mostly unaware of the speciﬁc\n",
      "occupations mapped to each DWA during the labeling process. This led to unclear logic for aggregating\n",
      "tasks and occupations, as well as some evident discrepancies in labels, demonstrated in Table 1. We\n",
      "experimented with various aggregation methods and discovered that even with a maximum-matching\n",
      "approach (taking the matching human<>model label if one existed), the agreement remained relatively\n",
      "consistent. Ultimately, we collected additional labels for task/occupation pairs where there was\n",
      "signiﬁcant disagreement.WORKING PAPER\n",
      "Figure 2: Human raters (x-axis) and GPT-4 ratings (y-axis) show a high degree of agreement about LLM\n",
      "exposure by occupation. We compute occupation-level exposure in these ﬁgures by averaging the task-level\n",
      "exposures under the Vmethod. O*NET designates some tasks as \"core\" and others \"supplemental\". Core\n",
      "tasks are given twice the weight of supplemental tasks, and all weights sum to one. Near the highest levels of\n",
      "exposure following the Vmethod of aggregating exposure scores to occupations, GPT-4 ratings tend to be\n",
      "lower than Human ratings. We present the raw scatter plot and the binscatter. Near the top end of exposure\n",
      "ratings, humans are on average more likely to rate an occupation as exposed.\n",
      "•Forward-looking and subject to change, with some early evidence. Accurately predicting future\n",
      "LLM applications remains a signiﬁcant challenge, even for experts (OpenAI, 2023b). The discovery of\n",
      "new emergent capabilities, changes in human perception biases, and shifts in technological development\n",
      "can all aﬀect the accuracy and reliability of predictions regarding the potential impact of LLMs\n",
      "on worker tasks and the development of LLM-powered software. Our projections are inherently\n",
      "forward-looking and based on current trends, evidence, and perceptions of technological possibilities.\n",
      "As a result, they may change as new advancements arise in the ﬁeld. For example, some tasks that\n",
      "seem unlikely for LLMs or LLM-powered software to impact today might change with the introduction\n",
      "of new model capabilities. Conversely, tasks that appear exposed might face unforeseen challenges\n",
      "limiting language model applications.\n",
      "•Sources of disagreement. While we did not rigorously examine sources of disagreement, we found a\n",
      "few places where humans and the model tended to get \"stuck\" in their assessments:\n",
      "–Tasks or activities where while an LLM could theoretically help or accomplish the task, adopting\n",
      "it to do so would require multiple people to change their habits or expectations (e.g. meetings,\n",
      "negotiations),\n",
      "–Tasks or activities where there is currently some regulation or norm that requires or suggests\n",
      "human oversight, judgment or empathy (e.g. making decisions, counseling), and\n",
      "–Tasks or activities where there already exists a technology that can reasonably automate the task\n",
      "(e.g. making reservations).\n",
      "4 Results\n",
      "General-purpose technologies are relatively rare and characterized by their pervasiveness, improvement over\n",
      "time, and the development of signiﬁcant co-invention and spillovers (Lipsey et al., 2005). Our assessment ofWORKING PAPER\n",
      "LLMs’ potential impact on the labor market is limited since it does not consider total factor productivity or\n",
      "capital input potential. In addition to their inﬂuence on labor, LLMs may also inﬂuence these dimensions.\n",
      "At this stage, some general-purpose technology criteria are easier to evaluate than others. Our primary\n",
      "focus at this early stage is to test the hypothesis that LLMs have a pervasive inﬂuence on the economy,\n",
      "similar to the approach taken by (Goldfarb et al., 2023), who analyzed machine learning diﬀusion through\n",
      "job postings to assess its status as a general-purpose technology. Instead of using job postings or studying\n",
      "machine learning in general, we employ the task evaluation approach with both human and GPT-4 annotations.\n",
      "This analysis may reveal whether the impacts are limited to a speciﬁc set of similar tasks or occupations or if\n",
      "they will be more widespread.\n",
      "Our ﬁndings suggest that, based on their task-level capabilities, LLMs have the potential to signiﬁcantly\n",
      "aﬀect a diverse range of occupations within the U.S. economy, demonstrating a key attribute of general-purpose\n",
      "technologies. In the following sections, we discuss results across various roles and wage structures. Additional\n",
      "results on the relative exposure of industries within the U.S. economy can be found in Appendix C.\n",
      "4.1 Summary Statistics\n",
      "Summary statistics for these measures can be found in Table 3. Both human and GPT-4 annotations indicate\n",
      "that average occupation-level Uvalues fall between 0.14 and 0.15, suggesting that, on average, approximately\n",
      "15% of tasks within an occupation are directly exposed to LLMs. 6This ﬁgure increases to over 30% for V\n",
      "and surpasses 50% for Z. Coincidentally, human and GPT-4 annotations also tag between 15% and 14% of\n",
      "total tasks in the dataset as being exposed to LLMs. Based on the Vvalues, we estimate that 80% of workers\n",
      "belong to an occupation with at least 10% of its tasks exposed to LLMs, while 19% of workers are in an\n",
      "occupation where over half of its tasks are labeled as exposed.\n",
      "We ran one set of analyses using O*NET’s \"Importance\" scores but did not ﬁnd signiﬁcant changes to our\n",
      "ﬁndings. Though we do acknowledge that not weighting relative importance of a task to a given occupation\n",
      "yields some curious results (e.g. ranking Barbers as having reasonably high exposure).\n",
      "Although the potential for tasks to be aﬀected is vast, LLMs and LLM-powered software must be\n",
      "incorporated into broader systems to fully realize this potential. As is common with general-purpose\n",
      "technologies, co-invention barriers may initially impede the rapid diﬀusion of GPTs into economic applications.\n",
      "Furthermore, predicting the need for human oversight is challenging, especially for tasks where model\n",
      "capabilities equal or surpass human levels. While the requirement for human supervision may initially slow\n",
      "down the speed at which these systems diﬀuse through the economy, users of LLMs and LLM-powered\n",
      "systems are likely to become increasingly acquainted with the technology over time, particularly in terms of\n",
      "understanding when and how to trust its outputs.\n",
      "4.2 Wages and Employment\n",
      "In Figure 3, we present exposure intensity across the economy. Each point on the plot displays occupational\n",
      "exposure, where the point’s x-axis value represents the share of an occupation’s tasks that are exposed (at\n",
      "each level U,V, and Z) and the point’s y-axis value represents the share of all US occupations with that share\n",
      "of tasks exposed. For example, human annotators determined that 2.3% of occupations are U50-exposed,\n",
      "21.6% are V50-exposed, and 47.3% are Z50-exposed, where the threshold of 50% comes from the x-axis and\n",
      "the percentage of occupations comes from the y axis. At any given point on the x-axis, the vertical distance\n",
      "between the Uand the Zrepresents the exposure potential attributable to tools and applications beyond direct\n",
      "exposure to LLMs. All tasks within an occupation in this ﬁgure are given equal weight.between the Uand the Zrepresents the exposure potential attributable to tools and applications beyond direct\n",
      "exposure to LLMs. All tasks within an occupation in this ﬁgure are given equal weight.\n",
      "6We compute occupation-level scores for Table 3 assigning double the weight to tasks designated as \"core\" by O*NET as tasks\n",
      "designated \"supplemental\". All tasks weights sum to one within an occupation.WORKING PAPER\n",
      "Occupation Level Exposure\n",
      "Human GPT-4\n",
      "mean std mean std\n",
      "UUU0.14 0.14 0.14 0.16\n",
      "VVV0.30 0.21 0.34 0.22\n",
      "ZZZ0.46 0.30 0.55 0.34\n",
      "Task Level Exposure\n",
      "Human GPT-4\n",
      "mean std mean std\n",
      "UUU0.15 0.36 0.14 0.35\n",
      "VVV0.31 0.37 0.35 0.35\n",
      "ZZZ0.47 0.50 0.56 0.50\n",
      "Table 3: Summary statistics of our human and model exposure data. Tasks designated as core tasks for an\n",
      "occupation are given twice the weight as those indicated to be supplemental in the O*NET task ﬁle.\n",
      "Figure 3: Exposure intensity across the economy, displayed in terms of percent of aﬀected occupations. A\n",
      "given data point gives the percent of occupations with exposure below the given threshold. A previous version\n",
      "of this paper had two labels reversed in the chart, ﬂipping human and model responses. In this ﬁgure, all tasks\n",
      "within an occupation are given equal weight.\n",
      "Aggregated at the occupation level, human and GPT-4 annotations exhibit qualitative similarities and\n",
      "tend to correlate, as demonstrated in Figure 4. Human annotations estimate marginally lower exposure for\n",
      "high-wage occupations compared to GPT-4 annotations. While there are numerous low-wage occupations\n",
      "with high exposure and high-wage occupations with low exposure, the overall trend in the binscatter plot\n",
      "reveals that higher wages are associated with increased exposure to LLMs. 7\n",
      "The potential exposure to LLMs seems to have little correlation with current employment levels. In\n",
      "Figure 4, both human and GPT-4 ratings of overall exposure are aggregated to the occupation-level (y-axis)\n",
      "and compared with the log of total employment (x-axis). Neither plot reveals signiﬁcant diﬀerences in LLM\n",
      "exposure across varying employment levels.\n",
      "7In aggregating tasks to the occupation-level, we assign half the weight to O*NET supplemental tasks as we do for core tasks.WORKING PAPER\n",
      "Figure 4: The binscatter plots depict the exposure to language models (LLMs) in various occupations, as\n",
      "assessed by both human evaluators and GPT-4. These plots compare the exposure to LLM and partial\n",
      "LLM-powered software ( V) at the occupation level against the log of total employment within an occupation\n",
      "and log of the median annual wage for occupations. While some discrepancies exist, both human and GPT-4\n",
      "assessments indicate that higher wage occupations tend to be more exposed to LLMs. Additionally, numerous\n",
      "lower wage occupations demonstrate high exposure based on our rubric. Core tasks receive twice the weight of\n",
      "supplemental tasks within occupations when calculating average exposure scores. Employment and wage data\n",
      "are sourced from the BLS-OES survey conducted in May 2021. In aggregating tasks to the occupation-level,\n",
      "we assign half the weight to O*NET supplemental tasks as we do for core tasks. All weights within an\n",
      "occupation sum to one.WORKING PAPER\n",
      "4.3 Skill Importance\n",
      "In this section, we explore the relationship between the importance of a skill for an occupation (as annotated\n",
      "in the O*NET dataset) and our exposure measures. First, we use the Basic Skills provided by O*NET (skill\n",
      "deﬁnitions can be found in Appendix B) and normalize the measure of skill importance for each occupation\n",
      "to improve the comprehensibility of the results. Next, we conduct a regression analysis on our exposure\n",
      "measures ( U,V,Z) to examine the strength of associations between skill importance and exposure.\n",
      "Our ﬁndings indicate that the importance of science andcritical thinking skills are strongly negatively\n",
      "associated with exposure, suggesting that occupations requiring these skills are less likely to be impacted\n",
      "by current LLMs. Conversely, programming andwriting skills show a strong positive association with\n",
      "exposure, implying that occupations involving these skills are more susceptible to being inﬂuenced by LLMs\n",
      "(see Table 5 for detailed results).\n",
      "4.4 Barriers to Entry\n",
      "Next, we examine barriers to entry to better understand if there is diﬀerentiation in exposure due to types of\n",
      "jobs. One such proxy is an O*NET occupation-level descriptor called the \"Job Zone.\" A Job Zone groups\n",
      "occupations that are similar in (a) the level of education needed to get a job in the occupation, (b) the amount\n",
      "of related experience required to do the work, and (c) the extent of on-the-job training needed to do the work.\n",
      "In the O*NET database, there are 5 Job Zones, with Job Zone 1 requiring the least amount of preparation (3\n",
      "months) and Job Zone 5 requiring the most extensive amount of preparation, 4 or more years. We observe that\n",
      "median income increases monotonically across Job Zones as the level of preparation needed also increases,\n",
      "with the median worker in Job Zone 1 earning $30,230and the median worker in Job Zone 5 earning $80,980.\n",
      "All of our measures ( U,V, and Z) show an identical pattern, that is, exposure increases from Job Zone 1 to\n",
      "Job Zone 4, and either remains similar or decreases at Job Zone 5. Similar to Figure 3, in Figure 5, we plot\n",
      "the percentage of workers at every threshold of exposure. We ﬁnd that, on average, the percentage of workers\n",
      "in occupations with greater than 50% Vexposure in Job Zones 1 through 5 have Vat 0.00% (Job Zone 1),\n",
      "6.11% (Job Zone 2), 10.57% (Job Zone 3), 34.5% (Job Zone 4), and 26.45% (Job Zone 5), respectively. 8\n",
      "4.4.1 Typical Education Needed for Entry\n",
      "Since inclusion in a Job Zone accounts for both the education required—which itself is a proxy for skill\n",
      "acquisition—and the preparation required, we seek data to disentangle these variables. We use two variables\n",
      "from the Bureau of Labor Statistics’ Occupational data: \"Typical Education Needed for Entry\" and \"On-the-job\n",
      "Training Required to Attain Competency\" in an occupation. By examining these factors, we aim to uncover\n",
      "trends with potential implications for the workforce. There are 3,504,000 workers for whom we lack data on\n",
      "education and on-the-job training requirements, and they are therefore excluded from the summary tables.\n",
      "Our analysis suggests that individuals holding Bachelor’s, Master’s, and professional degrees are more\n",
      "exposed to LLMs and LLM-powered software than those without formal educational credentials (see Table 7).\n",
      "Interestingly, we also ﬁnd that individuals with some college education but no degree exhibit a high level of\n",
      "exposure to LLMs and LLM-powered software. Upon examining the table displaying barriers to entry, we\n",
      "observe that the jobs with the least exposure require the most training, potentially oﬀering a lower payoﬀ (in\n",
      "terms of median income) once competency is achieved. Conversely, jobs with no on-the-job training required\n",
      "or only internship/residency required appear to yield higher income but are more exposed to LLMs.\n",
      "8For this set of results, all tasks have equal weight within an occupation. Results do not change meaningfully with the\n",
      "core/supplemental weighting scheme.WORKING PAPER\n",
      "Figure 5: Vexposure ratings of occupations in the ﬁve Job Zones, which are groups of similar occupations\n",
      "that are classiﬁed according to the level of education, experience, and on-the-job training needed to perform\n",
      "them. All tasks are weighted equally.WORKING PAPER\n",
      "Group Occupations with highest exposure % Exposure\n",
      "Human UUU Interpreters and Translators 76.5\n",
      "Survey Researchers 75.0\n",
      "Poets, Lyricists and Creative Writers 68.8\n",
      "Animal Scientists 66.7\n",
      "Public Relations Specialists 66.7\n",
      "Human VVV Survey Researchers 84.4\n",
      "Writers and Authors 82.5\n",
      "Interpreters and Translators 82.4\n",
      "Public Relations Specialists 80.6\n",
      "Animal Scientists 77.8\n",
      "Human ZZZ Mathematicians 100.0\n",
      "Tax Preparers 100.0\n",
      "Financial Quantitative Analysts 100.0\n",
      "Writers and Authors 100.0\n",
      "Web and Digital Interface Designers 100.0\n",
      "Humans labeled 15 occupations as \"fully exposed.\"\n",
      "Model UUU Mathematicians 100.0\n",
      "Correspondence Clerks 95.2\n",
      "Blockchain Engineers 94.1\n",
      "Court Reporters and Simultaneous Captioners 92.9\n",
      "Proofreaders and Copy Markers 90.9\n",
      "Model VVV Mathematicians 100.0\n",
      "Blockchain Engineers 97.1\n",
      "Court Reporters and Simultaneous Captioners 96.4\n",
      "Proofreaders and Copy Markers 95.5\n",
      "Correspondence Clerks 95.2\n",
      "Model ZZZ Accountants and Auditors 100.0\n",
      "News Analysts, Reporters, and Journalists 100.0\n",
      "Legal Secretaries and Administrative Assistants 100.0\n",
      "Clinical Data Managers 100.0\n",
      "Climate Change Policy Analysts 100.0\n",
      "The model labeled 86 occupations as \"fully exposed.\"\n",
      "Highest variance Search Marketing Strategists 14.5\n",
      "Graphic Designers 13.4\n",
      "Investment Fund Managers 13.0\n",
      "Financial Managers 13.0\n",
      "Insurance Appraisers, Auto Damage 12.6\n",
      "Table 4: Occupations with the highest exposure according to each measurement. The ﬁnal row lists the\n",
      "occupations with the highest f2value, indicating that they had the most variability in exposure scores.\n",
      "Exposure percentages indicate the share of an occupation’s task that are exposed to GPTs ( UUU) or GPT-powered\n",
      "software ( VVVandZZZ), where exposure is deﬁned as driving a reduction in time it takes to complete the task by at\n",
      "least 50% (see exposure rubric A.1). As such, occupations listed in this table are those where we estimate\n",
      "that GPTs and GPT-powered software are able to save workers a signiﬁcant amount of time completing a\n",
      "large share of their tasks, but it does not necessarily suggest that their tasks can be fully automated by these\n",
      "technologies. All tasks are assigned equal weight within an occupation.WORKING PAPER\n",
      "Basic Skill UUU\n",
      "(std err)VVV\n",
      "(std err)ZZZ\n",
      "(std err)\n",
      "All skill importance scores are normalized to be between 0 and 1.\n",
      "Constant 0.082*** -0.112*** 0.300***\n",
      "(0.011) (0.011) (0.057)\n",
      "Active Listening 0.128** 0.214*** 0.449***\n",
      "(0.047) (0.043) (0.027)\n",
      "Mathematics -0.127*** 0.161*** 0.787***\n",
      "(0.026) (0.021) (0.049)\n",
      "Reading Comprehension 0.153*** 0.470*** -0.346***\n",
      "(0.041) (0.037) (0.017)\n",
      "Science -0.114*** -0.230*** -0.346***\n",
      "(0.014) (0.012) (0.017)\n",
      "Speaking -0.028 0.133*** 0.294***\n",
      "(0.039) (0.033) (0.042)\n",
      "Writing 0.368*** 0.467*** 0.566***\n",
      "(0.042) (0.037) (0.047)\n",
      "Active Learning -0.157*** -0.065** 0.028\n",
      "(0.027) (0.024) (0.032)\n",
      "Critical Thinking -0.264*** -0.196*** -0.129**\n",
      "(0.036) (0.033) (0.042)\n",
      "Learning Strategies -0.072* -0.209*** -0.346***\n",
      "(0.028) (0.025) (0.034)\n",
      "Monitoring -0.067** -0.149*** -0.232***\n",
      "(0.023) 0.020) (0.026)\n",
      "Programming 0.637*** 0.623*** 0.609***\n",
      "(0.030) (0.022) (0.024)\n",
      "Table 5: Regression of occupation-level, human-annotated exposure to GPTs on skill importance for each\n",
      "skill in the O*NET Basic skills category, plus the programming skill. Descriptions of the skills may be found\n",
      "in Appendix B. Task ratings within each occupation for exposure have equal weight.\n",
      "Job\n",
      "ZonePreparation\n",
      "RequiredEducation\n",
      "RequiredExample Occupations Median\n",
      "IncomeTot Emp\n",
      "(000s )H\n",
      "UUUM\n",
      "UUUH\n",
      "VVVM\n",
      "VVVH\n",
      "ZZZM\n",
      "ZZZ\n",
      "1 None or little\n",
      "(0-3 months)High school\n",
      "diploma or GED\n",
      "(otional)Food preparation workers,\n",
      "dishwashers, ﬂoor sanders$30,230 13,100 0.03 0.04 0.06 0.06 0.09 0.08\n",
      "2 Some (3-12\n",
      "months)High school\n",
      "diplomaOrderlies, customer\n",
      "service representatives,\n",
      "tellers$38,215 73,962 0.07 0.12 0.16 0.20 0.24 0.27\n",
      "3 Medium (1-2\n",
      "years)Vocational school,\n",
      "on-the-job training,\n",
      "or associate’s\n",
      "degreeElectricians, barbers,\n",
      "medical assistants$54,815 37,881 0.11 0.14 0.26 0.32 0.41 0.51\n",
      "4 Considerable\n",
      "(2-4 years)Bachelor’s degree Database administrators,\n",
      "graphic designers, cost\n",
      "estimators$77,345 56,833 0.23 0.18 0.47 0.51 0.71 0.85\n",
      "5 Extensive (4+\n",
      "years)Master’s degree or\n",
      "higherPharmacists, lawyers,\n",
      "astronomers$81,980 21,221 0.23 0.13 0.43 0.45 0.63 0.76\n",
      "Table 6: Mean exposure to GPTs by job zone. For each job zone, we also present the median of median\n",
      "annual income for each constituting occupation in USD, and the total number of workers in all occupations\n",
      "for that job zone, in the thousands. Task weights are equal for all tasks.WORKING PAPER\n",
      "On The Job Training Required Median Income Tot Emp (000s) HUUU MUUU HVVVMVVV HZZZMZZZ\n",
      "None $77,440 90,776 0.20 0.16 0.42 0.46 0.63 0.76\n",
      "Apprenticeship $55,995 3,066 0.01 0.02 0.04 0.06 0.07 0.10\n",
      "Internship/residency $77,110 3,063 0.16 0.06 0.36 0.38 0.55 0.71\n",
      "Short-term on-the-job training $33,370 66,234 0.11 0.15 0.21 0.25 0.32 0.34\n",
      "Moderate-term on-the-job training $46,880 31,285 0.09 0.12 0.21 0.25 0.32 0.38\n",
      "Long-term on-the-job training $48,925 5,070 0.08 0.10 0.18 0.22 0.28 0.33\n",
      "Table 7: Mean exposure scores for occupations, grouped by level of on-the-job training required to attain\n",
      "competency in the job. Alongside exposure scores, we display the median of median annual income for each\n",
      "occupation, as well as the total number of workers in each group, in thousands. Task weights are equal within\n",
      "an occupation and sum to one.WORKING PAPER\n",
      "5 Validation of Measures\n",
      "5.1 Comparison to Earlier Eﬀorts\n",
      "This paper aims to build on a number of previous empirical studies examining the occupational exposure to\n",
      "advances in AI and/or automation. Previous studies have used a variety of methods, including:\n",
      "•Using occupational taxonomies like O*NET to characterize which occupations have routine vs.\n",
      "non-routine and manual vs. cognitive task content (Autor et al., 2003; Acemoglu and Autor, 2011a).\n",
      "•Mapping text descriptions of tasks to descriptions of technological advances in patents. (Kogan et al.,\n",
      "2021; Webb, 2020)\n",
      "•Linking capabilities of AI systems to occupational abilities and aggregating exposure estimates to the\n",
      "occupations where those abilities are required. (Felten et al., 2018, 2023)\n",
      "•Mapping the results of AI task benchmark evaluations (ImageNet, Robocup, etc.) to 59 worker tasks\n",
      "through a set of 14 cognitive abilities drawn from the cognitive science literature. (Tolan et al., 2021)\n",
      "•Expert labeling of automation potential for a set of O*NET occupations where experts had high\n",
      "conﬁdence, combined with a probabilistic classiﬁer to estimate automation potential for the remainder\n",
      "of O*NET occupations. (Frey and Osborne, 2017)\n",
      "•Developing a rubric for evaluating the \"suitability for machine learning\" (SML) of activities that\n",
      "workers are completing in the economy (Brynjolfsson and Mitchell, 2017; Brynjolfsson et al., 2018,\n",
      "2023).\n",
      "We provide a set of summary statistics on many of these prior eﬀorts in Table 8.\n",
      "This paper’s methodology primarily builds upon the SML approach by developing a rubric to evaluate the\n",
      "overlap between LLM capabilities and worker tasks as reported in the O*NET database. Table 9 presents the\n",
      "results of OLS regressions of our new LLM exposure measurements on occupation-level exposure measures\n",
      "from (Felten et al., 2018) (\"AI Occupational Exposure Score\" in the table), (Frey and Osborne, 2017) (Frey\n",
      "& Osborne Automation), scores from all three technologies in (Webb, 2020), normalized routine manual\n",
      "and cognitive scores from (Acemoglu and Autor, 2011a), and (Brynjolfsson et al., 2018, 2023) (SML). We\n",
      "also use annualized occupational salaries from the most recent BLS Occupational Employment Survey as a\n",
      "control. There are four separate output variables representing new scores in this paper that are predicted by\n",
      "earlier eﬀorts.\n",
      "GPT-4 Exposure Rating 1 corresponds to our overall exposure rubric as evaluated by GPT-4, where full\n",
      "exposure potential is coded as 1, no exposure potential is coded as 0, and partial exposure (E2 in our labeling\n",
      "scheme) is coded as 0.5. GPT-4 Exposure Rating 2 is scored similarly for overall exposure, but with a slightly\n",
      "diﬀerent prompt. The results are very similar across the two prompts. Human Exposure Rating represents the\n",
      "same rubric as in GPT-4 Exposure Rating 1 but is scored by humans, as discussed in an earlier section of the\n",
      "paper. These results correspond to the Vset of statistics presented above, with supplemental tasks having half\n",
      "the weight of core tasks within an occupation. These weights sum to one (core/supplemental distinctions are\n",
      "determined by O*NET).\n",
      "The results across each type of measurement are consistent. We ﬁnd generally positive and statistically\n",
      "signiﬁcant correlations between our LLM exposure measures and previous measurements targeting software\n",
      "and AI. Encouragingly, the SML exposure scores by occupation show signiﬁcant and positive associations\n",
      "with the exposure scores we develop in this paper, demonstrating a level of cohesion between the two studies\n",
      "with similar approaches. The Webb software and AI patent-based measures, SML, and normalized (demeanedWORKING PAPER\n",
      "Min 25th Perc. Median 75th Perc Max Mean Std. Dev. Count\n",
      "GPT-4 Exposure Rating 1 0.00 0.13 0.34 0.50 1.00 0.33 0.22 750\n",
      "GPT-4 Exposure Rating 2 0.00 0.09 0.24 0.40 0.98 0.26 0.20 750\n",
      "Human Exposure Rating 0.00 0.09 0.29 0.47 0.84 0.29 0.21 750\n",
      "Software (Webb) 1.00 25.00 50.00 75.00 100.00 50.69 30.05 750\n",
      "Robot (Webb) 1.00 22.00 52.00 69.00 100.00 48.61 28.61 750\n",
      "AI (Webb) 1.00 28.00 55.00 82.00 100.00 54.53 29.65 750\n",
      "Suitability for Machine Learning 2.60 2.84 2.95 3.12 3.55 2.99 0.18 750\n",
      "Normalized Routine Cognitive -3.05 -0.46 0.10 0.63 3.42 0.07 0.86 750\n",
      "Normalized Routine Manual -1.81 -0.81 -0.11 0.73 2.96 0.05 1.01 750\n",
      "AI Occupational Exposure Score 1.42 3.09 3.56 4.04 6.54 3.56 0.70 750\n",
      "Frey & Osborne Automation 0.00 0.07 0.59 0.88 0.99 0.50 0.38 681\n",
      "Log Avg. Salary 10.13 10.67 11.00 11.34 12.65 11.02 0.45 749\n",
      "Table 8: Summary statistics for a suite of prior eﬀorts to measure occupational exposure to AI and automation.\n",
      "We have also included summary statistics for measurements newly presented in this work. We include all\n",
      "measures from (Webb, 2020), normalized routine cognitive and manual scores from (Acemoglu and Autor,\n",
      "2011a) (means may deviate slightly from 0 due to imperfect matching of occupational groups), Suitability for\n",
      "Machine Learning from (Brynjolfsson and Mitchell, 2017; Brynjolfsson et al., 2018, 2023), AI Occupational\n",
      "Exposure from (Felten et al., 2018), and Automation exposure from (Frey and Osborne, 2017). We include as\n",
      "many occupations as we can match, but since O*NET taxonomies have changed as these measures have been\n",
      "developed, some of the roles may be missing from the most recent version of O*NET 6-digit occupations.\n",
      "and divided by standard deviation) routine cognitive scores all exhibit positive associations with some of our\n",
      "measures.\n",
      "Software, SML, and routine cognitive scores all show positive and statistically signiﬁcant associations\n",
      "with LLM exposure scores at a 1% level. Coeﬃcients on AI scores from (Webb, 2020) are also positive and\n",
      "statistically signiﬁcant at a 5% level, but our secondary prompt on overall exposure to LLMs in columns 3\n",
      "and 4 does not exhibit a statistically signiﬁcant relationship. For the most part, the AI Occupational Exposure\n",
      "Score is not correlated with our exposure measures. Webb’s Robot exposure scores, routine manual task\n",
      "content, and the overall Automation metric from (Frey and Osborne, 2017) are all negatively correlated with\n",
      "our primary GPT-4 and human-assessed overall exposure ratings, conditional on the other measurements.\n",
      "This negative correlation reﬂects the limited exposure of physical tasks to LLMs. Manual work is not exposed\n",
      "to LLMs or even LLMs with additional systems integration for the time being.\n",
      "Low correlations with (Felten et al., 2018) and (Frey and Osborne, 2017) could potentially be explained\n",
      "by diﬀerences in approaches. Linking AI capabilities to worker abilities or scoring exposure directly based on\n",
      "the occupation’s characteristics, rather than aggregating up to the occupation from DWA or task-level scoring\n",
      "(as in the SML paper and our own), oﬀer a slightly diﬀerent perspective on the content of occupations.\n",
      "In all regressions, the '2ranges between 60.7% (column 3) and 72.8% (column 5). This suggests that\n",
      "our measure, which explicitly focuses on LLM capabilities, has between 28 and 40% unexplained variance\n",
      "compared to other measurements. Particularly in the case of AI-related exposure scores, we anticipate that a\n",
      "combination of other measurements would have a strong correlation with our scores. However, earlier eﬀorts\n",
      "had limited information about the future progress of LLMs or LLM-powered software. We expect that our\n",
      "understanding of future machine learning technologies is similarly imperfectly captured by our rubric today.WORKING PAPER\n",
      "GPT-4 Exposure Rating 1 GPT-4 Exposure Rating 2 Human Exposure Rating\n",
      "(1) (2) (3) (4) (5) (6)\n",
      "Software (Webb) 0.00113⇤⇤⇤0.00123⇤⇤⇤0.00111⇤⇤⇤0.00119⇤⇤⇤0.00096⇤⇤⇤0.00101⇤⇤⇤\n",
      "(0.00031 )( 0.00031 )( 0.00031 )( 0.00031 )( 0.00031 )( 0.00031 )\n",
      "Robot (Webb) \u00000.00378⇤⇤⇤\u00000.00405⇤⇤⇤\u00000.00377⇤⇤⇤\u00000.00399⇤⇤⇤\u00000.00371⇤⇤⇤\u00000.00383⇤⇤⇤\n",
      "(0.00032 )( 0.00031 )( 0.00034 )( 0.00033 )( 0.00029 )( 0.00028 )\n",
      "AI (Webb) 0.00080⇤⇤⇤0.00090⇤⇤⇤0.00036 0 .00045 0 .00067⇤⇤0.00071⇤⇤\n",
      "(0.00030 )( 0.00029 )( 0.00030 )( 0.00030 )( 0.00030 )( 0.00030 )\n",
      "Suitability for Machine Learning 0.29522⇤⇤⇤0.26888⇤⇤⇤0.28468⇤⇤⇤0.26245⇤⇤⇤0.19514⇤⇤⇤0.18373⇤⇤⇤\n",
      "(0.04503 )( 0.04418 )( 0.04404 )( 0.04342 )( 0.03990 )( 0.03886 )\n",
      "Normalized Routine Cognitive 0.06601⇤⇤⇤0.06868⇤⇤⇤0.04743⇤⇤⇤0.05015⇤⇤⇤0.03568⇤⇤⇤0.03659⇤⇤⇤\n",
      "(0.00886 )( 0.00894 )( 0.00872 )( 0.00879 )( 0.00671 )( 0.00669 )\n",
      "Normalized Routine Manual \u00000.11147⇤⇤⇤\u00000.11371⇤⇤⇤\u00000.09390⇤⇤⇤\u00000.09561⇤⇤⇤\u00000.11045⇤⇤⇤\u00000.11152⇤⇤⇤\n",
      "(0.00785 )( 0.00789 )( 0.00817 )( 0.00818 )( 0.00741 )( 0.00744 )\n",
      "AI Occupational Exposure Score 0.00993 0 .02465⇤⇤\u00000.01537 \u00000.00265 0 .00630 0 .01252\n",
      "(0.01107 )( 0.01059 )( 0.01160 )( 0.01114 )( 0.00918 )( 0.00845 )\n",
      "Frey & Osborne Automation \u00000.03024⇤\u00000.03950⇤⇤\u00000.00364 \u00000.01217 \u00000.03890⇤⇤\u00000.04253⇤⇤\n",
      "(0.01835 )( 0.01841 )( 0.02007 )( 0.01972 )( 0.01883 )( 0.01858 )\n",
      "Log Avg. Salary 0.05804⇤⇤⇤0.04863⇤⇤⇤0.02531\n",
      "(0.01870 )( 0.01860 )( 0.01727 )\n",
      "Constant \u00001.12937⇤⇤⇤\u00000.45743⇤⇤⇤\u00000.96117⇤⇤⇤\u00000.39935⇤⇤⇤\u00000.47078⇤\u00000.17706\n",
      "(0.26859 )( 0.15327 )( 0.26365 )( 0.15017 )( 0.24684 )( 0.13256 )\n",
      "N 680.00000 681 .00000 680 .00000 681 .00000 680 .00000 681 .00000\n",
      "'20.68741 0 .68212 0 .60737 0 .60198 0 .71213 0 .71126\n",
      "Table 9: Regression of LLM-exposure scores on prior measures of occupational exposure to AI and automation.\n",
      "We also include annualized wages from the BLS-OES survey in May 2021. Each measure is kept in its\n",
      "original scale, with the exception of routine cognitive and routine manual scores from (Acemoglu and Autor,\n",
      "2011a). Those two scores are standardized to mean zero and variance 1. Generally we ﬁnd strong positive\n",
      "associations with previous eﬀorts, though large residual variance to still be explained by our new measures.\n",
      "Columns 1 and 2 are based on our main Vexposure measure from GPT-4 ratings. Columns 3 and 4 are\n",
      "based on a similar slightly diﬀerent exposure rubric also rated by GPT-4 for robustness. Columns 5 and 6\n",
      "reﬂect human ratings on the same rubric as columns 1 and 2. Occupation-level scores are built using the\n",
      "core/supplemental task weights, assigning supplemental tasks as having half the weight of core tasks.WORKING PAPER\n",
      "6 Discussion\n",
      "6.1 GPTs as a General-Purpose Technology\n",
      "Earlier in this paper we discuss the possibility that LLMs could be classiﬁed as a general-purpose technology.\n",
      "This classiﬁcation requires LLMs to meet three core criteria: improvement over time, pervasiveness throughout\n",
      "the economy, and the ability to spawn complementary innovations (Lipsey et al., 2005). Evidence from the AI\n",
      "and machine learning literature thoroughly demonstrates that LLMs meet the ﬁrst criteria – they are improving\n",
      "in capabilities over time with the ability to complete or be helpful for an increasingly complex set of tasks and\n",
      "use-cases (see 2.1). This paper presents evidence to support the latter two criteria, ﬁnding that LLMs on their\n",
      "own can have pervasive impacts across the economy, and that complementary innovations enabled by LLMs –\n",
      "particularly via software and digital tools – can have widespread application to economic activity.\n",
      "Figure 3 oﬀers one illustration of the potential economic impact of complementary software built on top of\n",
      "LLMs. Taking the diﬀerence in the y-axis (the share of all occupations) between UandZat a given point along\n",
      "the x-axis (the share of tasks within an occupation that are exposed) gives the aggregate within-occupation\n",
      "exposure potential attributable to tools and software over and above direct exposure from LLMs on their\n",
      "own. The diﬀerence in means across all tasks between UandZof 0.42 using the GPT-4 annotations and 0.32\n",
      "using the human annotations (see Figure 3), suggests that the average impact of LLM-powered software on\n",
      "task-exposure may be more than twice as large as the mean exposure from LLMs on their own (mean Zof 0.14\n",
      "based on both human annotations and GPT-4 annotations). While our ﬁndings suggest that out-of-the-box\n",
      "these models are relevant to a meaningful share of workers and tasks, they also suggest that the software\n",
      "innovations they spawn could drive a much broader impact.\n",
      "One component of the pervasiveness of a technology is its level of adoption by businesses and users.\n",
      "This paper does not systematically analyze adoption of these models, however, there is early qualitative\n",
      "evidence that adoption and use of LLMs is becoming increasingly widespread. The power of relatively\n",
      "simple UI improvements on top of LLMs was evident in the rollout of ChatGPT – wherein versions of the\n",
      "underlying language model had been previously available via API, but usage skyrocketed after the release of\n",
      "the ChatGPT interface. (Chow, 2023; OpenAI, 2022) Following this release, a number of commercial surveys\n",
      "indicate that ﬁrm and worker adoption of LLMs has increased over the past several months. (Constantz, 2023;\n",
      "ResumeBuilder.com, 2023)\n",
      "Widespread adoption of these models requires addressing existing bottlenecks. A key determinant of\n",
      "their utility is the level of conﬁdence humans place in them and how humans adapt their habits. For instance,\n",
      "in the legal profession, the models’ usefulness depends on whether legal professionals can trust model\n",
      "outputs without verifying original documents or conducting independent research. The cost and ﬂexibility\n",
      "of the technology, worker and ﬁrm preferences, and incentives also signiﬁcantly inﬂuence the adoption of\n",
      "tools built on top of LLMs. In this way, adoption may be driven by progress on some of the ethical and\n",
      "safety risks associated with LLMs: bias, fabrication of facts, and misalignment, to name a few OpenAI\n",
      "(2023a). Moreover, the adoption of LLMs will vary across diﬀerent economic sectors due to factors such\n",
      "as data availability, regulatory environment, and the distribution of power and interests. Consequently, a\n",
      "comprehensive understanding of the adoption and use of LLMs by workers and ﬁrms requires a more in-depth\n",
      "exploration of these intricacies.\n",
      "One possibility is that time savings and seamless application will hold greater importance than quality\n",
      "improvement for the majority of tasks. Another is that the initial focus will be on augmentation, followed byimprovement for the majority of tasks. Another is that the initial focus will be on augmentation, followed by\n",
      "automation (Huang and Rust, 2018). One way this might take shape is through an augmentation phase where\n",
      "jobs ﬁrst become more precarious (e.g., writers becoming freelancers) before transitioning to full automation.WORKING PAPER\n",
      "6.2 Implications for US Public Policy\n",
      "The introduction of automation technologies, including LLMs, has previously been linked to heightened\n",
      "economic disparity and labor disruption, which may give rise to adverse downstream eﬀects (Acemoglu and\n",
      "Restrepo, 2022a; Acemoglu, 2002; Moll et al., 2021; Klinova and Korinek, 2021; Weidinger et al., 2021,\n",
      "2022). Our results examining worker exposure in the United States underscore the need for societal and policy\n",
      "preparedness to the potential economic disruption posed by LLMs and the complementary technologies\n",
      "that they spawn. While it is outside the scope of this paper to recommend speciﬁc policy prescriptions to\n",
      "smooth the transition to an economy with increasingly widespread LLM adoption, prior work such as (Autor\n",
      "et al., 2022b) has articulated several important directions for US policy related to education, worker training,\n",
      "reforms to safety net programs, and more.\n",
      "6.3 Limitations and Future Work\n",
      "In addition to those discussed above, we highlight some particular limitations of this work that warrant further\n",
      "investigation. Primarily, our focus on the United States restricts the generalizability of our ﬁndings to other\n",
      "nations where the adoption and impact of generative models may diﬀer due to factors such as industrial\n",
      "organization, technological infrastructure, regulatory frameworks, linguistic diversity, and cultural contexts.\n",
      "We hope to address this limitation by extending the study’s scope and by sharing our methods so other\n",
      "researchers can build on them.\n",
      "Subsequent research eﬀorts should consider two additional studies: one exploring LLM adoption patterns\n",
      "across various sectors and occupations, and another scrutinizing the actual capabilities and limitations of\n",
      "state-of-the-art models in relation to worker activities beyond the scope of our exposure scores. For example,\n",
      "despite recent advances in multimodal capabilities with GPT-4, we did not consider vision capabilities in\n",
      "theUratings on direct LLMs-exposure (OpenAI, 2023b). Future work should consider the impact of such\n",
      "capability advances as they unfold. Furthermore, we acknowledge that there may be discrepancies between\n",
      "theoretical and practical performance, particularly in complex, open-ended, and domain-speciﬁc tasks.\n",
      "7 Conclusion\n",
      "In conclusion, this study oﬀers an examination of the potential impact of LLMs on various occupations and\n",
      "industries within the U.S. economy. By applying a new rubric for understanding LLM capabilities and their\n",
      "potential eﬀects on jobs, we have observed that most occupations exhibit some degree of exposure to LLMs,\n",
      "with higher-wage occupations generally presenting more tasks with high exposure. Our analysis indicates that\n",
      "approximately 19% of jobs have at least 50% of their tasks exposed to LLMs when considering both current\n",
      "model capabilities and anticipated LLM-powered software.\n",
      "Our research aims to highlight the general-purpose potential of LLMs and their possible implications for\n",
      "US workers. Previous literature demonstrates the impressive improvements of LLMs to date (see 2.1). Our\n",
      "ﬁndings conﬁrm the hypothesis that these technologies can have pervasive impacts across a wide swath of\n",
      "occupations in the US, and that additional advancements supported by LLMs, mainly through software and\n",
      "digital tools, can have signiﬁcant eﬀects on a range of economic activities. However, while the technical\n",
      "capacity for LLMs to make human labor more eﬃcient appears evident, it is important to recognize that social,\n",
      "economic, regulatory, and other factors will inﬂuence actual labor productivity outcomes. As capabilities\n",
      "continue to evolve, the impact of LLMs on the economy will likely persist and increase, posing challenges for\n",
      "policymakers in predicting and regulating their trajectory.\n",
      "Further research is necessary to explore the broader implications of LLM advancements, including\n",
      "their potential to augment or displace human labor, their impact on job quality, impacts on inequality, skilltheir potential to augment or displace human labor, their impact on job quality, impacts on inequality, skill\n",
      "development, and numerous other outcomes. By seeking to understand the capabilities and potential eﬀectsWORKING PAPER\n",
      "of LLMs on the workforce, policymakers and stakeholders can make more informed decisions to navigate the\n",
      "complex landscape of AI and its role in shaping the future of work.\n",
      "7.1 LLM Conclusion (GPT-4’s Version)\n",
      "Generative Pre-trained Transformers (GPTs) generate profound transformations, garnering potential technolog-\n",
      "ical growth, permeating tasks, greatly impacting professions. This study probes GPTs’ potential trajectories,\n",
      "presenting a groundbreaking rubric to gauge tasks’ GPT exposure, particularly in the U.S. labor market.\n",
      "7.2 LLM Conclusion (Author-Augmented Version)\n",
      "Generative Pre-trained Transformers (GPTs) generate profound transformations, garnering potential techno-\n",
      "logical growth, permeating tasks, gutting professional management. Gauging possible trajectories? Generate\n",
      "pioneering taxonomies, gather policymakers together, generalize past today.\n",
      "Acknowledgments\n",
      "Thank you to the group of annotators who helped us annotate task exposure, including Muhammad Ahmed\n",
      "Saeed, Bongane Zitha, Merve Özen Şenen, J.J., and Peter Hoeschele. We also thank Lauryn Fuld, Ashley Glat,\n",
      "Michael Lampe, and Julia Susser for excellent research assistance. We thank Miles Brundage for signiﬁcant\n",
      "feedback on this paper.\n",
      "We thank Todor Markov and Vik Goel for setting up the infrastructure we use to run our rubrics with\n",
      "GPT-4. We thank Lama Ahmad, Donald Bakong, Seth Benzell, Erik Brynjolfsson, Parfait Eloundou-Enyegue,\n",
      "Carl Frey, Sarah Giroux, Gillian Hadﬁeld, Johannes Heidecke, Alan Hickey, Eric Horvitz, Shengli Hu,\n",
      "Ashyana Kachra, Christina Kim, Katya Klinova, Daniel Kokotajlo, Gretchen Krueger, Michael Lampe, Aalok\n",
      "Mehta, Larissa Schiavo, Daniel Selsam, Sarah Shoker, Prasanna Tambe, and Jeﬀ Wu for feedback and edits at\n",
      "various stages of the project.\n",
      "LLM assistance statement\n",
      "GPT-4 and ChatGPT were used for writing, coding, and formatting assistance in this project.\n",
      "A Rubric\n",
      "A.1 Exposure\n",
      "# E Exposure Taxonomy\n",
      "Consider the most powerful OpenAI large language model (LLM) This model can complete many tasks\n",
      "that can be formulated as having text input and text output where the context for the input can be captured in\n",
      "2000 words. The model also cannot draw up-to-date facts (those from <1 year ago) unless they are captured\n",
      "in the input.\n",
      "Assume you are a worker with an average level of expertise in your role trying to complete the given task.\n",
      "You have access to the LLM as well as any other existing software or computer hardware tools mentioned\n",
      "in the task. You also have access to any commonly available technical tools accessible via a laptop (e.g. a\n",
      "microphone, speakers, etc.). You do not have access to any other physical tools or materials.\n",
      "Please label the given task according to the taxonomy below.\n",
      "## E0 – No exposure\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 8192 tokens. However, your messages resulted in 18821 tokens. Please reduce the length of the messages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/lanchu/Library/CloudStorage/OneDrive-Raboweb/Documents/Project/langchain-tutorials/chains/Chain Types copy.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lanchu/Library/CloudStorage/OneDrive-Raboweb/Documents/Project/langchain-tutorials/chains/Chain%20Types%20copy.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m chain\u001b[39m.\u001b[39;49mrun(job_doc)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchain/chains/base.py:505\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    504\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 505\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[1;32m    506\u001b[0m         _output_key\n\u001b[1;32m    507\u001b[0m     ]\n\u001b[1;32m    509\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    510\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[1;32m    511\u001b[0m         _output_key\n\u001b[1;32m    512\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchain/chains/base.py:310\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    309\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    311\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    312\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    313\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    314\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchain/chains/base.py:304\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    297\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    298\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    299\u001b[0m     inputs,\n\u001b[1;32m    300\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[1;32m    301\u001b[0m )\n\u001b[1;32m    302\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 304\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    305\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    306\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    307\u001b[0m     )\n\u001b[1;32m    308\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    309\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchain/chains/combine_documents/base.py:122\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m    121\u001b[0m other_keys \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key}\n\u001b[0;32m--> 122\u001b[0m output, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_docs(\n\u001b[1;32m    123\u001b[0m     docs, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mother_keys\n\u001b[1;32m    124\u001b[0m )\n\u001b[1;32m    125\u001b[0m extra_return_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key] \u001b[39m=\u001b[39m output\n\u001b[1;32m    126\u001b[0m \u001b[39mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchain/chains/combine_documents/stuff.py:171\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_inputs(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    170\u001b[0m \u001b[39m# Call predict on the LLM.\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_chain\u001b[39m.\u001b[39;49mpredict(callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs), {}\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchain/chains/llm.py:298\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    284\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \n\u001b[1;32m    286\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchain/chains/base.py:310\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    309\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    311\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    312\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    313\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    314\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchain/chains/base.py:304\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    297\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    298\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    299\u001b[0m     inputs,\n\u001b[1;32m    300\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[1;32m    301\u001b[0m )\n\u001b[1;32m    302\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 304\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    305\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    306\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    307\u001b[0m     )\n\u001b[1;32m    308\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    309\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchain/chains/llm.py:108\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[1;32m    104\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    105\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m    106\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    107\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 108\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    109\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchain/chains/llm.py:120\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    118\u001b[0m callbacks \u001b[39m=\u001b[39m run_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    121\u001b[0m         prompts,\n\u001b[1;32m    122\u001b[0m         stop,\n\u001b[1;32m    123\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    124\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_kwargs,\n\u001b[1;32m    125\u001b[0m     )\n\u001b[1;32m    126\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm\u001b[39m.\u001b[39mbind(stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_kwargs)\u001b[39m.\u001b[39mbatch(\n\u001b[1;32m    128\u001b[0m         cast(List, prompts), {\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks}\n\u001b[1;32m    129\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchain/chat_models/base.py:459\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    452\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    453\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    457\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    458\u001b[0m     prompt_messages \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_messages() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 459\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_messages, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchain/chat_models/base.py:349\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n\u001b[1;32m    348\u001b[0m             run_managers[i]\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 349\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    350\u001b[0m flattened_outputs \u001b[39m=\u001b[39m [\n\u001b[1;32m    351\u001b[0m     LLMResult(generations\u001b[39m=\u001b[39m[res\u001b[39m.\u001b[39mgenerations], llm_output\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39mllm_output)\n\u001b[1;32m    352\u001b[0m     \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results\n\u001b[1;32m    353\u001b[0m ]\n\u001b[1;32m    354\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchain/chat_models/base.py:339\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mfor\u001b[39;00m i, m \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(messages):\n\u001b[1;32m    337\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m         results\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 339\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_with_cache(\n\u001b[1;32m    340\u001b[0m                 m,\n\u001b[1;32m    341\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    342\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[i] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    343\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    344\u001b[0m             )\n\u001b[1;32m    345\u001b[0m         )\n\u001b[1;32m    346\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    347\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchain/chat_models/base.py:492\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    489\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m     )\n\u001b[1;32m    491\u001b[0m \u001b[39mif\u001b[39;00m new_arg_supported:\n\u001b[0;32m--> 492\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    493\u001b[0m         messages, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    494\u001b[0m     )\n\u001b[1;32m    495\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(messages, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchain/chat_models/openai.py:365\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m message_dicts, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    364\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[0;32m--> 365\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompletion_with_retry(\n\u001b[1;32m    366\u001b[0m     messages\u001b[39m=\u001b[39;49mmessage_dicts, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[1;32m    367\u001b[0m )\n\u001b[1;32m    368\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchain/chat_models/openai.py:303\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    300\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 303\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchain/chat_models/openai.py:301\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    300\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 301\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    157\u001b[0m         url,\n\u001b[1;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/openai/api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    298\u001b[0m     )\n\u001b[0;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/openai/api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    715\u001b[0m         ),\n\u001b[1;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    717\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/openai/api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    777\u001b[0m     )\n\u001b[1;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 8192 tokens. However, your messages resulted in 18821 tokens. Please reduce the length of the messages."
     ]
    }
   ],
   "source": [
    "chain.run(job_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc1482",
   "metadata": {},
   "source": [
    "### Summarize: Map Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='WORKING PAPER\\nGPTs are GPTs: An Early Look at the Labor Market Impact Potential\\nof Large Language Models\\nTyna Eloundou1, Sam Manning1,2, Pamela Mishkin\\x001, and Daniel Rock3\\n1OpenAI\\n2OpenResearch\\n3University of Pennsylvania\\nAugust 22, 2023\\nAbstract\\nWe investigate the potential implications of large language models (LLMs), such as Generative Pre-\\ntrained Transformers (GPTs), on the U.S. labor market, focusing on the increased capabilities arising from\\nLLM-powered software compared to LLMs on their own. Using a new rubric, we assess occupations based\\non their alignment with LLM capabilities, integrating both human expertise and GPT-4 classiﬁcations.\\nOur ﬁndings reveal that around 80% of the U.S. workforce could have at least 10% of their work tasks\\naﬀected by the introduction of LLMs, while approximately 19% of workers may see at least 50% of their\\ntasks impacted. We do not make predictions about the development or adoption timeline of such LLMs.\\nThe projected e ﬀects span all wage levels, with higher-income jobs potentially facing greater exposure to\\nLLM capabilities and LLM-powered software. Signiﬁcantly, these impacts are not restricted to industries\\nwith higher recent productivity growth. Our analysis suggests that, with access to an LLM, about 15%\\nof all worker tasks in the US could be completed signiﬁcantly faster at the same level of quality. When\\nincorporating software and tooling built on top of LLMs, this share increases to between 47 and 56%\\nof all tasks. This ﬁnding implies that LLM-powered software will have a substantial e ﬀect on scaling\\nthe economic impacts of the underlying models. We conclude that LLMs such as GPTs exhibit traits of\\ngeneral-purpose technologies, indicating that they could have considerable economic, social, and policy\\nimplications.\\n1 Introduction\\nAs shown in Figure 1, recent years, months, and weeks have seen remarkable progress in the ﬁeld of generative\\nAI and large language models (LLMs). While the public often associates LLMs with various iterations of the\\nGenerative Pre-trained Transformer (GPT), LLMs can be trained using a range of architectures, and are not\\nlimited to transformer-based models (Devlin et al., 2019). LLMs can process and produce various forms of\\nsequential data, including assembly language, protein sequences and chess games, extending beyond natural\\nlanguage applications alone. In this paper, we use LLMs and GPTs somewhat interchangeably, and specify in\\nour rubric that these should be considered similar to the GPT-family of models available via ChatGPT or\\nthe OpenAI Playground (which at the time of labeling included models in the GPT-3.5 family but not in the\\nGPT-4 family). We examine LLMs with text- and code-generating abilities, use the term \"generative AI\" to\\nadditionally include modalities such as images or audio, and use \"LLM-powered software\" to cover tools built\\non top of LLMs or that combine LLMs with other generative AI models.\\n\\x00Corresponding author (pamela@openai.com). Authors contributed equally and are listed alphabetically.arXiv:2303.10130v5  [econ.GN]  21 Aug 2023WORKING PAPER\\nFigure 1: Taken directly from GPT-4 Technical Report (OpenAI, 2023b). To get a sense of how quickly\\nmodel capabilities are progressing – consider the jump in exam performance between GPT-3.5 and GPT-4\\n(OpenAI, 2023b).\\nOur study is motivated less by the progress of these models alone though, and more by the breadth,\\nscale, and capabilities we’ve seen in the complementary technologies developed around them. The role of\\ncomplementary technologies remains to be seen, but maximizing the impact of LLMs appears contingent\\non integrating them with larger systems (Bresnahan, 2019; Agrawal et al., 2021). While the focus of our\\ndiscussion is primarily on the generative capabilities of LLMs, it is important to note that these models can\\nalso be utilized for various tasks beyond text generation. For example, embeddings from LLMs can be used\\nfor custom search applications, and LLMs can perform tasks such as summarization and classiﬁcation where\\nthe context may be largely contained in the prompt.\\nTo complement predictions of technology’s impacts on work and provide a framework for understanding\\nthe evolving landscape of language models and their associated technologies,'),\n",
       " Document(page_content=' LLMs, it is important to note that these models can\\nalso be utilized for various tasks beyond text generation. For example, embeddings from LLMs can be used\\nfor custom search applications, and LLMs can perform tasks such as summarization and classiﬁcation where\\nthe context may be largely contained in the prompt.\\nTo complement predictions of technology’s impacts on work and provide a framework for understanding\\nthe evolving landscape of language models and their associated technologies, we propose a new rubric\\nfor assessing LLM capabilities and their potential e ﬀects on jobs. This rubric (A.1) measures the overall\\nexposure of tasks to LLMs, following the spirit of prior work on quantifying exposure to machine learning\\n(Brynjolfsson et al., 2018; Felten et al., 2018; Webb, 2020). We deﬁne exposure as a proxy for potential\\neconomic impact without distinguishing between labor-augmenting or labor-displacing e ﬀects. We employ\\nhuman annotators and GPT-4 itself as a classiﬁer to apply this rubric to occupational data in the U.S. economy,\\nprimarily sourced from the O*NET database. 12\\nTo construct our primary exposure dataset, we collected both human annotations and GPT-4 classiﬁcations,\\nusing a prompt tuned for agreement with a sample of labels from the authors. We observe similar agreement\\n1This is distinct from recent social science research that makes use of LLMs to simulate human behavior (Horton, 2023; Sorensen\\net al., 2022)\\n2While our exposure rubric does not necessarily tie the concept of language models to any particular model, we were strongly\\nmotivated by our observed capabilities of GPT-4 and the suite of capabilities we saw in development with OpenAI’s launch partners\\n(OpenAI, 2023b).WORKING PAPER\\nlevels in GPT-4 responses and between human and machine evaluations, when aggregated to the task level.\\nThis exposure measure reﬂects an estimate of the technical capacity to make human labor more e ﬃcient;\\nhowever, social, economic, regulatory, and other determinants imply that technical feasibility does not\\nguarantee labor productivity or automation outcomes. Our analysis indicates that approximately 19% of jobs\\nhave at least 50% of their tasks exposed when considering both current model capabilities and anticipated\\ntools built upon them. Human assessments suggest that only 3% of U.S. workers have over half of their tasks\\nexposed to LLMs when considering existing language and code capabilities without additional software or\\nmodalities. Accounting for other generative models and complementary technologies, our human estimates\\nindicate that up to 49% of workers could have half or more of their tasks exposed to LLMs.\\nOur ﬁndings consistently show across both human and GPT-4 annotations that most occupations exhibit\\nsome degree of exposure to LLMs, with varying exposure levels across di ﬀerent types of work. Occupations\\nwith higher wages generally present with higher exposure, a result contrary to similar evaluations of overall\\nexposure to machine learning (Brynjolfsson et al., 2023). When regressing exposure measures on skillsets\\nusing O*NET’s skill rubric, we discover that roles heavily reliant on science and critical thinking skills show\\na negative correlation with exposure, while programming and writing skills are positively associated with\\nLLM exposure. Following Autor et al. (2022a), we examine barriers to entry by \"Job Zones\" and ﬁnd that\\noccupational exposure to LLMs weakly increases with the di ﬃculty of job preparation. In other words,\\nworkers facing higher (lower) barriers to entry in their jobs tend to experience more (less) exposure to LLMs.\\nWe further compare our measurements to previous e ﬀorts documenting the distribution of automation\\nexposure in the economy and ﬁnd broadly consistent results. Most other technology exposure measures we\\nexamine are statistically signiﬁcantly correlated with our preferred exposure measure, while measures of\\nmanual routineness and robotics exposure show negative correlations. The variance explained by these earlier\\neﬀorts (Acemoglu and Autor, 2011a; Frey and Osborne, 2017; Brynjolfsson et al., 2018; Felten et al., 2018;\\nWebb, 2020; Brynjolfsson et al., 2023), along with wage controls, ranges from 60 to 72%, indicating that 28\\nto 40% of the variation in our AI exposure measure remains unaccounted for by previous technology exposure\\nmeasurements.\\nWe analyze exposure by industry and discover that information processing industries (4-digit NAICS)\\nexhibit high exposure, while manufacturing,'),\n",
       " Document(page_content='njolfsson et al., 2018; Felten et al., 2018;\\nWebb, 2020; Brynjolfsson et al., 2023), along with wage controls, ranges from 60 to 72%, indicating that 28\\nto 40% of the variation in our AI exposure measure remains unaccounted for by previous technology exposure\\nmeasurements.\\nWe analyze exposure by industry and discover that information processing industries (4-digit NAICS)\\nexhibit high exposure, while manufacturing, agriculture, and mining demonstrate lower exposure. The\\nconnection between productivity growth in the past decade and overall LLM exposure appears weak, suggesting\\na potential optimistic case that future productivity gains from LLMs may not exacerbate possible cost disease\\neﬀects (Baumol, 2012; Aghion et al., 2018). 3\\nOur analysis indicates that the impacts of LLMs like GPT-4, are likely to be pervasive. While LLMs\\nhave consistently improved in capabilities over time, their growing economic e ﬀect is expected to persist and\\nincrease even if we halt the development of new capabilities today. We also ﬁnd that the potential impact of\\nLLMs expands signiﬁcantly when we take into account the development of complementary technologies.\\nCollectively, these characteristics imply that Generative Pre-trained Transformers (GPTs) are general-purpose\\ntechnologies (GPTs). 4(Bresnahan and Trajtenberg, 1995; Lipsey et al., 2005).\\n(Goldfarb et al., 2023) argue that machine learning as a broad category is likely a general-purpose\\ntechnology. Our evidence supports a wider impact, as even subsets of machine learning software meet thetechnology. Our evidence supports a wider impact, as even subsets of machine learning software meet the\\ncriteria for general-purpose technology status independently. This paper’s primary contributions are to provide\\na set of measurements of LLM impact potential and to demonstrate the use case of applying LLMs to develop\\nsuch measurements e ﬃciently and at scale. Additionally, we showcase the general-purpose potential of LLMs.\\nIf \"GPTs are GPTs,\" the eventual trajectory of LLM development and application may be challenging for\\n3Baumol’s cost disease is a theory that explains why the cost of labor-intensive services, such as healthcare and education,\\nincreases over time. This happens because wages for skilled workers in other industries increase, but there is no corresponding\\nincrease in productivity or e ﬃciency in these service industries. Therefore, the cost of labor in these industries becomes relatively\\nmore expensive compared to other goods and services in the economy.\\n4For the remainder of the paper we spell out general-purpose technologies when it is used outside of stating \"GPTs are GPTs.\"WORKING PAPER\\npolicymakers to predict and regulate. As with other general-purpose technologies, much of these algorithms’\\npotential will emerge across a broad range of economically valuable use cases, including the creation of new\\ntypes of work (Acemoglu and Restrepo, 2018; Autor et al., 2022a). Our research serves to measure what is\\ntechnically feasible now, but necessarily will miss the evolving impact potential of the LLMs over time.\\nThe paper is structured as follows: Section 2 reviews relevant prior work, Section 3 discusses methods\\nand data collection, Section 4 presents summary statistics and results, Section 5 relates our measurements to\\nearlier e ﬀorts, Section 6 discusses the results, and Section 7 o ﬀers concluding remarks.\\n2 Literature Review\\n2.1 The Advancement of Large Language Models\\nIn recent years, generative AI models have gained signiﬁcant attention from both the artiﬁcial intelligence\\n(AI) research community and the general public, due to their ability to tackle a wide array of complex\\nlanguage-based tasks. The progress in these models’ abilities has been fueled by multiple factors, including\\nincreased model parameter count, greater training data volume, and enhanced training conﬁgurations (Brown\\net al., 2020; Radford et al., 2019; Hernandez et al., 2021; Kaplan et al., 2020). Broad, state-of-the-art LLMs,\\nsuch as LaMDA (Thoppilan et al., 2022) and GPT-4 (OpenAI, 2023b), excel in diverse applications like\\ntranslation, classiﬁcation, creative writing, and code generation—capabilities that previously demanded\\nspecialized, task-speciﬁc models developed by expert engineers using domain-speciﬁc data.\\nConcurrently, researchers have improved the steerability, reliability, and utility of these models using\\nmethods like ﬁne-tuning and reinforcement'),\n",
       " Document(page_content=' and GPT-4 (OpenAI, 2023b), excel in diverse applications like\\ntranslation, classiﬁcation, creative writing, and code generation—capabilities that previously demanded\\nspecialized, task-speciﬁc models developed by expert engineers using domain-speciﬁc data.\\nConcurrently, researchers have improved the steerability, reliability, and utility of these models using\\nmethods like ﬁne-tuning and reinforcement learning with human feedback (Ouyang et al., 2022; Bai et al.,\\n2022). These advancements enhance the models’ ability to discern user intent, rendering them more\\nuser-friendly and practical. Moreover, recent studies reveal the potential of LLMs to program and control\\nother digital tools, such as APIs, search engines, and even other generative AI systems (Schick et al., 2023;\\nMialon et al., 2023; Chase, 2022). This enables seamless integration of individual components for better\\nutility, performance, and generalization. At their limit, these trends suggest a world where LLMs may be\\ncapable of executing any task typically performed at a computer.\\nGenerative AI models have mostly been deployed as modular specialists, performing speciﬁc tasks such as\\ngenerating images from captions or transcribing text from speech. However, we argue that it is essential to view\\nLLMs as versatile building blocks for creating additional tools. Developing these tools and integrating them\\ninto systems will require time and possibly signiﬁcant reconﬁguration of existing processes across various\\nindustries. Nevertheless, we are already witnessing emerging adoption trends. Despite their limitations,\\nLLMs are increasingly being integrated into specialized applications in ﬁelds like writing assistance, coding,\\nand legal research. These specialized applications then allow businesses and individuals to adopt LLMs into\\ntheir workﬂows.\\nWe emphasize the signiﬁcance of these complementary technologies, partly because out-of-the-box\\ngeneral-purpose LLMs may continue to be unreliable for various tasks due to issues such as factual inaccuracies,\\ninherent biases, privacy concerns, and disinformation risks (Abid et al., 2021; Schramowski et al., 2022;\\nGoldstein et al., 2023; OpenAI, 2023a). However, specialized workﬂows—including tooling, software, or\\nhuman-in-the-loop systems—can help address these shortcomings by incorporating domain-speciﬁc expertise.\\nFor example, Casetext o ﬀers LLM-based legal research tools that provide lawyers with quicker and more\\naccurate legal research results, utilizing embeddings and summarization to counter the risk that GPT-4 couldaccurate legal research results, utilizing embeddings and summarization to counter the risk that GPT-4 could\\nprovide inaccurate details about a legal case or set of documents. GitHub Copilot is a coding assistant that\\nemploys LLMs to generate code snippets and auto-complete code, which users can then accept or reject based\\non their expertise. In other words, while it’s true that on its own GPT-4 does not \"know what time it is,\" it’s\\neasy enough to give it a watch.WORKING PAPER\\nFurthermore, a positive feedback loop may emerge as LLMs surpass a speciﬁc performance threshold,\\nallowing them to assist in building the very tooling that enhances their usefulness and usability across various\\ncontexts. This could lower the cost and engineering expertise required to create such tools, potentially\\naccelerating LLM adoption and integration even further (Chen et al., 2021; Peng et al., 2023). LLMs can also\\nbecome valuable assets in machine learning model development—serving as coding assistants for researchers,\\ndata labeling services, or synthetic data generators. There is potential for such models to contribute to\\neconomic decision-making at the task level, for instance, by reﬁning methods for task and sub-task allocation\\nbetween humans and machines (Singla et al., 2015; Shahaf and Horvitz, 2010). As LLMs advance over time\\nand better align with user preferences, we can anticipate continuous improvement in performance. However, it\\nis essential to recognize that these trends also bring a variety of serious risks. (Khlaaf et al., 2022; Weidinger\\net al., 2022; Solaiman et al., 2019)\\n2.2 The Economic Impacts of Automation Technologies\\nA large and growing body of literature addresses the labor market impacts of AI and automation technologies.\\nThe concept of skill-biased technological change and the task model of automation—often considered\\nthe standard framework for understanding technology’s inﬂuence on labor—originated from research\\n'),\n",
       " Document(page_content=' risks. (Khlaaf et al., 2022; Weidinger\\net al., 2022; Solaiman et al., 2019)\\n2.2 The Economic Impacts of Automation Technologies\\nA large and growing body of literature addresses the labor market impacts of AI and automation technologies.\\nThe concept of skill-biased technological change and the task model of automation—often considered\\nthe standard framework for understanding technology’s inﬂuence on labor—originated from research\\ndemonstrating that technological progress raises the demand for skilled workers over unskilled workers (Katz\\nand Murphy, 1992). Numerous studies have built upon this concept, exploring the e ﬀects of technological\\nchange and automation on workers within a task-based framework (Autor et al., 2003; Acemoglu and Autor,\\n2011b; Acemoglu and Restrepo, 2018). This strand of research has shown that workers involved in routine and\\nrepetitive tasks are at a higher risk of technology-driven displacement, a phenomenon known as routine-biased\\ntechnological change. More recent studies have distinguished between technology’s task-displacement and\\ntask-reinstatement e ﬀects (where new technology increases the need for a wider array of labor-intensive tasks)\\n(Acemoglu and Restrepo, 2018, 2019). Several studies have shown that automation technologies have resulted\\nin wage inequality in the US, driven by relative wage declines for workers specializing in routine tasks (Autor\\net al., 2006; Van Reenen, 2011; Acemoglu and Restrepo, 2022b).\\nPrior research has employed various approaches to estimate the overlap between AI capabilities and\\nthe tasks and activities workers undertake in di ﬀerent occupations. These methods include mapping patent\\ndescriptions to worker task descriptions (Webb, 2020; Meindl et al., 2021), linking AI capabilities to\\noccupational abilities documented in the O*NET database (Felten et al., 2018, 2023), aligning AI task\\nbenchmark evaluations with worker tasks via cognitive abilities (Tolan et al., 2021), labeling automation\\npotential for a subset of US occupations and using machine learning classiﬁers to estimate this potential for\\nall other US occupations (Frey and Osborne, 2017), modeling task-level automation and aggregating the\\nresults to occupation-level insights (Arntz et al., 2017), collecting expert forecasts (Grace et al., 2018), and\\nmost relevantly to this paper, devising a new rubric to assess worker activities for their suitability for machine\\nlearning (Brynjolfsson et al., 2018, 2023). Some of these approaches have found exposure to AI technologies\\nat the task-level tends to be diversiﬁed within occupation. Considering each job as a bundle of tasks, it would\\nbe rare to ﬁnd any occupation for which AI tools could do nearly all of the work. (Autor et al., 2022a) ﬁnds as\\nwell that automation and augmentation exposures tend to be positively correlated. There is also a growing setwell that automation and augmentation exposures tend to be positively correlated. There is also a growing set\\nof studies examining speciﬁc economic impacts and opportunities for LLMs (Bommasani et al., 2021; Felten\\net al., 2023; Korinek, 2023; Mollick and Mollick, 2022; Noy and Zhang, 2023; Peng et al., 2023). Alongside\\nthis work, our measurements help characterize the broader potential relevance of language models to the\\nlabor market.\\nGeneral-purpose technologies (e.g. printing, the steam engine) are characterized by widespread prolifera-\\ntion, continuous improvement, and the generation of complementary innovations (Bresnahan and Trajtenberg,\\n1995; Lipsey et al., 2005). Their far-reaching consequences, which unfold over decades, are di ﬃcult to\\nanticipate, particularly in relation to labor demand (Bessen, 2018; Korinek and Stiglitz, 2018; Acemoglu et al.,WORKING PAPER\\n2020; Benzell et al., 2021). The realization of general purpose technologies’ full potential requires extensive\\nco-invention (Bresnahan and Trajtenberg, 1995; Bresnahan et al., 1996, 2002; Lipsey et al., 2005; Dixon et al.,\\n2021), a costly and time-consuming process involving the discovery of new business procedures (David, 1990;\\nBresnahan, 1999; Frey, 2019; Brynjolfsson et al., 2021; Feigenbaum and Gross, 2021). Consequently, many\\nstudies of machine learning technologies focus on systems-level adoption, arguing that organizational systems\\nmay require redesign to e �'),\n",
       " Document(page_content='ahan et al., 1996, 2002; Lipsey et al., 2005; Dixon et al.,\\n2021), a costly and time-consuming process involving the discovery of new business procedures (David, 1990;\\nBresnahan, 1999; Frey, 2019; Brynjolfsson et al., 2021; Feigenbaum and Gross, 2021). Consequently, many\\nstudies of machine learning technologies focus on systems-level adoption, arguing that organizational systems\\nmay require redesign to e ﬀectively take advantage of novel machine learning advancements (Bresnahan,\\n2019; Agrawal et al., 2021; Goldfarb et al., 2023). Appropriately designed systems can yield considerable\\nbusiness value and improve ﬁrm performance (Rock, 2019; Babina et al., 2021; Zolas et al., 2021), with AI\\ntools facilitating the discovery process (Cockburn et al., 2018; Cheng et al., 2022). By employing task-level\\ninformation to assess whether LLMs fulﬁll the criteria of a general purpose technology, we seek to merge the\\ntwo perspectives for understanding the technology-labor relationship.\\nWe attempt to build on these diverse literature streams in several ways. Echoing (Felten et al., 2023), we\\nfocus our analysis on the impact of LLMs, rather than addressing machine learning or automation technologies\\nmore broadly. Additionally, we propose a novel method that employs LLMs, speciﬁcally GPT-4, to assess tasks\\nfor exposure and automation potential, thereby bolstering human scoring e ﬀorts. Subsequently, we aggregate\\nour ﬁndings to occupations and industries, capturing the overall potential exposure in the contemporary U.S.\\nlabor market.\\n3 Methods and Data Collection\\n3.1 Data on Activities and Tasks Performed by Occupation in the US\\nWe use the O*NET 27.2 database (O*NET, 2023), which contains information on 1,016 occupations, including\\ntheir respective Detailed Work Activities (DWAs) and tasks. A DWA is a comprehensive action that is part of\\ncompleting task, such as \"Study scripts to determine project requirements.\" A task, on the other hand, is an\\noccupation-speciﬁc unit of work that may be associated with zero, one, or multiple DWAs. We o ﬀer a sample\\nof tasks and DWAs in Table 1. The two datasets we use consist of:\\n•19,265 tasks, consisting of a \"task description\" and a corresponding occupation, and\\n•2,087 DWAs, where most DWAs are connected to one or more tasks, and tasks may be associated with\\none or more DWAs, though some tasks lack any associated DWAs.\\n3.2 Data on Wages, Employment, and Demographics\\nWe obtain employment and wage data from the 2020 and 2021 Occupational Employment series provided by\\nthe Bureau of Labor Statistics. This dataset encompasses occupational titles, the number of workers in each\\noccupation, and occupation-level employment projections for 2031, typical education required for entry in an\\noccupation and on-the-job training required to attain competency in an occupation (BLS, 2022). We use the\\nBLS-recommended crosswalk to O*NET (BLS, 2023b) to link the O*NET task and DWA dataset and the\\nBLS Labor Force Demographics (BLS, 2023a), which is derived from the Current Population Survey (CPS).\\nBoth of these data sources are collected by the U.S. government and primarily capture workers who are not\\nself-employed, are documented, and are working in the so-called formal economy.\\n3.3 Exposure\\nWe present our results based on an exposure rubric, in which we deﬁne exposure as a measure of whether\\naccess to an LLM or LLM-powered system would reduce the time required for a human to perform a speciﬁcWORKING PAPER\\nTask ID Occupation Title DWAs Task Description\\n14675 Computer Systems\\nEngineers/ArchitectsMonitor computer system performance\\nto ensure proper operation.Monitor system operation to detect potential\\nproblems.\\n18310 Acute Care Nurses Operate diagnostic or therapeutic\\nmedical instruments or equipment.\\nPrepare medical supplies or equipment\\nfor use.Set up, operate, or monitor invasive equipment\\nand devices, such as colostomy or tracheotomy\\nequipment, mechanical ventilators, catheters,\\ngastrointestinal tubes, and central lines.\\n4668.0 Gambling Cage\\nWorkersExecute sales or other ﬁnancial\\ntransactions.Cash checks and process credit card advances\\nfor patrons.\\n15709 Online Merchants Execute sales or other ﬁnancial\\ntransactions.Deliver'),\n",
       " Document(page_content=' operate, or monitor invasive equipment\\nand devices, such as colostomy or tracheotomy\\nequipment, mechanical ventilators, catheters,\\ngastrointestinal tubes, and central lines.\\n4668.0 Gambling Cage\\nWorkersExecute sales or other ﬁnancial\\ntransactions.Cash checks and process credit card advances\\nfor patrons.\\n15709 Online Merchants Execute sales or other ﬁnancial\\ntransactions.Deliver e-mail conﬁrmation of completed\\ntransactions and shipment.\\n6529 Kindergarten\\nTeachers, Except\\nSpecial Education– Involve parent volunteers and older students in\\nchildren’s activities to facilitate involvement in\\nfocused, complex play.\\n6568 Elementary School\\nTeachers, Except\\nSpecial Education– Involve parent volunteers and older students in\\nchildren’s activities to facilitate involvement in\\nfocused, complex play.\\nTable 1: Sample of occupations, tasks, and Detailed Work Activities from the O*NET database. We see\\nthat aggregating over activities alone is imprecise, as evidenced by the fact that we’d expect Gambling Cage\\nWorkers to complete the given DWA in person, using some physicality while we’d expect Online Merchants\\nto complete the same activity solely with a computer.\\nDWA or complete a task by at least 50 percent. Though GPT-4 has vision capabilities OpenAI (2023b) and\\n\"LLM\" is often used to refer to a much wider range of modalities, vision and image capabilities were only\\nincluded in our deﬁnition of LLM-powered software. We provide a summary of our rubric below, while the\\ncomplete rubric can be found in A.1. When we have labels for DWAs, we ﬁrst aggregate them to the task\\nlevel before aggregating to the occupation level.\\nNo exposure (E0) if:\\n•using the described LLM results in no or minimal reduction in the time required to\\ncomplete the activity or task while maintaining equivalent qualityaor\\n•using the described LLM results in a decrease in the quality of the activity/task output.\\nDirect exposure (E1) if:\\n•using the described LLM via ChatGPT or the OpenAI playground can decrease the time\\nrequired to complete the DWA or task by at least half (50%).\\nLLM+ Exposed (E2) if:\\n•access to the described LLM alone would not reduce the time required to complete the\\nactivity/task by at least half, but\\n•additional software could be developed on top of the LLM that could reduce the time it\\ntakes to complete the speciﬁc activity/task with quality by at least half. Among these\\nsystems, we count access to image generation systems.b\\naEquivalent quality means that a third party, typically the recipient of the output, would not notice or\\ncare about LLM assistance.\\nbIn practice, as can be seen in the full rubric in Appendix A.1, we categorize access to image capabilities\\nseparately (E3) to facilitate annotation, though we combine E2 and E3 for all analyses.Summary of exposure rubric\\nWe set the exposure threshold at a potential 50% reduction in time required to complete a speciﬁc DWAWORKING PAPER\\nor task while maintaining consistent quality. We anticipate that adoption will be highest and most immediate\\nfor applications that realize a considerable increase in productivity. Although this threshold is somewhat\\narbitrary, it was selected for ease of interpretation by annotators. Moreover, regardless of the chosen threshold,\\nwe guessed that the real-world reduction in task time would likely be slightly or signiﬁcantly lower than our\\nestimates, leading us to opt for a relatively high threshold. In our own validation labeling, we found that this\\ncorresponded closely to whether an LLM or LLM-powered software could perform the core part of a task or\\nnearly the entire task.\\nComparison WWeighting Agreement Pearson’s\\nGPT-4, Rubric 1; Human UE1 80.8% 0.223\\nVE1 + .5*E2 65.6% 0.591\\nZE1 + E2 82.1% 0.654\\nGPT-4, Rubric 2; Human UE1 81.8% 0.221\\nVE1 + .5*E2 65.6% 0.538\\nZE1 + E2 79.5% 0.589\\nGPT-4, Rubric 1; GPT-4, Rubric 2 UE1 91.1% 0.611\\nVE1 + .5*E2 76.0% 0.705\\nZE1 + E2 82.4'),\n",
       " Document(page_content='PT-4, Rubric 2; Human UE1 81.8% 0.221\\nVE1 + .5*E2 65.6% 0.538\\nZE1 + E2 79.5% 0.589\\nGPT-4, Rubric 1; GPT-4, Rubric 2 UE1 91.1% 0.611\\nVE1 + .5*E2 76.0% 0.705\\nZE1 + E2 82.4% 0.680\\nTable 2: Model and human comparison of agreement and Pearson’s correlation scores. The agreement score\\nis determined by looking at how often the two groups agree on the annotation (e.g. E0, E1 or E2). In the\\npaper we use GPT-4, Rubric 1. Core tasks are given twice the weight at the occupation-level as supplemental\\ntasks. All weights sum to one.\\nWe then collected both human and GPT-4-generated annotations using the exposure rubric, which underlie\\nthe bulk of the analyses in this paper.\\n•Human Ratings: We obtained human annotations by applying the rubric to each O*NET Detailed\\nWorker Activity (DWA) and a subset of all O*NET tasks and then aggregated those DWA and task\\nscores 5at the task and occupation levels. The authors personally labeled a large sample of tasks and\\nDWAs and enlisted experienced human annotators who have reviewed GPT-3, GPT-3.5 and GPT-4\\noutputs as part of OpenAI’s alignment work (Ouyang et al., 2022).\\n•GPT-4 Ratings: We administered a similar rubric to an early version of GPT-4 (OpenAI, 2023b) but on\\nall task/occupation pairs rather than DWAs. We made slight modiﬁcations to the rubric (which was\\nused as a \"prompt\" to the model in this case) to enhance agreement with a set of human labels. Full\\nagreement rates are given in Table 2.\\nWe construct three primary measures for our dependent variable of interest: (i) U, corresponding to E1 in\\nthe exposure rubric above, anticipated to represent the lower bound of the proportion of exposed tasks within\\nan occupation, (ii) V, which is the sum of E1 and 0.5*E2, where the 0.5 weight on E2 is intended to account\\nfor exposure when deploying the technology via complementary tools and applications necessitates additional\\ninvestment, and (iii) Z, the sum of E1 and E2, an upper bound of exposure that provides an assessment of\\nmaximal exposure to an LLLM and LLM-powered software. We summarize agreement between annotation\\ngroups and measures in Table 2. For the remainder of the analysis, if not speciﬁed, the reader may assume that\\n5The authors annotated DWAs that clearly required a high degree of physicality or manual dexterity, and the contracted annotators\\nlabeled the remaining activities, along with a subset of tasks including those without associated DWAs and those for which there was\\nno clear task-level annotation after aggregating the DWA annotations.WORKING PAPER\\nwe refer to Vexposure – meaning all tasks directly exposed via tools like ChatGPT or the OpenAI Playground\\nare considered twice as exposed as tasks requiring some complementary innovation.\\n3.4 Limitations of our methodology\\n3.4.1 Subjective human judgments\\nA fundamental limitation of our approach lies in the subjectivity of the labeling. In our study, we employ\\nannotators who are familiar with LLM capabilities. However, this group is not occupationally diverse,\\npotentially leading to biased judgments regarding LLMs’ reliability and e ﬀectiveness in performing tasks\\nwithin unfamiliar occupations. We acknowledge that obtaining high-quality labels for each task in an\\noccupation requires workers engaged in those occupations or, at a minimum, possessing in-depth knowledge\\nof the diverse tasks within those occupations. This represents an important area for future work in validating\\nthese results.\\n3.4.2 Measuring LLMs with GPT-4\\nRecent research indicates that GPT-4 serves as an e ﬀective discriminator, capable of applying intricate\\ntaxonomies and responding to changes in wording and emphasis (OpenAI, 2023b). The outcomes of GPT-4\\ntask classiﬁcation are sensitive to alterations in the rubric’s wording, the prompt’s order and composition, the\\npresence or absence of speciﬁc examples in the rubric, the level of detail provided, and the deﬁnitions given\\nfor key terms. Iterating on the prompt, based on observed outcomes in a small validation set, can'),\n",
       " Document(page_content='OpenAI, 2023b). The outcomes of GPT-4\\ntask classiﬁcation are sensitive to alterations in the rubric’s wording, the prompt’s order and composition, the\\npresence or absence of speciﬁc examples in the rubric, the level of detail provided, and the deﬁnitions given\\nfor key terms. Iterating on the prompt, based on observed outcomes in a small validation set, can enhance the\\nagreement between model outputs and the rubric’s intent. Consequently, there are slight di ﬀerences between\\nthe rubric presented to humans and the one used for GPT-4. This decision was made deliberately to guide\\nthe model towards reasonable labels without excessively inﬂuencing human annotators. As a result, we use\\nmultiple annotation sources, but none should be considered the deﬁnitive ground truth relative to the others.\\nIn this analysis, we present results from human annotators as our primary results. Further improvement and\\ninnovation in crafting e ﬀective rubrics for LLM classiﬁcation remains possible. Still, we observe a high\\ndegree of agreement between human ratings and GPT-4 ratings at the occupation level concerning overall\\nexposure to LLM systems (see Table 2, Figure 2).\\n3.4.3 Additional Weaknesses\\n•Validity of task-based framework. It is unclear to what extent occupations can be entirely broken\\ndown into tasks, and whether this approach systematically omits certain categories of skills or tasks\\nthat are tacitly required for competent performance of a job. Additionally, tasks can be composed of\\nsub-tasks, some of which are more automatable than others. Some tasks may function as pre-cursor to\\nother tasks, such that the completion of downstream tasks is dependent on precursor tasks. If indeed,\\nthe task-based breakdown is not a valid representation of how most work in an occupation is performed,\\nour exposure analysis would largely be invalidated.\\n•Lack of expertise and task interpretation. Human annotators were mostly unaware of the speciﬁc\\noccupations mapped to each DWA during the labeling process. This led to unclear logic for aggregating\\ntasks and occupations, as well as some evident discrepancies in labels, demonstrated in Table 1. We\\nexperimented with various aggregation methods and discovered that even with a maximum-matching\\napproach (taking the matching human<>model label if one existed), the agreement remained relatively\\nconsistent. Ultimately, we collected additional labels for task/occupation pairs where there was\\nsigniﬁcant disagreement.WORKING PAPER\\nFigure 2: Human raters (x-axis) and GPT-4 ratings (y-axis) show a high degree of agreement about LLM\\nexposure by occupation. We compute occupation-level exposure in these ﬁgures by averaging the task-level\\nexposures under the Vmethod. O*NET designates some tasks as \"core\" and others \"supplemental\". Core\\ntasks are given twice the weight of supplemental tasks, and all weights sum to one. Near the highest levels of\\nexposure following the Vmethod of aggregating exposure scores to occupations, GPT-4 ratings tend to be\\nlower than Human ratings. We present the raw scatter plot and the binscatter. Near the top end of exposure\\nratings, humans are on average more likely to rate an occupation as exposed.\\n•Forward-looking and subject to change, with some early evidence. Accurately predicting future\\nLLM applications remains a signiﬁcant challenge, even for experts (OpenAI, 2023b). The discovery of\\nnew emergent capabilities, changes in human perception biases, and shifts in technological development\\ncan all a ﬀect the accuracy and reliability of predictions regarding the potential impact of LLMs\\non worker tasks and the development of LLM-powered software. Our projections are inherently\\nforward-looking and based on current trends, evidence, and perceptions of technological possibilities.\\nAs a result, they may change as new advancements arise in the ﬁeld. For example, some tasks that\\nseem unlikely for LLMs or LLM-powered software to impact today might change with the introduction\\nof new model capabilities. Conversely, tasks that appear exposed might face unforeseen challenges\\nlimiting language model applications.\\n•Sources of disagreement. While we did not rigorously examine sources of disagreement, we found a\\nfew places where humans and the model tended to get \"stuck\" in their assessments:\\n–Tasks or activities where while an LLM could theoretically help or accomplish the task, adopting\\nit to do so would require multiple people to change their habits or expectations (e.g. meetings,\\nnegotiations),\\n–Tasks or'),\n",
       " Document(page_content=' unforeseen challenges\\nlimiting language model applications.\\n•Sources of disagreement. While we did not rigorously examine sources of disagreement, we found a\\nfew places where humans and the model tended to get \"stuck\" in their assessments:\\n–Tasks or activities where while an LLM could theoretically help or accomplish the task, adopting\\nit to do so would require multiple people to change their habits or expectations (e.g. meetings,\\nnegotiations),\\n–Tasks or activities where there is currently some regulation or norm that requires or suggests\\nhuman oversight, judgment or empathy (e.g. making decisions, counseling), and\\n–Tasks or activities where there already exists a technology that can reasonably automate the task\\n(e.g. making reservations).\\n4 Results\\nGeneral-purpose technologies are relatively rare and characterized by their pervasiveness, improvement over\\ntime, and the development of signiﬁcant co-invention and spillovers (Lipsey et al., 2005). Our assessment ofWORKING PAPER\\nLLMs’ potential impact on the labor market is limited since it does not consider total factor productivity or\\ncapital input potential. In addition to their inﬂuence on labor, LLMs may also inﬂuence these dimensions.\\nAt this stage, some general-purpose technology criteria are easier to evaluate than others. Our primary\\nfocus at this early stage is to test the hypothesis that LLMs have a pervasive inﬂuence on the economy,\\nsimilar to the approach taken by (Goldfarb et al., 2023), who analyzed machine learning di ﬀusion through\\njob postings to assess its status as a general-purpose technology. Instead of using job postings or studying\\nmachine learning in general, we employ the task evaluation approach with both human and GPT-4 annotations.\\nThis analysis may reveal whether the impacts are limited to a speciﬁc set of similar tasks or occupations or if\\nthey will be more widespread.\\nOur ﬁndings suggest that, based on their task-level capabilities, LLMs have the potential to signiﬁcantly\\naﬀect a diverse range of occupations within the U.S. economy, demonstrating a key attribute of general-purpose\\ntechnologies. In the following sections, we discuss results across various roles and wage structures. Additional\\nresults on the relative exposure of industries within the U.S. economy can be found in Appendix C.\\n4.1 Summary Statistics\\nSummary statistics for these measures can be found in Table 3. Both human and GPT-4 annotations indicate\\nthat average occupation-level Uvalues fall between 0.14 and 0.15, suggesting that, on average, approximately\\n15% of tasks within an occupation are directly exposed to LLMs. 6This ﬁgure increases to over 30% for V\\nand surpasses 50% for Z. Coincidentally, human and GPT-4 annotations also tag between 15% and 14% of\\ntotal tasks in the dataset as being exposed to LLMs. Based on the Vvalues, we estimate that 80% of workers\\nbelong to an occupation with at least 10% of its tasks exposed to LLMs, while 19% of workers are in an\\noccupation where over half of its tasks are labeled as exposed.\\nWe ran one set of analyses using O*NET’s \"Importance\" scores but did not ﬁnd signiﬁcant changes to our\\nﬁndings. Though we do acknowledge that not weighting relative importance of a task to a given occupation\\nyields some curious results (e.g. ranking Barbers as having reasonably high exposure).\\nAlthough the potential for tasks to be a ﬀected is vast, LLMs and LLM-powered software must be\\nincorporated into broader systems to fully realize this potential. As is common with general-purpose\\ntechnologies, co-invention barriers may initially impede the rapid di ﬀusion of GPTs into economic applications.\\nFurthermore, predicting the need for human oversight is challenging, especially for tasks where model\\ncapabilities equal or surpass human levels. While the requirement for human supervision may initially slow\\ndown the speed at which these systems di ﬀuse through the economy, users of LLMs and LLM-powered\\nsystems are likely to become increasingly acquainted with the technology over time, particularly in terms of\\nunderstanding when and how to trust its outputs.\\n4.2 Wages and Employment\\nIn Figure 3, we present exposure intensity across the economy. Each point on the plot displays occupational\\nexposure, where the point’s x-axis value represents the share of an occupation’s tasks that are exposed (at\\neach level U,V, and Z) and the point’s y-axis value represents the share of all'),\n",
       " Document(page_content=' over time, particularly in terms of\\nunderstanding when and how to trust its outputs.\\n4.2 Wages and Employment\\nIn Figure 3, we present exposure intensity across the economy. Each point on the plot displays occupational\\nexposure, where the point’s x-axis value represents the share of an occupation’s tasks that are exposed (at\\neach level U,V, and Z) and the point’s y-axis value represents the share of all US occupations with that share\\nof tasks exposed. For example, human annotators determined that 2.3% of occupations are U50-exposed,\\n21.6% are V50-exposed, and 47.3% are Z50-exposed, where the threshold of 50% comes from the x-axis and\\nthe percentage of occupations comes from the y axis. At any given point on the x-axis, the vertical distance\\nbetween the Uand the Zrepresents the exposure potential attributable to tools and applications beyond direct\\nexposure to LLMs. All tasks within an occupation in this ﬁgure are given equal weight.between the Uand the Zrepresents the exposure potential attributable to tools and applications beyond direct\\nexposure to LLMs. All tasks within an occupation in this ﬁgure are given equal weight.\\n6We compute occupation-level scores for Table 3 assigning double the weight to tasks designated as \"core\" by O*NET as tasks\\ndesignated \"supplemental\". All tasks weights sum to one within an occupation.WORKING PAPER\\nOccupation Level Exposure\\nHuman GPT-4\\nmean std mean std\\nUUU0.14 0.14 0.14 0.16\\nVVV0.30 0.21 0.34 0.22\\nZZZ0.46 0.30 0.55 0.34\\nTask Level Exposure\\nHuman GPT-4\\nmean std mean std\\nUUU0.15 0.36 0.14 0.35\\nVVV0.31 0.37 0.35 0.35\\nZZZ0.47 0.50 0.56 0.50\\nTable 3: Summary statistics of our human and model exposure data. Tasks designated as core tasks for an\\noccupation are given twice the weight as those indicated to be supplemental in the O*NET task ﬁle.\\nFigure 3: Exposure intensity across the economy, displayed in terms of percent of a ﬀected occupations. A\\ngiven data point gives the percent of occupations with exposure below the given threshold. A previous version\\nof this paper had two labels reversed in the chart, ﬂipping human and model responses. In this ﬁgure, all tasks\\nwithin an occupation are given equal weight.\\nAggregated at the occupation level, human and GPT-4 annotations exhibit qualitative similarities and\\ntend to correlate, as demonstrated in Figure 4. Human annotations estimate marginally lower exposure for\\nhigh-wage occupations compared to GPT-4 annotations. While there are numerous low-wage occupations\\nwith high exposure and high-wage occupations with low exposure, the overall trend in the binscatter plot\\nreveals that higher wages are associated with increased exposure to LLMs. 7\\nThe potential exposure to LLMs seems to have little correlation with current employment levels. In\\nFigure 4, both human and GPT-4 ratings of overall exposure are aggregated to the occupation-level (y-axis)\\nand compared with the log of total employment (x-axis). Neither plot reveals signiﬁcant di ﬀerences in LLM\\nexposure across varying employment levels.\\n7In aggregating tasks to the occupation-level, we assign half the weight to O*NET supplemental tasks as we do for core tasks.WORKING PAPER\\nFigure 4: The binscatter plots depict the exposure to language models (LLMs) in various occupations, as\\nassessed by both human evaluators and GPT-4. These plots compare the exposure to LLM and partial\\nLLM-powered software ( V) at the occupation level against the log of total employment within an occupation\\nand log of the median annual wage for occupations. While some discrepancies exist, both human and GPT-4\\nassessments indicate that higher wage occupations tend to be more exposed to LLMs. Additionally, numerous\\nlower wage occupations demonstrate high exposure based on our rubric. Core tasks receive twice the weight of\\nsupplemental tasks within occupations when calculating average exposure scores. Employment and wage data\\nare sourced from the BLS-OES survey conducted in May 2021. In aggregating tasks to the occupation-level,\\nwe assign half the weight to O*NET supplemental tasks as we do for core tasks. All weights within an\\noccupation sum to one.WORKING PAPER\\n4.3 Skill Importance\\nIn this section'),\n",
       " Document(page_content=' our rubric. Core tasks receive twice the weight of\\nsupplemental tasks within occupations when calculating average exposure scores. Employment and wage data\\nare sourced from the BLS-OES survey conducted in May 2021. In aggregating tasks to the occupation-level,\\nwe assign half the weight to O*NET supplemental tasks as we do for core tasks. All weights within an\\noccupation sum to one.WORKING PAPER\\n4.3 Skill Importance\\nIn this section, we explore the relationship between the importance of a skill for an occupation (as annotated\\nin the O*NET dataset) and our exposure measures. First, we use the Basic Skills provided by O*NET (skill\\ndeﬁnitions can be found in Appendix B) and normalize the measure of skill importance for each occupation\\nto improve the comprehensibility of the results. Next, we conduct a regression analysis on our exposure\\nmeasures ( U,V,Z) to examine the strength of associations between skill importance and exposure.\\nOur ﬁndings indicate that the importance of science andcritical thinking skills are strongly negatively\\nassociated with exposure, suggesting that occupations requiring these skills are less likely to be impacted\\nby current LLMs. Conversely, programming andwriting skills show a strong positive association with\\nexposure, implying that occupations involving these skills are more susceptible to being inﬂuenced by LLMs\\n(see Table 5 for detailed results).\\n4.4 Barriers to Entry\\nNext, we examine barriers to entry to better understand if there is di ﬀerentiation in exposure due to types of\\njobs. One such proxy is an O*NET occupation-level descriptor called the \"Job Zone.\" A Job Zone groups\\noccupations that are similar in (a) the level of education needed to get a job in the occupation, (b) the amount\\nof related experience required to do the work, and (c) the extent of on-the-job training needed to do the work.\\nIn the O*NET database, there are 5 Job Zones, with Job Zone 1 requiring the least amount of preparation (3\\nmonths) and Job Zone 5 requiring the most extensive amount of preparation, 4 or more years. We observe that\\nmedian income increases monotonically across Job Zones as the level of preparation needed also increases,\\nwith the median worker in Job Zone 1 earning $30,230and the median worker in Job Zone 5 earning $80,980.\\nAll of our measures ( U,V, and Z) show an identical pattern, that is, exposure increases from Job Zone 1 to\\nJob Zone 4, and either remains similar or decreases at Job Zone 5. Similar to Figure 3, in Figure 5, we plot\\nthe percentage of workers at every threshold of exposure. We ﬁnd that, on average, the percentage of workers\\nin occupations with greater than 50% Vexposure in Job Zones 1 through 5 have Vat 0.00% (Job Zone 1),\\n6.11% (Job Zone 2), 10.57% (Job Zone 3), 34.5% (Job Zone 4), and 26.45% (Job Zone 5), respectively. 8\\n4.4.1 Typical Education Needed for Entry\\nSince inclusion in a Job Zone accounts for both the education required—which itself is a proxy for skill\\nacquisition—and the preparation required, we seek data to disentangle these variables. We use two variables\\nfrom the Bureau of Labor Statistics’ Occupational data: \"Typical Education Needed for Entry\" and \"On-the-job\\nTraining Required to Attain Competency\" in an occupation. By examining these factors, we aim to uncover\\ntrends with potential implications for the workforce. There are 3,504,000 workers for whom we lack data on\\neducation and on-the-job training requirements, and they are therefore excluded from the summary tables.\\nOur analysis suggests that individuals holding Bachelor’s, Master’s, and professional degrees are more\\nexposed to LLMs and LLM-powered software than those without formal educational credentials (see Table 7).\\nInterestingly, we also ﬁnd that individuals with some college education but no degree exhibit a high level of\\nexposure to LLMs and LLM-powered software. Upon examining the table displaying barriers to entry, we\\nobserve that the jobs with the least exposure require the most training, potentially o ﬀering a lower payo ﬀ(in\\nterms of median income) once competency is achieved. Conversely, jobs with no on-the-job training required\\nor only internship/residency required appear to yield higher income but are more exposed to LLMs.\\n8For this set of results, all tasks have equal weight within an occupation. Results do not change meaningfully with the\\ncore/supplemental weighting scheme.WORKING PAP'),\n",
       " Document(page_content=', potentially o ﬀering a lower payo ﬀ(in\\nterms of median income) once competency is achieved. Conversely, jobs with no on-the-job training required\\nor only internship/residency required appear to yield higher income but are more exposed to LLMs.\\n8For this set of results, all tasks have equal weight within an occupation. Results do not change meaningfully with the\\ncore/supplemental weighting scheme.WORKING PAPER\\nFigure 5: Vexposure ratings of occupations in the ﬁve Job Zones, which are groups of similar occupations\\nthat are classiﬁed according to the level of education, experience, and on-the-job training needed to perform\\nthem. All tasks are weighted equally.WORKING PAPER\\nGroup Occupations with highest exposure % Exposure\\nHuman UUU Interpreters and Translators 76.5\\nSurvey Researchers 75.0\\nPoets, Lyricists and Creative Writers 68.8\\nAnimal Scientists 66.7\\nPublic Relations Specialists 66.7\\nHuman VVV Survey Researchers 84.4\\nWriters and Authors 82.5\\nInterpreters and Translators 82.4\\nPublic Relations Specialists 80.6\\nAnimal Scientists 77.8\\nHuman ZZZ Mathematicians 100.0\\nTax Preparers 100.0\\nFinancial Quantitative Analysts 100.0\\nWriters and Authors 100.0\\nWeb and Digital Interface Designers 100.0\\nHumans labeled 15 occupations as \"fully exposed.\"\\nModel UUU Mathematicians 100.0\\nCorrespondence Clerks 95.2\\nBlockchain Engineers 94.1\\nCourt Reporters and Simultaneous Captioners 92.9\\nProofreaders and Copy Markers 90.9\\nModel VVV Mathematicians 100.0\\nBlockchain Engineers 97.1\\nCourt Reporters and Simultaneous Captioners 96.4\\nProofreaders and Copy Markers 95.5\\nCorrespondence Clerks 95.2\\nModel ZZZ Accountants and Auditors 100.0\\nNews Analysts, Reporters, and Journalists 100.0\\nLegal Secretaries and Administrative Assistants 100.0\\nClinical Data Managers 100.0\\nClimate Change Policy Analysts 100.0\\nThe model labeled 86 occupations as \"fully exposed.\"\\nHighest variance Search Marketing Strategists 14.5\\nGraphic Designers 13.4\\nInvestment Fund Managers 13.0\\nFinancial Managers 13.0\\nInsurance Appraisers, Auto Damage 12.6\\nTable 4: Occupations with the highest exposure according to each measurement. The ﬁnal row lists the\\noccupations with the highest f2value, indicating that they had the most variability in exposure scores.\\nExposure percentages indicate the share of an occupation’s task that are exposed to GPTs ( UUU) or GPT-powered\\nsoftware ( VVVandZZZ), where exposure is deﬁned as driving a reduction in time it takes to complete the task by at\\nleast 50% (see exposure rubric A.1). As such, occupations listed in this table are those where we estimate\\nthat GPTs and GPT-powered software are able to save workers a signiﬁcant amount of time completing a\\nlarge share of their tasks, but it does not necessarily suggest that their tasks can be fully automated by these\\ntechnologies. All tasks are assigned equal weight within an occupation.WORKING PAPER\\nBasic Skill UUU\\n(std err)VVV\\n(std err)ZZZ\\n(std err)\\nAll skill importance scores are normalized to be between 0 and 1.\\nConstant 0.082*** -0.112*** 0.300***\\n(0.011) (0.011) (0.057)\\nActive Listening 0.128** 0.214*** 0.449***\\n(0.047) (0.043) (0.027)\\nMathematics -0.127*** 0.161*** 0.787***\\n(0.026) (0.021) (0.049)\\nReading Comprehension 0.153*** 0.470*** -0.346***\\n(0.041) (0.037) (0.017)\\nScience -0.114*** -0.230*** -0.346***\\n(0.014) (0.012) (0.017)\\nSpeaking -0.028 0.133*** 0.294***\\n(0.039) (0.033) (0.042)\\nWriting 0.368*** 0.467*** 0.566***\\n(0.042) (0.037) (0.047)\\nActive Learning -0.157*** -0.0'),\n",
       " Document(page_content='230*** -0.346***\\n(0.014) (0.012) (0.017)\\nSpeaking -0.028 0.133*** 0.294***\\n(0.039) (0.033) (0.042)\\nWriting 0.368*** 0.467*** 0.566***\\n(0.042) (0.037) (0.047)\\nActive Learning -0.157*** -0.065** 0.028\\n(0.027) (0.024) (0.032)\\nCritical Thinking -0.264*** -0.196*** -0.129**\\n(0.036) (0.033) (0.042)\\nLearning Strategies -0.072* -0.209*** -0.346***\\n(0.028) (0.025) (0.034)\\nMonitoring -0.067** -0.149*** -0.232***\\n(0.023) 0.020) (0.026)\\nProgramming 0.637*** 0.623*** 0.609***\\n(0.030) (0.022) (0.024)\\nTable 5: Regression of occupation-level, human-annotated exposure to GPTs on skill importance for each\\nskill in the O*NET Basic skills category, plus the programming skill. Descriptions of the skills may be found\\nin Appendix B. Task ratings within each occupation for exposure have equal weight.\\nJob\\nZonePreparation\\nRequiredEducation\\nRequiredExample Occupations Median\\nIncomeTot Emp\\n(000s )H\\nUUUM\\nUUUH\\nVVVM\\nVVVH\\nZZZM\\nZZZ\\n1 None or little\\n(0-3 months)High school\\ndiploma or GED\\n(otional)Food preparation workers,\\ndishwashers, ﬂoor sanders$30,230 13,100 0.03 0.04 0.06 0.06 0.09 0.08\\n2 Some (3-12\\nmonths)High school\\ndiplomaOrderlies, customer\\nservice representatives,\\ntellers$38,215 73,962 0.07 0.12 0.16 0.20 0.24 0.27\\n3 Medium (1-2\\nyears)Vocational school,\\non-the-job training,\\nor associate’s\\ndegreeElectricians, barbers,\\nmedical assistants$54,815 37,881 0.11 0.14 0.26 0.32 0.41 0.51\\n4 Considerable\\n(2-4 years)Bachelor’s degree Database administrators,\\ngraphic designers, cost\\nestimators$77,345 56,833 0.23 0.18 0.47 0.51 0.71 0.85\\n5 Extensive (4+\\nyears)Master’s degree or\\nhigherPharmacists, lawyers,\\nastronomers$81,980 21,221 0.23 0.13 0.43 0.45 0.63 0.76\\nTable 6: Mean exposure to GPTs by job zone. For each job zone, we also present the median of median\\nannual income for each constituting occupation in USD, and the total number of workers in all occupations\\nfor that job zone, in the thousands. Task weights are equal for all tasks.WORKING PAPER\\nOn The Job Training Required Median Income Tot Emp (000s) HUUU MUUU HVVVMVVV HZZZMZZZ\\nNone $77,440 90,776 0.20 0.16 0.42 0.46 0.63 0.76\\nApprenticeship $55,995 3,066 0.01 0.02 0.04 0.06 0.07 0.10\\nInternship/residency $77,110 3,063 0.16 0.06 0.36 0.38 0.55 0.71\\nShort-term on-the-job training $33,370 66,234 0.11 0.15 0.21 0.25 0.32 0.34\\nModerate-term on-the-job training $46,880 31,285 0.09 0.12 0.21 0.25 0.32 0.38\\nLong-term on-the-job training $48,925 5,070 0.08 0.10 0.18 0.22 0.28 0.33\\nTable 7: Mean exposure scores for occupations, grouped by level of on-the-job training required to attain\\ncompetency in the job. Alongside exposure scores, we display the median of median annual income for each\\noccupation, as well as the total number of workers in each group,'),\n",
       " Document(page_content=' 0.38\\nLong-term on-the-job training $48,925 5,070 0.08 0.10 0.18 0.22 0.28 0.33\\nTable 7: Mean exposure scores for occupations, grouped by level of on-the-job training required to attain\\ncompetency in the job. Alongside exposure scores, we display the median of median annual income for each\\noccupation, as well as the total number of workers in each group, in thousands. Task weights are equal within\\nan occupation and sum to one.WORKING PAPER\\n5 Validation of Measures\\n5.1 Comparison to Earlier E ﬀorts\\nThis paper aims to build on a number of previous empirical studies examining the occupational exposure to\\nadvances in AI and/or automation. Previous studies have used a variety of methods, including:\\n•Using occupational taxonomies like O*NET to characterize which occupations have routine vs.\\nnon-routine and manual vs. cognitive task content (Autor et al., 2003; Acemoglu and Autor, 2011a).\\n•Mapping text descriptions of tasks to descriptions of technological advances in patents. (Kogan et al.,\\n2021; Webb, 2020)\\n•Linking capabilities of AI systems to occupational abilities and aggregating exposure estimates to the\\noccupations where those abilities are required. (Felten et al., 2018, 2023)\\n•Mapping the results of AI task benchmark evaluations (ImageNet, Robocup, etc.) to 59 worker tasks\\nthrough a set of 14 cognitive abilities drawn from the cognitive science literature. (Tolan et al., 2021)\\n•Expert labeling of automation potential for a set of O*NET occupations where experts had high\\nconﬁdence, combined with a probabilistic classiﬁer to estimate automation potential for the remainder\\nof O*NET occupations. (Frey and Osborne, 2017)\\n•Developing a rubric for evaluating the \"suitability for machine learning\" (SML) of activities that\\nworkers are completing in the economy (Brynjolfsson and Mitchell, 2017; Brynjolfsson et al., 2018,\\n2023).\\nWe provide a set of summary statistics on many of these prior e ﬀorts in Table 8.\\nThis paper’s methodology primarily builds upon the SML approach by developing a rubric to evaluate the\\noverlap between LLM capabilities and worker tasks as reported in the O*NET database. Table 9 presents the\\nresults of OLS regressions of our new LLM exposure measurements on occupation-level exposure measures\\nfrom (Felten et al., 2018) (\"AI Occupational Exposure Score\" in the table), (Frey and Osborne, 2017) (Frey\\n& Osborne Automation), scores from all three technologies in (Webb, 2020), normalized routine manual\\nand cognitive scores from (Acemoglu and Autor, 2011a), and (Brynjolfsson et al., 2018, 2023) (SML). We\\nalso use annualized occupational salaries from the most recent BLS Occupational Employment Survey as a\\ncontrol. There are four separate output variables representing new scores in this paper that are predicted by\\nearlier e ﬀorts.\\nGPT-4 Exposure Rating 1 corresponds to our overall exposure rubric as evaluated by GPT-4, where full\\nexposure potential is coded as 1, no exposure potential is coded as 0, and partial exposure (E2 in our labeling\\nscheme) is coded as 0.5. GPT-4 Exposure Rating 2 is scored similarly for overall exposure, but with a slightly\\ndiﬀerent prompt. The results are very similar across the two prompts. Human Exposure Rating represents the\\nsame rubric as in GPT-4 Exposure Rating 1 but is scored by humans, as discussed in an earlier section of the\\npaper. These results correspond to the Vset of statistics presented above, with supplemental tasks having half\\nthe weight of core tasks within an occupation. These weights sum to one (core/supplemental distinctions are\\ndetermined by O*NET).\\nThe results across each type of measurement are consistent. We ﬁnd generally positive and statistically\\nsigniﬁcant correlations between our LLM exposure measures and previous measurements targeting software\\nand AI. Encouragingly, the SML exposure scores by occupation show signiﬁcant and positive associations\\nwith the exposure scores we develop in this paper, demonstrating a level of cohesion between the two studies\\nwith similar approaches. The Webb software and AI patent-based measures, SML, and normalized (demeanedWORKING PAPER\\nMin 25th Perc. Median 75th Perc Max Mean Std. Dev. Count\\nGPT-4 Exposure Rating 1 0.00 0.13 0.34 0.50 1.'),\n",
       " Document(page_content=\"iﬁcant and positive associations\\nwith the exposure scores we develop in this paper, demonstrating a level of cohesion between the two studies\\nwith similar approaches. The Webb software and AI patent-based measures, SML, and normalized (demeanedWORKING PAPER\\nMin 25th Perc. Median 75th Perc Max Mean Std. Dev. Count\\nGPT-4 Exposure Rating 1 0.00 0.13 0.34 0.50 1.00 0.33 0.22 750\\nGPT-4 Exposure Rating 2 0.00 0.09 0.24 0.40 0.98 0.26 0.20 750\\nHuman Exposure Rating 0.00 0.09 0.29 0.47 0.84 0.29 0.21 750\\nSoftware (Webb) 1.00 25.00 50.00 75.00 100.00 50.69 30.05 750\\nRobot (Webb) 1.00 22.00 52.00 69.00 100.00 48.61 28.61 750\\nAI (Webb) 1.00 28.00 55.00 82.00 100.00 54.53 29.65 750\\nSuitability for Machine Learning 2.60 2.84 2.95 3.12 3.55 2.99 0.18 750\\nNormalized Routine Cognitive -3.05 -0.46 0.10 0.63 3.42 0.07 0.86 750\\nNormalized Routine Manual -1.81 -0.81 -0.11 0.73 2.96 0.05 1.01 750\\nAI Occupational Exposure Score 1.42 3.09 3.56 4.04 6.54 3.56 0.70 750\\nFrey & Osborne Automation 0.00 0.07 0.59 0.88 0.99 0.50 0.38 681\\nLog Avg. Salary 10.13 10.67 11.00 11.34 12.65 11.02 0.45 749\\nTable 8: Summary statistics for a suite of prior e ﬀorts to measure occupational exposure to AI and automation.\\nWe have also included summary statistics for measurements newly presented in this work. We include all\\nmeasures from (Webb, 2020), normalized routine cognitive and manual scores from (Acemoglu and Autor,\\n2011a) (means may deviate slightly from 0 due to imperfect matching of occupational groups), Suitability for\\nMachine Learning from (Brynjolfsson and Mitchell, 2017; Brynjolfsson et al., 2018, 2023), AI Occupational\\nExposure from (Felten et al., 2018), and Automation exposure from (Frey and Osborne, 2017). We include as\\nmany occupations as we can match, but since O*NET taxonomies have changed as these measures have been\\ndeveloped, some of the roles may be missing from the most recent version of O*NET 6-digit occupations.\\nand divided by standard deviation) routine cognitive scores all exhibit positive associations with some of our\\nmeasures.\\nSoftware, SML, and routine cognitive scores all show positive and statistically signiﬁcant associations\\nwith LLM exposure scores at a 1% level. Coe ﬃcients on AI scores from (Webb, 2020) are also positive and\\nstatistically signiﬁcant at a 5% level, but our secondary prompt on overall exposure to LLMs in columns 3\\nand 4 does not exhibit a statistically signiﬁcant relationship. For the most part, the AI Occupational Exposure\\nScore is not correlated with our exposure measures. Webb’s Robot exposure scores, routine manual task\\ncontent, and the overall Automation metric from (Frey and Osborne, 2017) are all negatively correlated with\\nour primary GPT-4 and human-assessed overall exposure ratings, conditional on the other measurements.\\nThis negative correlation reﬂects the limited exposure of physical tasks to LLMs. Manual work is not exposed\\nto LLMs or even LLMs with additional systems integration for the time being.\\nLow correlations with (Felten et al., 2018) and (Frey and Osborne, 2017) could potentially be explained\\nby diﬀerences in approaches. Linking AI capabilities to worker abilities or scoring exposure directly based on\\nthe occupation’s characteristics, rather than aggregating up to the occupation from DWA or task-level scoring\\n(as in the SML paper and our own), o ﬀer a slightly di ﬀerent perspective on the content of occupations.\\nIn all regressions, the '2ranges between 60.7% (column 3) and 72.8% (column 5). This suggests that\\nour measure, which explicitly focuses on LLM capabilities, has between 28 and 40% unexplained variance\\ncompared to other measurements\"),\n",
       " Document(page_content=\" to the occupation from DWA or task-level scoring\\n(as in the SML paper and our own), o ﬀer a slightly di ﬀerent perspective on the content of occupations.\\nIn all regressions, the '2ranges between 60.7% (column 3) and 72.8% (column 5). This suggests that\\nour measure, which explicitly focuses on LLM capabilities, has between 28 and 40% unexplained variance\\ncompared to other measurements. Particularly in the case of AI-related exposure scores, we anticipate that a\\ncombination of other measurements would have a strong correlation with our scores. However, earlier e ﬀorts\\nhad limited information about the future progress of LLMs or LLM-powered software. We expect that our\\nunderstanding of future machine learning technologies is similarly imperfectly captured by our rubric today.WORKING PAPER\\nGPT-4 Exposure Rating 1 GPT-4 Exposure Rating 2 Human Exposure Rating\\n(1) (2) (3) (4) (5) (6)\\nSoftware (Webb) 0.00113⇤⇤⇤0.00123⇤⇤⇤0.00111⇤⇤⇤0.00119⇤⇤⇤0.00096⇤⇤⇤0.00101⇤⇤⇤\\n(0.00031 )( 0.00031 )( 0.00031 )( 0.00031 )( 0.00031 )( 0.00031 )\\nRobot (Webb) \\x000.00378⇤⇤⇤\\x000.00405⇤⇤⇤\\x000.00377⇤⇤⇤\\x000.00399⇤⇤⇤\\x000.00371⇤⇤⇤\\x000.00383⇤⇤⇤\\n(0.00032 )( 0.00031 )( 0.00034 )( 0.00033 )( 0.00029 )( 0.00028 )\\nAI (Webb) 0.00080⇤⇤⇤0.00090⇤⇤⇤0.00036 0 .00045 0 .00067⇤⇤0.00071⇤⇤\\n(0.00030 )( 0.00029 )( 0.00030 )( 0.00030 )( 0.00030 )( 0.00030 )\\nSuitability for Machine Learning 0.29522⇤⇤⇤0.26888⇤⇤⇤0.28468⇤⇤⇤0.26245⇤⇤⇤0.19514⇤⇤⇤0.18373⇤⇤⇤\\n(0.04503 )( 0.04418 )( 0.04404 )( 0.04342 )( 0.03990 )( 0.03886 )\\nNormalized Routine Cognitive 0.06601⇤⇤⇤0.06868⇤⇤⇤0.04743⇤⇤⇤0.05015⇤⇤⇤0.03568⇤⇤⇤0.03659⇤⇤⇤\\n(0.00886 )( 0.00894 )( 0.00872 )( 0.00879 )( 0.00671 )( 0.00669 )\\nNormalized Routine Manual \\x000.11147⇤⇤⇤\\x000.11371⇤⇤⇤\\x000.09390⇤⇤⇤\\x000.09561⇤⇤⇤\\x000.11045⇤⇤⇤\\x000.11152⇤⇤⇤\\n(0.00785 )( 0.00789 )( 0.00817 )( 0.00818 )( 0.00741 )( 0.00744 )\\nAI Occupational Exposure Score 0.00993 0 .02465⇤⇤\\x000.01537 \\x000.00265 0 .00630 0 .01252\\n(0.01107 )( 0.01059 )( 0.01160 )( 0.01114 )( 0.00918 )( 0.00845 )\\nFrey &\"),\n",
       " Document(page_content=\"17 )( 0.00818 )( 0.00741 )( 0.00744 )\\nAI Occupational Exposure Score 0.00993 0 .02465⇤⇤\\x000.01537 \\x000.00265 0 .00630 0 .01252\\n(0.01107 )( 0.01059 )( 0.01160 )( 0.01114 )( 0.00918 )( 0.00845 )\\nFrey & Osborne Automation \\x000.03024⇤\\x000.03950⇤⇤\\x000.00364 \\x000.01217 \\x000.03890⇤⇤\\x000.04253⇤⇤\\n(0.01835 )( 0.01841 )( 0.02007 )( 0.01972 )( 0.01883 )( 0.01858 )\\nLog Avg. Salary 0.05804⇤⇤⇤0.04863⇤⇤⇤0.02531\\n(0.01870 )( 0.01860 )( 0.01727 )\\nConstant \\x001.12937⇤⇤⇤\\x000.45743⇤⇤⇤\\x000.96117⇤⇤⇤\\x000.39935⇤⇤⇤\\x000.47078⇤\\x000.17706\\n(0.26859 )( 0.15327 )( 0.26365 )( 0.15017 )( 0.24684 )( 0.13256 )\\nN 680.00000 681 .00000 680 .00000 681 .00000 680 .00000 681 .00000\\n'20.68741 0 .68212 0 .60737 0 .60198 0 .71213 0 .71126\\nTable 9: Regression of LLM-exposure scores on prior measures of occupational exposure to AI and automation.\\nWe also include annualized wages from the BLS-OES survey in May 2021. Each measure is kept in its\\noriginal scale, with the exception of routine cognitive and routine manual scores from (Acemoglu and Autor,\\n2011a). Those two scores are standardized to mean zero and variance 1. Generally we ﬁnd strong positive\\nassociations with previous e ﬀorts, though large residual variance to still be explained by our new measures.\\nColumns 1 and 2 are based on our main Vexposure measure from GPT-4 ratings. Columns 3 and 4 are\\nbased on a similar slightly di ﬀerent exposure rubric also rated by GPT-4 for robustness. Columns 5 and 6\\nreﬂect human ratings on the same rubric as columns 1 and 2. Occupation-level scores are built using the\\ncore/supplemental task weights, assigning supplemental tasks as having half the weight of core tasks.WORKING PAPER\\n6 Discussion\\n6.1 GPTs as a General-Purpose Technology\\nEarlier in this paper we discuss the possibility that LLMs could be classiﬁed as a general-purpose technology.\\nThis classiﬁcation requires LLMs to meet three core criteria: improvement over time, pervasiveness throughout\\nthe economy, and the ability to spawn complementary innovations (Lipsey et al., 2005). Evidence from the AI\\nand machine learning literature thoroughly demonstrates that LLMs meet the ﬁrst criteria – they are improving\\nin capabilities over time with the ability to complete or be helpful for an increasingly complex set of tasks and\\nuse-cases (see 2.1). This paper presents evidence to support the latter two criteria, ﬁnding that LLMs on their\\nown can have pervasive impacts across the economy, and that complementary innovations enabled by LLMs –\\nparticularly via software and digital tools – can have widespread application to economic activity.\\nFigure 3 o ﬀers one illustration of the potential economic impact of complementary software built on top of\\nLLMs. Taking the di ﬀerence in the y-axis (the share of all occupations) between UandZat a given point along\\nthe x-axis (the share of tasks within an occupation that are exposed) gives the aggregate within-occupation\\nexposure potential attributable to tools and software over and above direct exposure from LLMs on their\\nown. The di ﬀerence in means across all tasks between UandZof 0.42 using the GPT-4 annotations and 0.32\\nusing the human annotations (see Figure 3), suggests that the average impact of LLM-powered software on\\ntask-exposure may be more than twice as large as the mean exposure from LLMs on their own (mean Zof 0\"),\n",
       " Document(page_content='exposure potential attributable to tools and software over and above direct exposure from LLMs on their\\nown. The di ﬀerence in means across all tasks between UandZof 0.42 using the GPT-4 annotations and 0.32\\nusing the human annotations (see Figure 3), suggests that the average impact of LLM-powered software on\\ntask-exposure may be more than twice as large as the mean exposure from LLMs on their own (mean Zof 0.14\\nbased on both human annotations and GPT-4 annotations). While our ﬁndings suggest that out-of-the-box\\nthese models are relevant to a meaningful share of workers and tasks, they also suggest that the software\\ninnovations they spawn could drive a much broader impact.\\nOne component of the pervasiveness of a technology is its level of adoption by businesses and users.\\nThis paper does not systematically analyze adoption of these models, however, there is early qualitative\\nevidence that adoption and use of LLMs is becoming increasingly widespread. The power of relatively\\nsimple UI improvements on top of LLMs was evident in the rollout of ChatGPT – wherein versions of the\\nunderlying language model had been previously available via API, but usage skyrocketed after the release of\\nthe ChatGPT interface. (Chow, 2023; OpenAI, 2022) Following this release, a number of commercial surveys\\nindicate that ﬁrm and worker adoption of LLMs has increased over the past several months. (Constantz, 2023;\\nResumeBuilder.com, 2023)\\nWidespread adoption of these models requires addressing existing bottlenecks. A key determinant of\\ntheir utility is the level of conﬁdence humans place in them and how humans adapt their habits. For instance,\\nin the legal profession, the models’ usefulness depends on whether legal professionals can trust model\\noutputs without verifying original documents or conducting independent research. The cost and ﬂexibility\\nof the technology, worker and ﬁrm preferences, and incentives also signiﬁcantly inﬂuence the adoption of\\ntools built on top of LLMs. In this way, adoption may be driven by progress on some of the ethical and\\nsafety risks associated with LLMs: bias, fabrication of facts, and misalignment, to name a few OpenAI\\n(2023a). Moreover, the adoption of LLMs will vary across di ﬀerent economic sectors due to factors such\\nas data availability, regulatory environment, and the distribution of power and interests. Consequently, a\\ncomprehensive understanding of the adoption and use of LLMs by workers and ﬁrms requires a more in-depth\\nexploration of these intricacies.\\nOne possibility is that time savings and seamless application will hold greater importance than quality\\nimprovement for the majority of tasks. Another is that the initial focus will be on augmentation, followed byimprovement for the majority of tasks. Another is that the initial focus will be on augmentation, followed by\\nautomation (Huang and Rust, 2018). One way this might take shape is through an augmentation phase where\\njobs ﬁrst become more precarious (e.g., writers becoming freelancers) before transitioning to full automation.WORKING PAPER\\n6.2 Implications for US Public Policy\\nThe introduction of automation technologies, including LLMs, has previously been linked to heightened\\neconomic disparity and labor disruption, which may give rise to adverse downstream e ﬀects (Acemoglu and\\nRestrepo, 2022a; Acemoglu, 2002; Moll et al., 2021; Klinova and Korinek, 2021; Weidinger et al., 2021,\\n2022). Our results examining worker exposure in the United States underscore the need for societal and policy\\npreparedness to the potential economic disruption posed by LLMs and the complementary technologies\\nthat they spawn. While it is outside the scope of this paper to recommend speciﬁc policy prescriptions to\\nsmooth the transition to an economy with increasingly widespread LLM adoption, prior work such as (Autor\\net al., 2022b) has articulated several important directions for US policy related to education, worker training,\\nreforms to safety net programs, and more.\\n6.3 Limitations and Future Work\\nIn addition to those discussed above, we highlight some particular limitations of this work that warrant further\\ninvestigation. Primarily, our focus on the United States restricts the generalizability of our ﬁndings to other\\nnations where the adoption and impact of generative models may di ﬀer due to factors such as industrial\\norganization, technological infrastructure, regulatory frameworks, linguistic diversity, and cultural contexts.\\nWe hope to address this limitation by extending the study’s scope and by sharing our methods'),\n",
       " Document(page_content=', we highlight some particular limitations of this work that warrant further\\ninvestigation. Primarily, our focus on the United States restricts the generalizability of our ﬁndings to other\\nnations where the adoption and impact of generative models may di ﬀer due to factors such as industrial\\norganization, technological infrastructure, regulatory frameworks, linguistic diversity, and cultural contexts.\\nWe hope to address this limitation by extending the study’s scope and by sharing our methods so other\\nresearchers can build on them.\\nSubsequent research e ﬀorts should consider two additional studies: one exploring LLM adoption patterns\\nacross various sectors and occupations, and another scrutinizing the actual capabilities and limitations of\\nstate-of-the-art models in relation to worker activities beyond the scope of our exposure scores. For example,\\ndespite recent advances in multimodal capabilities with GPT-4, we did not consider vision capabilities in\\ntheUratings on direct LLMs-exposure (OpenAI, 2023b). Future work should consider the impact of such\\ncapability advances as they unfold. Furthermore, we acknowledge that there may be discrepancies between\\ntheoretical and practical performance, particularly in complex, open-ended, and domain-speciﬁc tasks.\\n7 Conclusion\\nIn conclusion, this study o ﬀers an examination of the potential impact of LLMs on various occupations and\\nindustries within the U.S. economy. By applying a new rubric for understanding LLM capabilities and their\\npotential e ﬀects on jobs, we have observed that most occupations exhibit some degree of exposure to LLMs,\\nwith higher-wage occupations generally presenting more tasks with high exposure. Our analysis indicates that\\napproximately 19% of jobs have at least 50% of their tasks exposed to LLMs when considering both current\\nmodel capabilities and anticipated LLM-powered software.\\nOur research aims to highlight the general-purpose potential of LLMs and their possible implications for\\nUS workers. Previous literature demonstrates the impressive improvements of LLMs to date (see 2.1). Our\\nﬁndings conﬁrm the hypothesis that these technologies can have pervasive impacts across a wide swath of\\noccupations in the US, and that additional advancements supported by LLMs, mainly through software and\\ndigital tools, can have signiﬁcant e ﬀects on a range of economic activities. However, while the technical\\ncapacity for LLMs to make human labor more e ﬃcient appears evident, it is important to recognize that social,\\neconomic, regulatory, and other factors will inﬂuence actual labor productivity outcomes. As capabilities\\ncontinue to evolve, the impact of LLMs on the economy will likely persist and increase, posing challenges for\\npolicymakers in predicting and regulating their trajectory.\\nFurther research is necessary to explore the broader implications of LLM advancements, including\\ntheir potential to augment or displace human labor, their impact on job quality, impacts on inequality, skilltheir potential to augment or displace human labor, their impact on job quality, impacts on inequality, skill\\ndevelopment, and numerous other outcomes. By seeking to understand the capabilities and potential e ﬀectsWORKING PAPER\\nof LLMs on the workforce, policymakers and stakeholders can make more informed decisions to navigate the\\ncomplex landscape of AI and its role in shaping the future of work.\\n7.1 LLM Conclusion (GPT-4’s Version)\\nGenerative Pre-trained Transformers (GPTs) generate profound transformations, garnering potential technolog-\\nical growth, permeating tasks, greatly impacting professions. This study probes GPTs’ potential trajectories,\\npresenting a groundbreaking rubric to gauge tasks’ GPT exposure, particularly in the U.S. labor market.\\n7.2 LLM Conclusion (Author-Augmented Version)\\nGenerative Pre-trained Transformers (GPTs) generate profound transformations, garnering potential techno-\\nlogical growth, permeating tasks, gutting professional management. Gauging possible trajectories? Generate\\npioneering taxonomies, gather policymakers together, generalize past today.\\nAcknowledgments\\nThank you to the group of annotators who helped us annotate task exposure, including Muhammad Ahmed\\nSaeed, Bongane Zitha, Merve Özen Şenen, J.J., and Peter Hoeschele. We also thank Lauryn Fuld, Ashley Glat,\\nMichael Lampe, and Julia Susser for excellent research assistance. We thank Miles Brundage for signiﬁcant\\nfeedback on this paper.\\nWe thank Todor Markov and Vik Goel for setting up the infrastructure we use to run our rubrics with\\nGPT-4. We thank Lama Ahmad, Donald Bakong,'),\n",
       " Document(page_content=', J.J., and Peter Hoeschele. We also thank Lauryn Fuld, Ashley Glat,\\nMichael Lampe, and Julia Susser for excellent research assistance. We thank Miles Brundage for signiﬁcant\\nfeedback on this paper.\\nWe thank Todor Markov and Vik Goel for setting up the infrastructure we use to run our rubrics with\\nGPT-4. We thank Lama Ahmad, Donald Bakong, Seth Benzell, Erik Brynjolfsson, Parfait Eloundou-Enyegue,\\nCarl Frey, Sarah Giroux, Gillian Hadﬁeld, Johannes Heidecke, Alan Hickey, Eric Horvitz, Shengli Hu,\\nAshyana Kachra, Christina Kim, Katya Klinova, Daniel Kokotajlo, Gretchen Krueger, Michael Lampe, Aalok\\nMehta, Larissa Schiavo, Daniel Selsam, Sarah Shoker, Prasanna Tambe, and Je ﬀWu for feedback and edits at\\nvarious stages of the project.\\nLLM assistance statement\\nGPT-4 and ChatGPT were used for writing, coding, and formatting assistance in this project.\\nA Rubric\\nA.1 Exposure\\n# E Exposure Taxonomy\\nConsider the most powerful OpenAI large language model (LLM) This model can complete many tasks\\nthat can be formulated as having text input and text output where the context for the input can be captured in\\n2000 words. The model also cannot draw up-to-date facts (those from <1 year ago) unless they are captured\\nin the input.\\nAssume you are a worker with an average level of expertise in your role trying to complete the given task.\\nYou have access to the LLM as well as any other existing software or computer hardware tools mentioned\\nin the task. You also have access to any commonly available technical tools accessible via a laptop (e.g. a\\nmicrophone, speakers, etc.). You do not have access to any other physical tools or materials.\\nPlease label the given task according to the taxonomy below.\\n## E0 – No exposure')]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=1024, chunk_overlap=100)\n",
    "job_doc = text_splitter.split_documents(job_doc)\n",
    "job_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "682900fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"WORKING PAPER\n",
      "GPTs are GPTs: An Early Look at the Labor Market Impact Potential\n",
      "of Large Language Models\n",
      "Tyna Eloundou1, Sam Manning1,2, Pamela Mishkin\u00001, and Daniel Rock3\n",
      "1OpenAI\n",
      "2OpenResearch\n",
      "3University of Pennsylvania\n",
      "August 22, 2023\n",
      "Abstract\n",
      "We investigate the potential implications of large language models (LLMs), such as Generative Pre-\n",
      "trained Transformers (GPTs), on the U.S. labor market, focusing on the increased capabilities arising from\n",
      "LLM-powered software compared to LLMs on their own. Using a new rubric, we assess occupations based\n",
      "on their alignment with LLM capabilities, integrating both human expertise and GPT-4 classiﬁcations.\n",
      "Our ﬁndings reveal that around 80% of the U.S. workforce could have at least 10% of their work tasks\n",
      "aﬀected by the introduction of LLMs, while approximately 19% of workers may see at least 50% of their\n",
      "tasks impacted. We do not make predictions about the development or adoption timeline of such LLMs.\n",
      "The projected eﬀects span all wage levels, with higher-income jobs potentially facing greater exposure to\n",
      "LLM capabilities and LLM-powered software. Signiﬁcantly, these impacts are not restricted to industries\n",
      "with higher recent productivity growth. Our analysis suggests that, with access to an LLM, about 15%\n",
      "of all worker tasks in the US could be completed signiﬁcantly faster at the same level of quality. When\n",
      "incorporating software and tooling built on top of LLMs, this share increases to between 47 and 56%\n",
      "of all tasks. This ﬁnding implies that LLM-powered software will have a substantial eﬀect on scaling\n",
      "the economic impacts of the underlying models. We conclude that LLMs such as GPTs exhibit traits of\n",
      "general-purpose technologies, indicating that they could have considerable economic, social, and policy\n",
      "implications.\n",
      "1 Introduction\n",
      "As shown in Figure 1, recent years, months, and weeks have seen remarkable progress in the ﬁeld of generative\n",
      "AI and large language models (LLMs). While the public often associates LLMs with various iterations of the\n",
      "Generative Pre-trained Transformer (GPT), LLMs can be trained using a range of architectures, and are not\n",
      "limited to transformer-based models (Devlin et al., 2019). LLMs can process and produce various forms of\n",
      "sequential data, including assembly language, protein sequences and chess games, extending beyond natural\n",
      "language applications alone. In this paper, we use LLMs and GPTs somewhat interchangeably, and specify in\n",
      "our rubric that these should be considered similar to the GPT-family of models available via ChatGPT or\n",
      "the OpenAI Playground (which at the time of labeling included models in the GPT-3.5 family but not in the\n",
      "GPT-4 family). We examine LLMs with text- and code-generating abilities, use the term \"generative AI\" to\n",
      "additionally include modalities such as images or audio, and use \"LLM-powered software\" to cover tools built\n",
      "on top of LLMs or that combine LLMs with other generative AI models.\n",
      "\u0000Corresponding author (pamela@openai.com). Authors contributed equally and are listed alphabetically.arXiv:2303.10130v5  [econ.GN]  21 Aug 2023WORKING PAPER\n",
      "Figure 1: Taken directly from GPT-4 Technical Report (OpenAI, 2023b). To get a sense of how quickly\n",
      "model capabilities are progressing – consider the jump in exam performance between GPT-3.5 and GPT-4\n",
      "(OpenAI, 2023b).\n",
      "Our study is motivated less by the progress of these models alone though, and more by the breadth,\n",
      "scale, and capabilities we’ve seen in the complementary technologies developed around them. The role of\n",
      "complementary technologies remains to be seen, but maximizing the impact of LLMs appears contingent\n",
      "on integrating them with larger systems (Bresnahan, 2019; Agrawal et al., 2021). While the focus of our\n",
      "discussion is primarily on the generative capabilities of LLMs, it is important to note that these models can\n",
      "also be utilized for various tasks beyond text generation. For example, embeddings from LLMs can be used\n",
      "for custom search applications, and LLMs can perform tasks such as summarization and classiﬁcation where\n",
      "the context may be largely contained in the prompt.\n",
      "To complement predictions of technology’s impacts on work and provide a framework for understanding\n",
      "the evolving landscape of language models and their associated technologies,\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\" LLMs, it is important to note that these models can\n",
      "also be utilized for various tasks beyond text generation. For example, embeddings from LLMs can be used\n",
      "for custom search applications, and LLMs can perform tasks such as summarization and classiﬁcation where\n",
      "the context may be largely contained in the prompt.\n",
      "To complement predictions of technology’s impacts on work and provide a framework for understanding\n",
      "the evolving landscape of language models and their associated technologies, we propose a new rubric\n",
      "for assessing LLM capabilities and their potential eﬀects on jobs. This rubric (A.1) measures the overall\n",
      "exposure of tasks to LLMs, following the spirit of prior work on quantifying exposure to machine learning\n",
      "(Brynjolfsson et al., 2018; Felten et al., 2018; Webb, 2020). We deﬁne exposure as a proxy for potential\n",
      "economic impact without distinguishing between labor-augmenting or labor-displacing eﬀects. We employ\n",
      "human annotators and GPT-4 itself as a classiﬁer to apply this rubric to occupational data in the U.S. economy,\n",
      "primarily sourced from the O*NET database. 12\n",
      "To construct our primary exposure dataset, we collected both human annotations and GPT-4 classiﬁcations,\n",
      "using a prompt tuned for agreement with a sample of labels from the authors. We observe similar agreement\n",
      "1This is distinct from recent social science research that makes use of LLMs to simulate human behavior (Horton, 2023; Sorensen\n",
      "et al., 2022)\n",
      "2While our exposure rubric does not necessarily tie the concept of language models to any particular model, we were strongly\n",
      "motivated by our observed capabilities of GPT-4 and the suite of capabilities we saw in development with OpenAI’s launch partners\n",
      "(OpenAI, 2023b).WORKING PAPER\n",
      "levels in GPT-4 responses and between human and machine evaluations, when aggregated to the task level.\n",
      "This exposure measure reﬂects an estimate of the technical capacity to make human labor more eﬃcient;\n",
      "however, social, economic, regulatory, and other determinants imply that technical feasibility does not\n",
      "guarantee labor productivity or automation outcomes. Our analysis indicates that approximately 19% of jobs\n",
      "have at least 50% of their tasks exposed when considering both current model capabilities and anticipated\n",
      "tools built upon them. Human assessments suggest that only 3% of U.S. workers have over half of their tasks\n",
      "exposed to LLMs when considering existing language and code capabilities without additional software or\n",
      "modalities. Accounting for other generative models and complementary technologies, our human estimates\n",
      "indicate that up to 49% of workers could have half or more of their tasks exposed to LLMs.\n",
      "Our ﬁndings consistently show across both human and GPT-4 annotations that most occupations exhibit\n",
      "some degree of exposure to LLMs, with varying exposure levels across diﬀerent types of work. Occupations\n",
      "with higher wages generally present with higher exposure, a result contrary to similar evaluations of overall\n",
      "exposure to machine learning (Brynjolfsson et al., 2023). When regressing exposure measures on skillsets\n",
      "using O*NET’s skill rubric, we discover that roles heavily reliant on science and critical thinking skills show\n",
      "a negative correlation with exposure, while programming and writing skills are positively associated with\n",
      "LLM exposure. Following Autor et al. (2022a), we examine barriers to entry by \"Job Zones\" and ﬁnd that\n",
      "occupational exposure to LLMs weakly increases with the diﬃculty of job preparation. In other words,\n",
      "workers facing higher (lower) barriers to entry in their jobs tend to experience more (less) exposure to LLMs.\n",
      "We further compare our measurements to previous eﬀorts documenting the distribution of automation\n",
      "exposure in the economy and ﬁnd broadly consistent results. Most other technology exposure measures we\n",
      "examine are statistically signiﬁcantly correlated with our preferred exposure measure, while measures of\n",
      "manual routineness and robotics exposure show negative correlations. The variance explained by these earlier\n",
      "eﬀorts (Acemoglu and Autor, 2011a; Frey and Osborne, 2017; Brynjolfsson et al., 2018; Felten et al., 2018;\n",
      "Webb, 2020; Brynjolfsson et al., 2023), along with wage controls, ranges from 60 to 72%, indicating that 28\n",
      "to 40% of the variation in our AI exposure measure remains unaccounted for by previous technology exposure\n",
      "measurements.\n",
      "We analyze exposure by industry and discover that information processing industries (4-digit NAICS)\n",
      "exhibit high exposure, while manufacturing,\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"njolfsson et al., 2018; Felten et al., 2018;\n",
      "Webb, 2020; Brynjolfsson et al., 2023), along with wage controls, ranges from 60 to 72%, indicating that 28\n",
      "to 40% of the variation in our AI exposure measure remains unaccounted for by previous technology exposure\n",
      "measurements.\n",
      "We analyze exposure by industry and discover that information processing industries (4-digit NAICS)\n",
      "exhibit high exposure, while manufacturing, agriculture, and mining demonstrate lower exposure. The\n",
      "connection between productivity growth in the past decade and overall LLM exposure appears weak, suggesting\n",
      "a potential optimistic case that future productivity gains from LLMs may not exacerbate possible cost disease\n",
      "eﬀects (Baumol, 2012; Aghion et al., 2018). 3\n",
      "Our analysis indicates that the impacts of LLMs like GPT-4, are likely to be pervasive. While LLMs\n",
      "have consistently improved in capabilities over time, their growing economic eﬀect is expected to persist and\n",
      "increase even if we halt the development of new capabilities today. We also ﬁnd that the potential impact of\n",
      "LLMs expands signiﬁcantly when we take into account the development of complementary technologies.\n",
      "Collectively, these characteristics imply that Generative Pre-trained Transformers (GPTs) are general-purpose\n",
      "technologies (GPTs). 4(Bresnahan and Trajtenberg, 1995; Lipsey et al., 2005).\n",
      "(Goldfarb et al., 2023) argue that machine learning as a broad category is likely a general-purpose\n",
      "technology. Our evidence supports a wider impact, as even subsets of machine learning software meet thetechnology. Our evidence supports a wider impact, as even subsets of machine learning software meet the\n",
      "criteria for general-purpose technology status independently. This paper’s primary contributions are to provide\n",
      "a set of measurements of LLM impact potential and to demonstrate the use case of applying LLMs to develop\n",
      "such measurements eﬃciently and at scale. Additionally, we showcase the general-purpose potential of LLMs.\n",
      "If \"GPTs are GPTs,\" the eventual trajectory of LLM development and application may be challenging for\n",
      "3Baumol’s cost disease is a theory that explains why the cost of labor-intensive services, such as healthcare and education,\n",
      "increases over time. This happens because wages for skilled workers in other industries increase, but there is no corresponding\n",
      "increase in productivity or eﬃciency in these service industries. Therefore, the cost of labor in these industries becomes relatively\n",
      "more expensive compared to other goods and services in the economy.\n",
      "4For the remainder of the paper we spell out general-purpose technologies when it is used outside of stating \"GPTs are GPTs.\"WORKING PAPER\n",
      "policymakers to predict and regulate. As with other general-purpose technologies, much of these algorithms’\n",
      "potential will emerge across a broad range of economically valuable use cases, including the creation of new\n",
      "types of work (Acemoglu and Restrepo, 2018; Autor et al., 2022a). Our research serves to measure what is\n",
      "technically feasible now, but necessarily will miss the evolving impact potential of the LLMs over time.\n",
      "The paper is structured as follows: Section 2 reviews relevant prior work, Section 3 discusses methods\n",
      "and data collection, Section 4 presents summary statistics and results, Section 5 relates our measurements to\n",
      "earlier eﬀorts, Section 6 discusses the results, and Section 7 oﬀers concluding remarks.\n",
      "2 Literature Review\n",
      "2.1 The Advancement of Large Language Models\n",
      "In recent years, generative AI models have gained signiﬁcant attention from both the artiﬁcial intelligence\n",
      "(AI) research community and the general public, due to their ability to tackle a wide array of complex\n",
      "language-based tasks. The progress in these models’ abilities has been fueled by multiple factors, including\n",
      "increased model parameter count, greater training data volume, and enhanced training conﬁgurations (Brown\n",
      "et al., 2020; Radford et al., 2019; Hernandez et al., 2021; Kaplan et al., 2020). Broad, state-of-the-art LLMs,\n",
      "such as LaMDA (Thoppilan et al., 2022) and GPT-4 (OpenAI, 2023b), excel in diverse applications like\n",
      "translation, classiﬁcation, creative writing, and code generation—capabilities that previously demanded\n",
      "specialized, task-speciﬁc models developed by expert engineers using domain-speciﬁc data.\n",
      "Concurrently, researchers have improved the steerability, reliability, and utility of these models using\n",
      "methods like ﬁne-tuning and reinforcement\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"The paper investigates the potential impact of large language models (LLMs) such as Generative Pre-trained Transformers (GPTs) on the US labor market. The study finds that around 80% of the US workforce could have at least 10% of their work tasks affected by the introduction of LLMs, while approximately 19% of workers may see at least 50% of their tasks impacted. The projected effects span all wage levels, with higher-income jobs potentially facing greater exposure to LLM capabilities and LLM-powered software. The study concludes that LLMs such as GPTs could have considerable economic, social, and policy implications.\n",
      "\n",
      "A new rubric has been proposed to assess the capabilities of large language models (LLMs) and their potential impact on jobs. The rubric measures the overall exposure of tasks to LLMs and was applied to occupational data in the US economy using human annotators and GPT-4. The analysis shows that approximately 19% of jobs have at least 50% of their tasks exposed to LLMs. The findings also indicate that most occupations exhibit some degree of exposure to LLMs, with varying exposure levels across different types of work and industries. Occupations with higher wages generally present with higher exposure.\n",
      "\n",
      "The paper analyzes the potential impact of Large Language Models (LLMs) like GPT-4, finding that they are likely to be pervasive and have a wide impact, making them a general-purpose technology. The paper provides measurements of LLM impact potential and demonstrates the use case of applying LLMs to develop such measurements efficiently and at scale. The paper also discusses the potential challenges for policymakers to predict and regulate the eventual trajectory of LLM development and application. The paper is structured to review relevant prior work, discuss methods and data collection, present summary statistics and results, relate measurements to earlier efforts, discuss the results, and offer concluding remarks.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A study on the potential impact of large language models (LLMs) such as Generative Pre-trained Transformers (GPTs) on the US labor market found that around 80% of the US workforce could have at least 10% of their work tasks affected by the introduction of LLMs, while approximately 19% of workers may see at least 50% of their tasks impacted. The study proposes a rubric to assess LLM capabilities and their potential impact on jobs and discusses the potential economic, social, and policy implications of LLMs. The paper also analyzes the challenges for policymakers to predict and regulate the eventual trajectory of LLM development and application.'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", verbose=True)\n",
    "chain.run(job_doc[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b99505",
   "metadata": {},
   "source": [
    "### Summarize: Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = (\n",
    "    \"{question}\"\n",
    "    \"\\n\"\n",
    "    \"\\n\"\n",
    "    \"{text}\"\n",
    "    \"\\n\"\n",
    "    \"\\n\"\n",
    "    \"CONCISE SUMMARY:\"\n",
    ")\n",
    "\n",
    "refine_prompt_template = (\n",
    "    \"We have provided an existing summary up to a certain point: {existing_answer}\"\n",
    "    \"We have the opportunity to refine the existing summary (only if needed) with some more context below.\"\n",
    "    \"------------\"\n",
    "    \"{text}\"\n",
    "    \"------------\"\n",
    "    \"Given the new context, and the original summary, please answer {question}.\"\n",
    ")\n",
    "\n",
    "question_prompt = PromptTemplate.from_template(prompt_template)\n",
    "refine_prompt = PromptTemplate.from_template(refine_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3msummarize the document in 50 words\n",
      "\n",
      "WORKING PAPER\n",
      "GPTs are GPTs: An Early Look at the Labor Market Impact Potential\n",
      "of Large Language Models\n",
      "Tyna Eloundou1, Sam Manning1,2, Pamela Mishkin\u00001, and Daniel Rock3\n",
      "1OpenAI\n",
      "2OpenResearch\n",
      "3University of Pennsylvania\n",
      "August 22, 2023\n",
      "Abstract\n",
      "We investigate the potential implications of large language models (LLMs), such as Generative Pre-\n",
      "trained Transformers (GPTs), on the U.S. labor market, focusing on the increased capabilities arising from\n",
      "LLM-powered software compared to LLMs on their own. Using a new rubric, we assess occupations based\n",
      "on their alignment with LLM capabilities, integrating both human expertise and GPT-4 classiﬁcations.\n",
      "Our ﬁndings reveal that around 80% of the U.S. workforce could have at least 10% of their work tasks\n",
      "aﬀected by the introduction of LLMs, while approximately 19% of workers may see at least 50% of their\n",
      "tasks impacted. We do not make predictions about the development or adoption timeline of such LLMs.\n",
      "The projected e ﬀects span all wage levels, with higher-income jobs potentially facing greater exposure to\n",
      "LLM capabilities and LLM-powered software. Signiﬁcantly, these impacts are not restricted to industries\n",
      "with higher recent productivity growth. Our analysis suggests that, with access to an LLM, about 15%\n",
      "of all worker tasks in the US could be completed signiﬁcantly faster at the same level of quality. When\n",
      "incorporating software and tooling built on top of LLMs, this share increases to between 47 and 56%\n",
      "of all tasks. This ﬁnding implies that LLM-powered software will have a substantial e ﬀect on scaling\n",
      "the economic impacts of the underlying models. We conclude that LLMs such as GPTs exhibit traits of\n",
      "general-purpose technologies, indicating that they could have considerable economic, social, and policy\n",
      "implications.\n",
      "1 Introduction\n",
      "As shown in Figure 1, recent years, months, and weeks have seen remarkable progress in the ﬁeld of generative\n",
      "AI and large language models (LLMs). While the public often associates LLMs with various iterations of the\n",
      "Generative Pre-trained Transformer (GPT), LLMs can be trained using a range of architectures, and are not\n",
      "limited to transformer-based models (Devlin et al., 2019). LLMs can process and produce various forms of\n",
      "sequential data, including assembly language, protein sequences and chess games, extending beyond natural\n",
      "language applications alone. In this paper, we use LLMs and GPTs somewhat interchangeably, and specify in\n",
      "our rubric that these should be considered similar to the GPT-family of models available via ChatGPT or\n",
      "the OpenAI Playground (which at the time of labeling included models in the GPT-3.5 family but not in the\n",
      "GPT-4 family). We examine LLMs with text- and code-generating abilities, use the term \"generative AI\" to\n",
      "additionally include modalities such as images or audio, and use \"LLM-powered software\" to cover tools built\n",
      "on top of LLMs or that combine LLMs with other generative AI models.\n",
      "\u0000Corresponding author (pamela@openai.com). Authors contributed equally and are listed alphabetically.arXiv:2303.10130v5  [econ.GN]  21 Aug 2023WORKING PAPER\n",
      "Figure 1: Taken directly from GPT-4 Technical Report (OpenAI, 2023b). To get a sense of how quickly\n",
      "model capabilities are progressing – consider the jump in exam performance between GPT-3.5 and GPT-4\n",
      "(OpenAI, 2023b).\n",
      "Our study is motivated less by the progress of these models alone though, and more by the breadth,\n",
      "scale, and capabilities we’ve seen in the complementary technologies developed around them. The role of\n",
      "complementary technologies remains to be seen, but maximizing the impact of LLMs appears contingent\n",
      "on integrating them with larger systems (Bresnahan, 2019; Agrawal et al., 2021). While the focus of our\n",
      "discussion is primarily on the generative capabilities of LLMs, it is important to note that these models can\n",
      "also be utilized for various tasks beyond text generation. For example, embeddings from LLMs can be used\n",
      "for custom search applications, and LLMs can perform tasks such as summarization and classiﬁcation where\n",
      "the context may be largely contained in the prompt.\n",
      "To complement predictions of technology’s impacts on work and provide a framework for understanding\n",
      "the evolving landscape of language models and their associated technologies,\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWe have provided an existing summary up to a certain point: A working paper by OpenAI and the University of Pennsylvania examines the potential implications of large language models (LLMs), such as Generative Pre-trained Transformers (GPTs), on the US labor market. The study finds that around 80% of the US workforce could have at least 10% of their work tasks affected by the introduction of LLMs, while approximately 19% of workers may see at least 50% of their tasks impacted. The study suggests that LLMs exhibit traits of general-purpose technologies, indicating that they could have considerable economic, social, and policy implications.We have the opportunity to refine the existing summary (only if needed) with some more context below.------------ LLMs, it is important to note that these models can\n",
      "also be utilized for various tasks beyond text generation. For example, embeddings from LLMs can be used\n",
      "for custom search applications, and LLMs can perform tasks such as summarization and classiﬁcation where\n",
      "the context may be largely contained in the prompt.\n",
      "To complement predictions of technology’s impacts on work and provide a framework for understanding\n",
      "the evolving landscape of language models and their associated technologies, we propose a new rubric\n",
      "for assessing LLM capabilities and their potential e ﬀects on jobs. This rubric (A.1) measures the overall\n",
      "exposure of tasks to LLMs, following the spirit of prior work on quantifying exposure to machine learning\n",
      "(Brynjolfsson et al., 2018; Felten et al., 2018; Webb, 2020). We deﬁne exposure as a proxy for potential\n",
      "economic impact without distinguishing between labor-augmenting or labor-displacing e ﬀects. We employ\n",
      "human annotators and GPT-4 itself as a classiﬁer to apply this rubric to occupational data in the U.S. economy,\n",
      "primarily sourced from the O*NET database. 12\n",
      "To construct our primary exposure dataset, we collected both human annotations and GPT-4 classiﬁcations,\n",
      "using a prompt tuned for agreement with a sample of labels from the authors. We observe similar agreement\n",
      "1This is distinct from recent social science research that makes use of LLMs to simulate human behavior (Horton, 2023; Sorensen\n",
      "et al., 2022)\n",
      "2While our exposure rubric does not necessarily tie the concept of language models to any particular model, we were strongly\n",
      "motivated by our observed capabilities of GPT-4 and the suite of capabilities we saw in development with OpenAI’s launch partners\n",
      "(OpenAI, 2023b).WORKING PAPER\n",
      "levels in GPT-4 responses and between human and machine evaluations, when aggregated to the task level.\n",
      "This exposure measure reﬂects an estimate of the technical capacity to make human labor more e ﬃcient;\n",
      "however, social, economic, regulatory, and other determinants imply that technical feasibility does not\n",
      "guarantee labor productivity or automation outcomes. Our analysis indicates that approximately 19% of jobs\n",
      "have at least 50% of their tasks exposed when considering both current model capabilities and anticipated\n",
      "tools built upon them. Human assessments suggest that only 3% of U.S. workers have over half of their tasks\n",
      "exposed to LLMs when considering existing language and code capabilities without additional software or\n",
      "modalities. Accounting for other generative models and complementary technologies, our human estimates\n",
      "indicate that up to 49% of workers could have half or more of their tasks exposed to LLMs.\n",
      "Our ﬁndings consistently show across both human and GPT-4 annotations that most occupations exhibit\n",
      "some degree of exposure to LLMs, with varying exposure levels across di ﬀerent types of work. Occupations\n",
      "with higher wages generally present with higher exposure, a result contrary to similar evaluations of overall\n",
      "exposure to machine learning (Brynjolfsson et al., 2023). When regressing exposure measures on skillsets\n",
      "using O*NET’s skill rubric, we discover that roles heavily reliant on science and critical thinking skills show\n",
      "a negative correlation with exposure, while programming and writing skills are positively associated with\n",
      "LLM exposure. Following Autor et al. (2022a), we examine barriers to entry by \"Job Zones\" and ﬁnd that\n",
      "occupational exposure to LLMs weakly increases with the di ﬃculty of job preparation. In other words,\n",
      "workers facing higher (lower) barriers to entry in their jobs tend to experience more (less) exposure to LLMs.\n",
      "We further compare our measurements to previous e ﬀorts documenting the distribution of automation\n",
      "exposure in the economy and ﬁnd broadly consistent results. Most other technology exposure measures we\n",
      "examine are statistically signiﬁcantly correlated with our preferred exposure measure, while measures of\n",
      "manual routineness and robotics exposure show negative correlations. The variance explained by these earlier\n",
      "eﬀorts (Acemoglu and Autor, 2011a; Frey and Osborne, 2017; Brynjolfsson et al., 2018; Felten et al., 2018;\n",
      "Webb, 2020; Brynjolfsson et al., 2023), along with wage controls, ranges from 60 to 72%, indicating that 28\n",
      "to 40% of the variation in our AI exposure measure remains unaccounted for by previous technology exposure\n",
      "measurements.\n",
      "We analyze exposure by industry and discover that information processing industries (4-digit NAICS)\n",
      "exhibit high exposure, while manufacturing,------------Given the new context, and the original summary, please answer summarize the document in 50 words.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWe have provided an existing summary up to a certain point: A working paper by OpenAI and the University of Pennsylvania examines the potential implications of large language models (LLMs) on the US labor market. The study finds that up to 49% of workers could have half or more of their tasks exposed to LLMs, with occupations with higher wages presenting with higher exposure. The study suggests that LLMs exhibit traits of general-purpose technologies, indicating that they could have considerable economic, social, and policy implications.We have the opportunity to refine the existing summary (only if needed) with some more context below.------------njolfsson et al., 2018; Felten et al., 2018;\n",
      "Webb, 2020; Brynjolfsson et al., 2023), along with wage controls, ranges from 60 to 72%, indicating that 28\n",
      "to 40% of the variation in our AI exposure measure remains unaccounted for by previous technology exposure\n",
      "measurements.\n",
      "We analyze exposure by industry and discover that information processing industries (4-digit NAICS)\n",
      "exhibit high exposure, while manufacturing, agriculture, and mining demonstrate lower exposure. The\n",
      "connection between productivity growth in the past decade and overall LLM exposure appears weak, suggesting\n",
      "a potential optimistic case that future productivity gains from LLMs may not exacerbate possible cost disease\n",
      "eﬀects (Baumol, 2012; Aghion et al., 2018). 3\n",
      "Our analysis indicates that the impacts of LLMs like GPT-4, are likely to be pervasive. While LLMs\n",
      "have consistently improved in capabilities over time, their growing economic e ﬀect is expected to persist and\n",
      "increase even if we halt the development of new capabilities today. We also ﬁnd that the potential impact of\n",
      "LLMs expands signiﬁcantly when we take into account the development of complementary technologies.\n",
      "Collectively, these characteristics imply that Generative Pre-trained Transformers (GPTs) are general-purpose\n",
      "technologies (GPTs). 4(Bresnahan and Trajtenberg, 1995; Lipsey et al., 2005).\n",
      "(Goldfarb et al., 2023) argue that machine learning as a broad category is likely a general-purpose\n",
      "technology. Our evidence supports a wider impact, as even subsets of machine learning software meet thetechnology. Our evidence supports a wider impact, as even subsets of machine learning software meet the\n",
      "criteria for general-purpose technology status independently. This paper’s primary contributions are to provide\n",
      "a set of measurements of LLM impact potential and to demonstrate the use case of applying LLMs to develop\n",
      "such measurements e ﬃciently and at scale. Additionally, we showcase the general-purpose potential of LLMs.\n",
      "If \"GPTs are GPTs,\" the eventual trajectory of LLM development and application may be challenging for\n",
      "3Baumol’s cost disease is a theory that explains why the cost of labor-intensive services, such as healthcare and education,\n",
      "increases over time. This happens because wages for skilled workers in other industries increase, but there is no corresponding\n",
      "increase in productivity or e ﬃciency in these service industries. Therefore, the cost of labor in these industries becomes relatively\n",
      "more expensive compared to other goods and services in the economy.\n",
      "4For the remainder of the paper we spell out general-purpose technologies when it is used outside of stating \"GPTs are GPTs.\"WORKING PAPER\n",
      "policymakers to predict and regulate. As with other general-purpose technologies, much of these algorithms’\n",
      "potential will emerge across a broad range of economically valuable use cases, including the creation of new\n",
      "types of work (Acemoglu and Restrepo, 2018; Autor et al., 2022a). Our research serves to measure what is\n",
      "technically feasible now, but necessarily will miss the evolving impact potential of the LLMs over time.\n",
      "The paper is structured as follows: Section 2 reviews relevant prior work, Section 3 discusses methods\n",
      "and data collection, Section 4 presents summary statistics and results, Section 5 relates our measurements to\n",
      "earlier e ﬀorts, Section 6 discusses the results, and Section 7 o ﬀers concluding remarks.\n",
      "2 Literature Review\n",
      "2.1 The Advancement of Large Language Models\n",
      "In recent years, generative AI models have gained signiﬁcant attention from both the artiﬁcial intelligence\n",
      "(AI) research community and the general public, due to their ability to tackle a wide array of complex\n",
      "language-based tasks. The progress in these models’ abilities has been fueled by multiple factors, including\n",
      "increased model parameter count, greater training data volume, and enhanced training conﬁgurations (Brown\n",
      "et al., 2020; Radford et al., 2019; Hernandez et al., 2021; Kaplan et al., 2020). Broad, state-of-the-art LLMs,\n",
      "such as LaMDA (Thoppilan et al., 2022) and GPT-4 (OpenAI, 2023b), excel in diverse applications like\n",
      "translation, classiﬁcation, creative writing, and code generation—capabilities that previously demanded\n",
      "specialized, task-speciﬁc models developed by expert engineers using domain-speciﬁc data.\n",
      "Concurrently, researchers have improved the steerability, reliability, and utility of these models using\n",
      "methods like ﬁne-tuning and reinforcement------------Given the new context, and the original summary, please answer summarize the document in 50 words.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "A study by OpenAI and the University of Pennsylvania suggests that up to 49% of US workers could have half or more of their tasks exposed to large language models (LLMs), with higher-wage occupations presenting higher exposure. LLMs are thought to have considerable economic, social, and policy implications, and exhibit traits of general-purpose technologies. The study also finds that information processing industries have high exposure, while manufacturing, agriculture, and mining have lower exposure. Overall, the impact of LLMs is expected to persist and increase, even if new capabilities are not developed.\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type=\"refine\",\n",
    "    verbose=True,\n",
    "    question_prompt=question_prompt,\n",
    "    refine_prompt=refine_prompt,\n",
    ")\n",
    "query = \"summarize the document in 50 words\"\n",
    "summary_result = chain({\"input_documents\": job_doc[:3], \"question\": query})\n",
    "summary_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A study by OpenAI and the University of Pennsylvania suggests that up to 49% of US workers could have half or more of their tasks exposed to large language models (LLMs), with higher-wage occupations presenting higher exposure. LLMs are thought to have considerable economic, social, and policy implications, and exhibit traits of general-purpose technologies. The study also finds that information processing industries have high exposure, while manufacturing, agriculture, and mining have lower exposure. Overall, the impact of LLMs is expected to persist and increase, even if new capabilities are not developed.\n"
     ]
    }
   ],
   "source": [
    "print(summary_result['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question-Answering: Map Re-reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapRerankDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "WORKING PAPER\n",
      "GPTs are GPTs: An Early Look at the Labor Market Impact Potential\n",
      "of Large Language Models\n",
      "Tyna Eloundou1, Sam Manning1,2, Pamela Mishkin\u00001, and Daniel Rock3\n",
      "1OpenAI\n",
      "2OpenResearch\n",
      "3University of Pennsylvania\n",
      "August 22, 2023\n",
      "Abstract\n",
      "We investigate the potential implications of large language models (LLMs), such as Generative Pre-\n",
      "trained Transformers (GPTs), on the U.S. labor market, focusing on the increased capabilities arising from\n",
      "LLM-powered software compared to LLMs on their own. Using a new rubric, we assess occupations based\n",
      "on their alignment with LLM capabilities, integrating both human expertise and GPT-4 classiﬁcations.\n",
      "Our ﬁndings reveal that around 80% of the U.S. workforce could have at least 10% of their work tasks\n",
      "aﬀected by the introduction of LLMs, while approximately 19% of workers may see at least 50% of their\n",
      "tasks impacted. We do not make predictions about the development or adoption timeline of such LLMs.\n",
      "The projected e ﬀects span all wage levels, with higher-income jobs potentially facing greater exposure to\n",
      "LLM capabilities and LLM-powered software. Signiﬁcantly, these impacts are not restricted to industries\n",
      "with higher recent productivity growth. Our analysis suggests that, with access to an LLM, about 15%\n",
      "of all worker tasks in the US could be completed signiﬁcantly faster at the same level of quality. When\n",
      "incorporating software and tooling built on top of LLMs, this share increases to between 47 and 56%\n",
      "of all tasks. This ﬁnding implies that LLM-powered software will have a substantial e ﬀect on scaling\n",
      "the economic impacts of the underlying models. We conclude that LLMs such as GPTs exhibit traits of\n",
      "general-purpose technologies, indicating that they could have considerable economic, social, and policy\n",
      "implications.\n",
      "1 Introduction\n",
      "As shown in Figure 1, recent years, months, and weeks have seen remarkable progress in the ﬁeld of generative\n",
      "AI and large language models (LLMs). While the public often associates LLMs with various iterations of the\n",
      "Generative Pre-trained Transformer (GPT), LLMs can be trained using a range of architectures, and are not\n",
      "limited to transformer-based models (Devlin et al., 2019). LLMs can process and produce various forms of\n",
      "sequential data, including assembly language, protein sequences and chess games, extending beyond natural\n",
      "language applications alone. In this paper, we use LLMs and GPTs somewhat interchangeably, and specify in\n",
      "our rubric that these should be considered similar to the GPT-family of models available via ChatGPT or\n",
      "the OpenAI Playground (which at the time of labeling included models in the GPT-3.5 family but not in the\n",
      "GPT-4 family). We examine LLMs with text- and code-generating abilities, use the term \"generative AI\" to\n",
      "additionally include modalities such as images or audio, and use \"LLM-powered software\" to cover tools built\n",
      "on top of LLMs or that combine LLMs with other generative AI models.\n",
      "\u0000Corresponding author (pamela@openai.com). Authors contributed equally and are listed alphabetically.arXiv:2303.10130v5  [econ.GN]  21 Aug 2023WORKING PAPER\n",
      "Figure 1: Taken directly from GPT-4 Technical Report (OpenAI, 2023b). To get a sense of how quickly\n",
      "model capabilities are progressing – consider the jump in exam performance between GPT-3.5 and GPT-4\n",
      "(OpenAI, 2023b).\n",
      "Our study is motivated less by the progress of these models alone though, and more by the breadth,\n",
      "scale, and capabilities we’ve seen in the complementary technologies developed around them. The role of\n",
      "complementary technologies remains to be seen, but maximizing the impact of LLMs appears contingent\n",
      "on integrating them with larger systems (Bresnahan, 2019; Agrawal et al., 2021). While the focus of our\n",
      "discussion is primarily on the generative capabilities of LLMs, it is important to note that these models can\n",
      "also be utilized for various tasks beyond text generation. For example, embeddings from LLMs can be used\n",
      "for custom search applications, and LLMs can perform tasks such as summarization and classiﬁcation where\n",
      "the context may be largely contained in the prompt.\n",
      "To complement predictions of technology’s impacts on work and provide a framework for understanding\n",
      "the evolving landscape of language models and their associated technologies,\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      " LLMs, it is important to note that these models can\n",
      "also be utilized for various tasks beyond text generation. For example, embeddings from LLMs can be used\n",
      "for custom search applications, and LLMs can perform tasks such as summarization and classiﬁcation where\n",
      "the context may be largely contained in the prompt.\n",
      "To complement predictions of technology’s impacts on work and provide a framework for understanding\n",
      "the evolving landscape of language models and their associated technologies, we propose a new rubric\n",
      "for assessing LLM capabilities and their potential e ﬀects on jobs. This rubric (A.1) measures the overall\n",
      "exposure of tasks to LLMs, following the spirit of prior work on quantifying exposure to machine learning\n",
      "(Brynjolfsson et al., 2018; Felten et al., 2018; Webb, 2020). We deﬁne exposure as a proxy for potential\n",
      "economic impact without distinguishing between labor-augmenting or labor-displacing e ﬀects. We employ\n",
      "human annotators and GPT-4 itself as a classiﬁer to apply this rubric to occupational data in the U.S. economy,\n",
      "primarily sourced from the O*NET database. 12\n",
      "To construct our primary exposure dataset, we collected both human annotations and GPT-4 classiﬁcations,\n",
      "using a prompt tuned for agreement with a sample of labels from the authors. We observe similar agreement\n",
      "1This is distinct from recent social science research that makes use of LLMs to simulate human behavior (Horton, 2023; Sorensen\n",
      "et al., 2022)\n",
      "2While our exposure rubric does not necessarily tie the concept of language models to any particular model, we were strongly\n",
      "motivated by our observed capabilities of GPT-4 and the suite of capabilities we saw in development with OpenAI’s launch partners\n",
      "(OpenAI, 2023b).WORKING PAPER\n",
      "levels in GPT-4 responses and between human and machine evaluations, when aggregated to the task level.\n",
      "This exposure measure reﬂects an estimate of the technical capacity to make human labor more e ﬃcient;\n",
      "however, social, economic, regulatory, and other determinants imply that technical feasibility does not\n",
      "guarantee labor productivity or automation outcomes. Our analysis indicates that approximately 19% of jobs\n",
      "have at least 50% of their tasks exposed when considering both current model capabilities and anticipated\n",
      "tools built upon them. Human assessments suggest that only 3% of U.S. workers have over half of their tasks\n",
      "exposed to LLMs when considering existing language and code capabilities without additional software or\n",
      "modalities. Accounting for other generative models and complementary technologies, our human estimates\n",
      "indicate that up to 49% of workers could have half or more of their tasks exposed to LLMs.\n",
      "Our ﬁndings consistently show across both human and GPT-4 annotations that most occupations exhibit\n",
      "some degree of exposure to LLMs, with varying exposure levels across di ﬀerent types of work. Occupations\n",
      "with higher wages generally present with higher exposure, a result contrary to similar evaluations of overall\n",
      "exposure to machine learning (Brynjolfsson et al., 2023). When regressing exposure measures on skillsets\n",
      "using O*NET’s skill rubric, we discover that roles heavily reliant on science and critical thinking skills show\n",
      "a negative correlation with exposure, while programming and writing skills are positively associated with\n",
      "LLM exposure. Following Autor et al. (2022a), we examine barriers to entry by \"Job Zones\" and ﬁnd that\n",
      "occupational exposure to LLMs weakly increases with the di ﬃculty of job preparation. In other words,\n",
      "workers facing higher (lower) barriers to entry in their jobs tend to experience more (less) exposure to LLMs.\n",
      "We further compare our measurements to previous e ﬀorts documenting the distribution of automation\n",
      "exposure in the economy and ﬁnd broadly consistent results. Most other technology exposure measures we\n",
      "examine are statistically signiﬁcantly correlated with our preferred exposure measure, while measures of\n",
      "manual routineness and robotics exposure show negative correlations. The variance explained by these earlier\n",
      "eﬀorts (Acemoglu and Autor, 2011a; Frey and Osborne, 2017; Brynjolfsson et al., 2018; Felten et al., 2018;\n",
      "Webb, 2020; Brynjolfsson et al., 2023), along with wage controls, ranges from 60 to 72%, indicating that 28\n",
      "to 40% of the variation in our AI exposure measure remains unaccounted for by previous technology exposure\n",
      "measurements.\n",
      "We analyze exposure by industry and discover that information processing industries (4-digit NAICS)\n",
      "exhibit high exposure, while manufacturing,\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "njolfsson et al., 2018; Felten et al., 2018;\n",
      "Webb, 2020; Brynjolfsson et al., 2023), along with wage controls, ranges from 60 to 72%, indicating that 28\n",
      "to 40% of the variation in our AI exposure measure remains unaccounted for by previous technology exposure\n",
      "measurements.\n",
      "We analyze exposure by industry and discover that information processing industries (4-digit NAICS)\n",
      "exhibit high exposure, while manufacturing, agriculture, and mining demonstrate lower exposure. The\n",
      "connection between productivity growth in the past decade and overall LLM exposure appears weak, suggesting\n",
      "a potential optimistic case that future productivity gains from LLMs may not exacerbate possible cost disease\n",
      "eﬀects (Baumol, 2012; Aghion et al., 2018). 3\n",
      "Our analysis indicates that the impacts of LLMs like GPT-4, are likely to be pervasive. While LLMs\n",
      "have consistently improved in capabilities over time, their growing economic e ﬀect is expected to persist and\n",
      "increase even if we halt the development of new capabilities today. We also ﬁnd that the potential impact of\n",
      "LLMs expands signiﬁcantly when we take into account the development of complementary technologies.\n",
      "Collectively, these characteristics imply that Generative Pre-trained Transformers (GPTs) are general-purpose\n",
      "technologies (GPTs). 4(Bresnahan and Trajtenberg, 1995; Lipsey et al., 2005).\n",
      "(Goldfarb et al., 2023) argue that machine learning as a broad category is likely a general-purpose\n",
      "technology. Our evidence supports a wider impact, as even subsets of machine learning software meet thetechnology. Our evidence supports a wider impact, as even subsets of machine learning software meet the\n",
      "criteria for general-purpose technology status independently. This paper’s primary contributions are to provide\n",
      "a set of measurements of LLM impact potential and to demonstrate the use case of applying LLMs to develop\n",
      "such measurements e ﬃciently and at scale. Additionally, we showcase the general-purpose potential of LLMs.\n",
      "If \"GPTs are GPTs,\" the eventual trajectory of LLM development and application may be challenging for\n",
      "3Baumol’s cost disease is a theory that explains why the cost of labor-intensive services, such as healthcare and education,\n",
      "increases over time. This happens because wages for skilled workers in other industries increase, but there is no corresponding\n",
      "increase in productivity or e ﬃciency in these service industries. Therefore, the cost of labor in these industries becomes relatively\n",
      "more expensive compared to other goods and services in the economy.\n",
      "4For the remainder of the paper we spell out general-purpose technologies when it is used outside of stating \"GPTs are GPTs.\"WORKING PAPER\n",
      "policymakers to predict and regulate. As with other general-purpose technologies, much of these algorithms’\n",
      "potential will emerge across a broad range of economically valuable use cases, including the creation of new\n",
      "types of work (Acemoglu and Restrepo, 2018; Autor et al., 2022a). Our research serves to measure what is\n",
      "technically feasible now, but necessarily will miss the evolving impact potential of the LLMs over time.\n",
      "The paper is structured as follows: Section 2 reviews relevant prior work, Section 3 discusses methods\n",
      "and data collection, Section 4 presents summary statistics and results, Section 5 relates our measurements to\n",
      "earlier e ﬀorts, Section 6 discusses the results, and Section 7 o ﬀers concluding remarks.\n",
      "2 Literature Review\n",
      "2.1 The Advancement of Large Language Models\n",
      "In recent years, generative AI models have gained signiﬁcant attention from both the artiﬁcial intelligence\n",
      "(AI) research community and the general public, due to their ability to tackle a wide array of complex\n",
      "language-based tasks. The progress in these models’ abilities has been fueled by multiple factors, including\n",
      "increased model parameter count, greater training data volume, and enhanced training conﬁgurations (Brown\n",
      "et al., 2020; Radford et al., 2019; Hernandez et al., 2021; Kaplan et al., 2020). Broad, state-of-the-art LLMs,\n",
      "such as LaMDA (Thoppilan et al., 2022) and GPT-4 (OpenAI, 2023b), excel in diverse applications like\n",
      "translation, classiﬁcation, creative writing, and code generation—capabilities that previously demanded\n",
      "specialized, task-speciﬁc models developed by expert engineers using domain-speciﬁc data.\n",
      "Concurrently, researchers have improved the steerability, reliability, and utility of these models using\n",
      "methods like ﬁne-tuning and reinforcement\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      " and GPT-4 (OpenAI, 2023b), excel in diverse applications like\n",
      "translation, classiﬁcation, creative writing, and code generation—capabilities that previously demanded\n",
      "specialized, task-speciﬁc models developed by expert engineers using domain-speciﬁc data.\n",
      "Concurrently, researchers have improved the steerability, reliability, and utility of these models using\n",
      "methods like ﬁne-tuning and reinforcement learning with human feedback (Ouyang et al., 2022; Bai et al.,\n",
      "2022). These advancements enhance the models’ ability to discern user intent, rendering them more\n",
      "user-friendly and practical. Moreover, recent studies reveal the potential of LLMs to program and control\n",
      "other digital tools, such as APIs, search engines, and even other generative AI systems (Schick et al., 2023;\n",
      "Mialon et al., 2023; Chase, 2022). This enables seamless integration of individual components for better\n",
      "utility, performance, and generalization. At their limit, these trends suggest a world where LLMs may be\n",
      "capable of executing any task typically performed at a computer.\n",
      "Generative AI models have mostly been deployed as modular specialists, performing speciﬁc tasks such as\n",
      "generating images from captions or transcribing text from speech. However, we argue that it is essential to view\n",
      "LLMs as versatile building blocks for creating additional tools. Developing these tools and integrating them\n",
      "into systems will require time and possibly signiﬁcant reconﬁguration of existing processes across various\n",
      "industries. Nevertheless, we are already witnessing emerging adoption trends. Despite their limitations,\n",
      "LLMs are increasingly being integrated into specialized applications in ﬁelds like writing assistance, coding,\n",
      "and legal research. These specialized applications then allow businesses and individuals to adopt LLMs into\n",
      "their workﬂows.\n",
      "We emphasize the signiﬁcance of these complementary technologies, partly because out-of-the-box\n",
      "general-purpose LLMs may continue to be unreliable for various tasks due to issues such as factual inaccuracies,\n",
      "inherent biases, privacy concerns, and disinformation risks (Abid et al., 2021; Schramowski et al., 2022;\n",
      "Goldstein et al., 2023; OpenAI, 2023a). However, specialized workﬂows—including tooling, software, or\n",
      "human-in-the-loop systems—can help address these shortcomings by incorporating domain-speciﬁc expertise.\n",
      "For example, Casetext o ﬀers LLM-based legal research tools that provide lawyers with quicker and more\n",
      "accurate legal research results, utilizing embeddings and summarization to counter the risk that GPT-4 couldaccurate legal research results, utilizing embeddings and summarization to counter the risk that GPT-4 could\n",
      "provide inaccurate details about a legal case or set of documents. GitHub Copilot is a coding assistant that\n",
      "employs LLMs to generate code snippets and auto-complete code, which users can then accept or reject based\n",
      "on their expertise. In other words, while it’s true that on its own GPT-4 does not \"know what time it is,\" it’s\n",
      "easy enough to give it a watch.WORKING PAPER\n",
      "Furthermore, a positive feedback loop may emerge as LLMs surpass a speciﬁc performance threshold,\n",
      "allowing them to assist in building the very tooling that enhances their usefulness and usability across various\n",
      "contexts. This could lower the cost and engineering expertise required to create such tools, potentially\n",
      "accelerating LLM adoption and integration even further (Chen et al., 2021; Peng et al., 2023). LLMs can also\n",
      "become valuable assets in machine learning model development—serving as coding assistants for researchers,\n",
      "data labeling services, or synthetic data generators. There is potential for such models to contribute to\n",
      "economic decision-making at the task level, for instance, by reﬁning methods for task and sub-task allocation\n",
      "between humans and machines (Singla et al., 2015; Shahaf and Horvitz, 2010). As LLMs advance over time\n",
      "and better align with user preferences, we can anticipate continuous improvement in performance. However, it\n",
      "is essential to recognize that these trends also bring a variety of serious risks. (Khlaaf et al., 2022; Weidinger\n",
      "et al., 2022; Solaiman et al., 2019)\n",
      "2.2 The Economic Impacts of Automation Technologies\n",
      "A large and growing body of literature addresses the labor market impacts of AI and automation technologies.\n",
      "The concept of skill-biased technological change and the task model of automation—often considered\n",
      "the standard framework for understanding technology’s inﬂuence on labor—originated from research\n",
      "\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      " risks. (Khlaaf et al., 2022; Weidinger\n",
      "et al., 2022; Solaiman et al., 2019)\n",
      "2.2 The Economic Impacts of Automation Technologies\n",
      "A large and growing body of literature addresses the labor market impacts of AI and automation technologies.\n",
      "The concept of skill-biased technological change and the task model of automation—often considered\n",
      "the standard framework for understanding technology’s inﬂuence on labor—originated from research\n",
      "demonstrating that technological progress raises the demand for skilled workers over unskilled workers (Katz\n",
      "and Murphy, 1992). Numerous studies have built upon this concept, exploring the e ﬀects of technological\n",
      "change and automation on workers within a task-based framework (Autor et al., 2003; Acemoglu and Autor,\n",
      "2011b; Acemoglu and Restrepo, 2018). This strand of research has shown that workers involved in routine and\n",
      "repetitive tasks are at a higher risk of technology-driven displacement, a phenomenon known as routine-biased\n",
      "technological change. More recent studies have distinguished between technology’s task-displacement and\n",
      "task-reinstatement e ﬀects (where new technology increases the need for a wider array of labor-intensive tasks)\n",
      "(Acemoglu and Restrepo, 2018, 2019). Several studies have shown that automation technologies have resulted\n",
      "in wage inequality in the US, driven by relative wage declines for workers specializing in routine tasks (Autor\n",
      "et al., 2006; Van Reenen, 2011; Acemoglu and Restrepo, 2022b).\n",
      "Prior research has employed various approaches to estimate the overlap between AI capabilities and\n",
      "the tasks and activities workers undertake in di ﬀerent occupations. These methods include mapping patent\n",
      "descriptions to worker task descriptions (Webb, 2020; Meindl et al., 2021), linking AI capabilities to\n",
      "occupational abilities documented in the O*NET database (Felten et al., 2018, 2023), aligning AI task\n",
      "benchmark evaluations with worker tasks via cognitive abilities (Tolan et al., 2021), labeling automation\n",
      "potential for a subset of US occupations and using machine learning classiﬁers to estimate this potential for\n",
      "all other US occupations (Frey and Osborne, 2017), modeling task-level automation and aggregating the\n",
      "results to occupation-level insights (Arntz et al., 2017), collecting expert forecasts (Grace et al., 2018), and\n",
      "most relevantly to this paper, devising a new rubric to assess worker activities for their suitability for machine\n",
      "learning (Brynjolfsson et al., 2018, 2023). Some of these approaches have found exposure to AI technologies\n",
      "at the task-level tends to be diversiﬁed within occupation. Considering each job as a bundle of tasks, it would\n",
      "be rare to ﬁnd any occupation for which AI tools could do nearly all of the work. (Autor et al., 2022a) ﬁnds as\n",
      "well that automation and augmentation exposures tend to be positively correlated. There is also a growing setwell that automation and augmentation exposures tend to be positively correlated. There is also a growing set\n",
      "of studies examining speciﬁc economic impacts and opportunities for LLMs (Bommasani et al., 2021; Felten\n",
      "et al., 2023; Korinek, 2023; Mollick and Mollick, 2022; Noy and Zhang, 2023; Peng et al., 2023). Alongside\n",
      "this work, our measurements help characterize the broader potential relevance of language models to the\n",
      "labor market.\n",
      "General-purpose technologies (e.g. printing, the steam engine) are characterized by widespread prolifera-\n",
      "tion, continuous improvement, and the generation of complementary innovations (Bresnahan and Trajtenberg,\n",
      "1995; Lipsey et al., 2005). Their far-reaching consequences, which unfold over decades, are di ﬃcult to\n",
      "anticipate, particularly in relation to labor demand (Bessen, 2018; Korinek and Stiglitz, 2018; Acemoglu et al.,WORKING PAPER\n",
      "2020; Benzell et al., 2021). The realization of general purpose technologies’ full potential requires extensive\n",
      "co-invention (Bresnahan and Trajtenberg, 1995; Bresnahan et al., 1996, 2002; Lipsey et al., 2005; Dixon et al.,\n",
      "2021), a costly and time-consuming process involving the discovery of new business procedures (David, 1990;\n",
      "Bresnahan, 1999; Frey, 2019; Brynjolfsson et al., 2021; Feigenbaum and Gross, 2021). Consequently, many\n",
      "studies of machine learning technologies focus on systems-level adoption, arguing that organizational systems\n",
      "may require redesign to e �\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "ahan et al., 1996, 2002; Lipsey et al., 2005; Dixon et al.,\n",
      "2021), a costly and time-consuming process involving the discovery of new business procedures (David, 1990;\n",
      "Bresnahan, 1999; Frey, 2019; Brynjolfsson et al., 2021; Feigenbaum and Gross, 2021). Consequently, many\n",
      "studies of machine learning technologies focus on systems-level adoption, arguing that organizational systems\n",
      "may require redesign to e ﬀectively take advantage of novel machine learning advancements (Bresnahan,\n",
      "2019; Agrawal et al., 2021; Goldfarb et al., 2023). Appropriately designed systems can yield considerable\n",
      "business value and improve ﬁrm performance (Rock, 2019; Babina et al., 2021; Zolas et al., 2021), with AI\n",
      "tools facilitating the discovery process (Cockburn et al., 2018; Cheng et al., 2022). By employing task-level\n",
      "information to assess whether LLMs fulﬁll the criteria of a general purpose technology, we seek to merge the\n",
      "two perspectives for understanding the technology-labor relationship.\n",
      "We attempt to build on these diverse literature streams in several ways. Echoing (Felten et al., 2023), we\n",
      "focus our analysis on the impact of LLMs, rather than addressing machine learning or automation technologies\n",
      "more broadly. Additionally, we propose a novel method that employs LLMs, speciﬁcally GPT-4, to assess tasks\n",
      "for exposure and automation potential, thereby bolstering human scoring e ﬀorts. Subsequently, we aggregate\n",
      "our ﬁndings to occupations and industries, capturing the overall potential exposure in the contemporary U.S.\n",
      "labor market.\n",
      "3 Methods and Data Collection\n",
      "3.1 Data on Activities and Tasks Performed by Occupation in the US\n",
      "We use the O*NET 27.2 database (O*NET, 2023), which contains information on 1,016 occupations, including\n",
      "their respective Detailed Work Activities (DWAs) and tasks. A DWA is a comprehensive action that is part of\n",
      "completing task, such as \"Study scripts to determine project requirements.\" A task, on the other hand, is an\n",
      "occupation-speciﬁc unit of work that may be associated with zero, one, or multiple DWAs. We o ﬀer a sample\n",
      "of tasks and DWAs in Table 1. The two datasets we use consist of:\n",
      "•19,265 tasks, consisting of a \"task description\" and a corresponding occupation, and\n",
      "•2,087 DWAs, where most DWAs are connected to one or more tasks, and tasks may be associated with\n",
      "one or more DWAs, though some tasks lack any associated DWAs.\n",
      "3.2 Data on Wages, Employment, and Demographics\n",
      "We obtain employment and wage data from the 2020 and 2021 Occupational Employment series provided by\n",
      "the Bureau of Labor Statistics. This dataset encompasses occupational titles, the number of workers in each\n",
      "occupation, and occupation-level employment projections for 2031, typical education required for entry in an\n",
      "occupation and on-the-job training required to attain competency in an occupation (BLS, 2022). We use the\n",
      "BLS-recommended crosswalk to O*NET (BLS, 2023b) to link the O*NET task and DWA dataset and the\n",
      "BLS Labor Force Demographics (BLS, 2023a), which is derived from the Current Population Survey (CPS).\n",
      "Both of these data sources are collected by the U.S. government and primarily capture workers who are not\n",
      "self-employed, are documented, and are working in the so-called formal economy.\n",
      "3.3 Exposure\n",
      "We present our results based on an exposure rubric, in which we deﬁne exposure as a measure of whether\n",
      "access to an LLM or LLM-powered system would reduce the time required for a human to perform a speciﬁcWORKING PAPER\n",
      "Task ID Occupation Title DWAs Task Description\n",
      "14675 Computer Systems\n",
      "Engineers/ArchitectsMonitor computer system performance\n",
      "to ensure proper operation.Monitor system operation to detect potential\n",
      "problems.\n",
      "18310 Acute Care Nurses Operate diagnostic or therapeutic\n",
      "medical instruments or equipment.\n",
      "Prepare medical supplies or equipment\n",
      "for use.Set up, operate, or monitor invasive equipment\n",
      "and devices, such as colostomy or tracheotomy\n",
      "equipment, mechanical ventilators, catheters,\n",
      "gastrointestinal tubes, and central lines.\n",
      "4668.0 Gambling Cage\n",
      "WorkersExecute sales or other ﬁnancial\n",
      "transactions.Cash checks and process credit card advances\n",
      "for patrons.\n",
      "15709 Online Merchants Execute sales or other ﬁnancial\n",
      "transactions.Deliver\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      " operate, or monitor invasive equipment\n",
      "and devices, such as colostomy or tracheotomy\n",
      "equipment, mechanical ventilators, catheters,\n",
      "gastrointestinal tubes, and central lines.\n",
      "4668.0 Gambling Cage\n",
      "WorkersExecute sales or other ﬁnancial\n",
      "transactions.Cash checks and process credit card advances\n",
      "for patrons.\n",
      "15709 Online Merchants Execute sales or other ﬁnancial\n",
      "transactions.Deliver e-mail conﬁrmation of completed\n",
      "transactions and shipment.\n",
      "6529 Kindergarten\n",
      "Teachers, Except\n",
      "Special Education– Involve parent volunteers and older students in\n",
      "children’s activities to facilitate involvement in\n",
      "focused, complex play.\n",
      "6568 Elementary School\n",
      "Teachers, Except\n",
      "Special Education– Involve parent volunteers and older students in\n",
      "children’s activities to facilitate involvement in\n",
      "focused, complex play.\n",
      "Table 1: Sample of occupations, tasks, and Detailed Work Activities from the O*NET database. We see\n",
      "that aggregating over activities alone is imprecise, as evidenced by the fact that we’d expect Gambling Cage\n",
      "Workers to complete the given DWA in person, using some physicality while we’d expect Online Merchants\n",
      "to complete the same activity solely with a computer.\n",
      "DWA or complete a task by at least 50 percent. Though GPT-4 has vision capabilities OpenAI (2023b) and\n",
      "\"LLM\" is often used to refer to a much wider range of modalities, vision and image capabilities were only\n",
      "included in our deﬁnition of LLM-powered software. We provide a summary of our rubric below, while the\n",
      "complete rubric can be found in A.1. When we have labels for DWAs, we ﬁrst aggregate them to the task\n",
      "level before aggregating to the occupation level.\n",
      "No exposure (E0) if:\n",
      "•using the described LLM results in no or minimal reduction in the time required to\n",
      "complete the activity or task while maintaining equivalent qualityaor\n",
      "•using the described LLM results in a decrease in the quality of the activity/task output.\n",
      "Direct exposure (E1) if:\n",
      "•using the described LLM via ChatGPT or the OpenAI playground can decrease the time\n",
      "required to complete the DWA or task by at least half (50%).\n",
      "LLM+ Exposed (E2) if:\n",
      "•access to the described LLM alone would not reduce the time required to complete the\n",
      "activity/task by at least half, but\n",
      "•additional software could be developed on top of the LLM that could reduce the time it\n",
      "takes to complete the speciﬁc activity/task with quality by at least half. Among these\n",
      "systems, we count access to image generation systems.b\n",
      "aEquivalent quality means that a third party, typically the recipient of the output, would not notice or\n",
      "care about LLM assistance.\n",
      "bIn practice, as can be seen in the full rubric in Appendix A.1, we categorize access to image capabilities\n",
      "separately (E3) to facilitate annotation, though we combine E2 and E3 for all analyses.Summary of exposure rubric\n",
      "We set the exposure threshold at a potential 50% reduction in time required to complete a speciﬁc DWAWORKING PAPER\n",
      "or task while maintaining consistent quality. We anticipate that adoption will be highest and most immediate\n",
      "for applications that realize a considerable increase in productivity. Although this threshold is somewhat\n",
      "arbitrary, it was selected for ease of interpretation by annotators. Moreover, regardless of the chosen threshold,\n",
      "we guessed that the real-world reduction in task time would likely be slightly or signiﬁcantly lower than our\n",
      "estimates, leading us to opt for a relatively high threshold. In our own validation labeling, we found that this\n",
      "corresponded closely to whether an LLM or LLM-powered software could perform the core part of a task or\n",
      "nearly the entire task.\n",
      "Comparison WWeighting Agreement Pearson’s\n",
      "GPT-4, Rubric 1; Human UE1 80.8% 0.223\n",
      "VE1 + .5*E2 65.6% 0.591\n",
      "ZE1 + E2 82.1% 0.654\n",
      "GPT-4, Rubric 2; Human UE1 81.8% 0.221\n",
      "VE1 + .5*E2 65.6% 0.538\n",
      "ZE1 + E2 79.5% 0.589\n",
      "GPT-4, Rubric 1; GPT-4, Rubric 2 UE1 91.1% 0.611\n",
      "VE1 + .5*E2 76.0% 0.705\n",
      "ZE1 + E2 82.4\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "PT-4, Rubric 2; Human UE1 81.8% 0.221\n",
      "VE1 + .5*E2 65.6% 0.538\n",
      "ZE1 + E2 79.5% 0.589\n",
      "GPT-4, Rubric 1; GPT-4, Rubric 2 UE1 91.1% 0.611\n",
      "VE1 + .5*E2 76.0% 0.705\n",
      "ZE1 + E2 82.4% 0.680\n",
      "Table 2: Model and human comparison of agreement and Pearson’s correlation scores. The agreement score\n",
      "is determined by looking at how often the two groups agree on the annotation (e.g. E0, E1 or E2). In the\n",
      "paper we use GPT-4, Rubric 1. Core tasks are given twice the weight at the occupation-level as supplemental\n",
      "tasks. All weights sum to one.\n",
      "We then collected both human and GPT-4-generated annotations using the exposure rubric, which underlie\n",
      "the bulk of the analyses in this paper.\n",
      "•Human Ratings: We obtained human annotations by applying the rubric to each O*NET Detailed\n",
      "Worker Activity (DWA) and a subset of all O*NET tasks and then aggregated those DWA and task\n",
      "scores 5at the task and occupation levels. The authors personally labeled a large sample of tasks and\n",
      "DWAs and enlisted experienced human annotators who have reviewed GPT-3, GPT-3.5 and GPT-4\n",
      "outputs as part of OpenAI’s alignment work (Ouyang et al., 2022).\n",
      "•GPT-4 Ratings: We administered a similar rubric to an early version of GPT-4 (OpenAI, 2023b) but on\n",
      "all task/occupation pairs rather than DWAs. We made slight modiﬁcations to the rubric (which was\n",
      "used as a \"prompt\" to the model in this case) to enhance agreement with a set of human labels. Full\n",
      "agreement rates are given in Table 2.\n",
      "We construct three primary measures for our dependent variable of interest: (i) U, corresponding to E1 in\n",
      "the exposure rubric above, anticipated to represent the lower bound of the proportion of exposed tasks within\n",
      "an occupation, (ii) V, which is the sum of E1 and 0.5*E2, where the 0.5 weight on E2 is intended to account\n",
      "for exposure when deploying the technology via complementary tools and applications necessitates additional\n",
      "investment, and (iii) Z, the sum of E1 and E2, an upper bound of exposure that provides an assessment of\n",
      "maximal exposure to an LLLM and LLM-powered software. We summarize agreement between annotation\n",
      "groups and measures in Table 2. For the remainder of the analysis, if not speciﬁed, the reader may assume that\n",
      "5The authors annotated DWAs that clearly required a high degree of physicality or manual dexterity, and the contracted annotators\n",
      "labeled the remaining activities, along with a subset of tasks including those without associated DWAs and those for which there was\n",
      "no clear task-level annotation after aggregating the DWA annotations.WORKING PAPER\n",
      "we refer to Vexposure – meaning all tasks directly exposed via tools like ChatGPT or the OpenAI Playground\n",
      "are considered twice as exposed as tasks requiring some complementary innovation.\n",
      "3.4 Limitations of our methodology\n",
      "3.4.1 Subjective human judgments\n",
      "A fundamental limitation of our approach lies in the subjectivity of the labeling. In our study, we employ\n",
      "annotators who are familiar with LLM capabilities. However, this group is not occupationally diverse,\n",
      "potentially leading to biased judgments regarding LLMs’ reliability and e ﬀectiveness in performing tasks\n",
      "within unfamiliar occupations. We acknowledge that obtaining high-quality labels for each task in an\n",
      "occupation requires workers engaged in those occupations or, at a minimum, possessing in-depth knowledge\n",
      "of the diverse tasks within those occupations. This represents an important area for future work in validating\n",
      "these results.\n",
      "3.4.2 Measuring LLMs with GPT-4\n",
      "Recent research indicates that GPT-4 serves as an e ﬀective discriminator, capable of applying intricate\n",
      "taxonomies and responding to changes in wording and emphasis (OpenAI, 2023b). The outcomes of GPT-4\n",
      "task classiﬁcation are sensitive to alterations in the rubric’s wording, the prompt’s order and composition, the\n",
      "presence or absence of speciﬁc examples in the rubric, the level of detail provided, and the deﬁnitions given\n",
      "for key terms. Iterating on the prompt, based on observed outcomes in a small validation set, can\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "OpenAI, 2023b). The outcomes of GPT-4\n",
      "task classiﬁcation are sensitive to alterations in the rubric’s wording, the prompt’s order and composition, the\n",
      "presence or absence of speciﬁc examples in the rubric, the level of detail provided, and the deﬁnitions given\n",
      "for key terms. Iterating on the prompt, based on observed outcomes in a small validation set, can enhance the\n",
      "agreement between model outputs and the rubric’s intent. Consequently, there are slight di ﬀerences between\n",
      "the rubric presented to humans and the one used for GPT-4. This decision was made deliberately to guide\n",
      "the model towards reasonable labels without excessively inﬂuencing human annotators. As a result, we use\n",
      "multiple annotation sources, but none should be considered the deﬁnitive ground truth relative to the others.\n",
      "In this analysis, we present results from human annotators as our primary results. Further improvement and\n",
      "innovation in crafting e ﬀective rubrics for LLM classiﬁcation remains possible. Still, we observe a high\n",
      "degree of agreement between human ratings and GPT-4 ratings at the occupation level concerning overall\n",
      "exposure to LLM systems (see Table 2, Figure 2).\n",
      "3.4.3 Additional Weaknesses\n",
      "•Validity of task-based framework. It is unclear to what extent occupations can be entirely broken\n",
      "down into tasks, and whether this approach systematically omits certain categories of skills or tasks\n",
      "that are tacitly required for competent performance of a job. Additionally, tasks can be composed of\n",
      "sub-tasks, some of which are more automatable than others. Some tasks may function as pre-cursor to\n",
      "other tasks, such that the completion of downstream tasks is dependent on precursor tasks. If indeed,\n",
      "the task-based breakdown is not a valid representation of how most work in an occupation is performed,\n",
      "our exposure analysis would largely be invalidated.\n",
      "•Lack of expertise and task interpretation. Human annotators were mostly unaware of the speciﬁc\n",
      "occupations mapped to each DWA during the labeling process. This led to unclear logic for aggregating\n",
      "tasks and occupations, as well as some evident discrepancies in labels, demonstrated in Table 1. We\n",
      "experimented with various aggregation methods and discovered that even with a maximum-matching\n",
      "approach (taking the matching human<>model label if one existed), the agreement remained relatively\n",
      "consistent. Ultimately, we collected additional labels for task/occupation pairs where there was\n",
      "signiﬁcant disagreement.WORKING PAPER\n",
      "Figure 2: Human raters (x-axis) and GPT-4 ratings (y-axis) show a high degree of agreement about LLM\n",
      "exposure by occupation. We compute occupation-level exposure in these ﬁgures by averaging the task-level\n",
      "exposures under the Vmethod. O*NET designates some tasks as \"core\" and others \"supplemental\". Core\n",
      "tasks are given twice the weight of supplemental tasks, and all weights sum to one. Near the highest levels of\n",
      "exposure following the Vmethod of aggregating exposure scores to occupations, GPT-4 ratings tend to be\n",
      "lower than Human ratings. We present the raw scatter plot and the binscatter. Near the top end of exposure\n",
      "ratings, humans are on average more likely to rate an occupation as exposed.\n",
      "•Forward-looking and subject to change, with some early evidence. Accurately predicting future\n",
      "LLM applications remains a signiﬁcant challenge, even for experts (OpenAI, 2023b). The discovery of\n",
      "new emergent capabilities, changes in human perception biases, and shifts in technological development\n",
      "can all a ﬀect the accuracy and reliability of predictions regarding the potential impact of LLMs\n",
      "on worker tasks and the development of LLM-powered software. Our projections are inherently\n",
      "forward-looking and based on current trends, evidence, and perceptions of technological possibilities.\n",
      "As a result, they may change as new advancements arise in the ﬁeld. For example, some tasks that\n",
      "seem unlikely for LLMs or LLM-powered software to impact today might change with the introduction\n",
      "of new model capabilities. Conversely, tasks that appear exposed might face unforeseen challenges\n",
      "limiting language model applications.\n",
      "•Sources of disagreement. While we did not rigorously examine sources of disagreement, we found a\n",
      "few places where humans and the model tended to get \"stuck\" in their assessments:\n",
      "–Tasks or activities where while an LLM could theoretically help or accomplish the task, adopting\n",
      "it to do so would require multiple people to change their habits or expectations (e.g. meetings,\n",
      "negotiations),\n",
      "–Tasks or\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      " unforeseen challenges\n",
      "limiting language model applications.\n",
      "•Sources of disagreement. While we did not rigorously examine sources of disagreement, we found a\n",
      "few places where humans and the model tended to get \"stuck\" in their assessments:\n",
      "–Tasks or activities where while an LLM could theoretically help or accomplish the task, adopting\n",
      "it to do so would require multiple people to change their habits or expectations (e.g. meetings,\n",
      "negotiations),\n",
      "–Tasks or activities where there is currently some regulation or norm that requires or suggests\n",
      "human oversight, judgment or empathy (e.g. making decisions, counseling), and\n",
      "–Tasks or activities where there already exists a technology that can reasonably automate the task\n",
      "(e.g. making reservations).\n",
      "4 Results\n",
      "General-purpose technologies are relatively rare and characterized by their pervasiveness, improvement over\n",
      "time, and the development of signiﬁcant co-invention and spillovers (Lipsey et al., 2005). Our assessment ofWORKING PAPER\n",
      "LLMs’ potential impact on the labor market is limited since it does not consider total factor productivity or\n",
      "capital input potential. In addition to their inﬂuence on labor, LLMs may also inﬂuence these dimensions.\n",
      "At this stage, some general-purpose technology criteria are easier to evaluate than others. Our primary\n",
      "focus at this early stage is to test the hypothesis that LLMs have a pervasive inﬂuence on the economy,\n",
      "similar to the approach taken by (Goldfarb et al., 2023), who analyzed machine learning di ﬀusion through\n",
      "job postings to assess its status as a general-purpose technology. Instead of using job postings or studying\n",
      "machine learning in general, we employ the task evaluation approach with both human and GPT-4 annotations.\n",
      "This analysis may reveal whether the impacts are limited to a speciﬁc set of similar tasks or occupations or if\n",
      "they will be more widespread.\n",
      "Our ﬁndings suggest that, based on their task-level capabilities, LLMs have the potential to signiﬁcantly\n",
      "aﬀect a diverse range of occupations within the U.S. economy, demonstrating a key attribute of general-purpose\n",
      "technologies. In the following sections, we discuss results across various roles and wage structures. Additional\n",
      "results on the relative exposure of industries within the U.S. economy can be found in Appendix C.\n",
      "4.1 Summary Statistics\n",
      "Summary statistics for these measures can be found in Table 3. Both human and GPT-4 annotations indicate\n",
      "that average occupation-level Uvalues fall between 0.14 and 0.15, suggesting that, on average, approximately\n",
      "15% of tasks within an occupation are directly exposed to LLMs. 6This ﬁgure increases to over 30% for V\n",
      "and surpasses 50% for Z. Coincidentally, human and GPT-4 annotations also tag between 15% and 14% of\n",
      "total tasks in the dataset as being exposed to LLMs. Based on the Vvalues, we estimate that 80% of workers\n",
      "belong to an occupation with at least 10% of its tasks exposed to LLMs, while 19% of workers are in an\n",
      "occupation where over half of its tasks are labeled as exposed.\n",
      "We ran one set of analyses using O*NET’s \"Importance\" scores but did not ﬁnd signiﬁcant changes to our\n",
      "ﬁndings. Though we do acknowledge that not weighting relative importance of a task to a given occupation\n",
      "yields some curious results (e.g. ranking Barbers as having reasonably high exposure).\n",
      "Although the potential for tasks to be a ﬀected is vast, LLMs and LLM-powered software must be\n",
      "incorporated into broader systems to fully realize this potential. As is common with general-purpose\n",
      "technologies, co-invention barriers may initially impede the rapid di ﬀusion of GPTs into economic applications.\n",
      "Furthermore, predicting the need for human oversight is challenging, especially for tasks where model\n",
      "capabilities equal or surpass human levels. While the requirement for human supervision may initially slow\n",
      "down the speed at which these systems di ﬀuse through the economy, users of LLMs and LLM-powered\n",
      "systems are likely to become increasingly acquainted with the technology over time, particularly in terms of\n",
      "understanding when and how to trust its outputs.\n",
      "4.2 Wages and Employment\n",
      "In Figure 3, we present exposure intensity across the economy. Each point on the plot displays occupational\n",
      "exposure, where the point’s x-axis value represents the share of an occupation’s tasks that are exposed (at\n",
      "each level U,V, and Z) and the point’s y-axis value represents the share of all\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      " over time, particularly in terms of\n",
      "understanding when and how to trust its outputs.\n",
      "4.2 Wages and Employment\n",
      "In Figure 3, we present exposure intensity across the economy. Each point on the plot displays occupational\n",
      "exposure, where the point’s x-axis value represents the share of an occupation’s tasks that are exposed (at\n",
      "each level U,V, and Z) and the point’s y-axis value represents the share of all US occupations with that share\n",
      "of tasks exposed. For example, human annotators determined that 2.3% of occupations are U50-exposed,\n",
      "21.6% are V50-exposed, and 47.3% are Z50-exposed, where the threshold of 50% comes from the x-axis and\n",
      "the percentage of occupations comes from the y axis. At any given point on the x-axis, the vertical distance\n",
      "between the Uand the Zrepresents the exposure potential attributable to tools and applications beyond direct\n",
      "exposure to LLMs. All tasks within an occupation in this ﬁgure are given equal weight.between the Uand the Zrepresents the exposure potential attributable to tools and applications beyond direct\n",
      "exposure to LLMs. All tasks within an occupation in this ﬁgure are given equal weight.\n",
      "6We compute occupation-level scores for Table 3 assigning double the weight to tasks designated as \"core\" by O*NET as tasks\n",
      "designated \"supplemental\". All tasks weights sum to one within an occupation.WORKING PAPER\n",
      "Occupation Level Exposure\n",
      "Human GPT-4\n",
      "mean std mean std\n",
      "UUU0.14 0.14 0.14 0.16\n",
      "VVV0.30 0.21 0.34 0.22\n",
      "ZZZ0.46 0.30 0.55 0.34\n",
      "Task Level Exposure\n",
      "Human GPT-4\n",
      "mean std mean std\n",
      "UUU0.15 0.36 0.14 0.35\n",
      "VVV0.31 0.37 0.35 0.35\n",
      "ZZZ0.47 0.50 0.56 0.50\n",
      "Table 3: Summary statistics of our human and model exposure data. Tasks designated as core tasks for an\n",
      "occupation are given twice the weight as those indicated to be supplemental in the O*NET task ﬁle.\n",
      "Figure 3: Exposure intensity across the economy, displayed in terms of percent of a ﬀected occupations. A\n",
      "given data point gives the percent of occupations with exposure below the given threshold. A previous version\n",
      "of this paper had two labels reversed in the chart, ﬂipping human and model responses. In this ﬁgure, all tasks\n",
      "within an occupation are given equal weight.\n",
      "Aggregated at the occupation level, human and GPT-4 annotations exhibit qualitative similarities and\n",
      "tend to correlate, as demonstrated in Figure 4. Human annotations estimate marginally lower exposure for\n",
      "high-wage occupations compared to GPT-4 annotations. While there are numerous low-wage occupations\n",
      "with high exposure and high-wage occupations with low exposure, the overall trend in the binscatter plot\n",
      "reveals that higher wages are associated with increased exposure to LLMs. 7\n",
      "The potential exposure to LLMs seems to have little correlation with current employment levels. In\n",
      "Figure 4, both human and GPT-4 ratings of overall exposure are aggregated to the occupation-level (y-axis)\n",
      "and compared with the log of total employment (x-axis). Neither plot reveals signiﬁcant di ﬀerences in LLM\n",
      "exposure across varying employment levels.\n",
      "7In aggregating tasks to the occupation-level, we assign half the weight to O*NET supplemental tasks as we do for core tasks.WORKING PAPER\n",
      "Figure 4: The binscatter plots depict the exposure to language models (LLMs) in various occupations, as\n",
      "assessed by both human evaluators and GPT-4. These plots compare the exposure to LLM and partial\n",
      "LLM-powered software ( V) at the occupation level against the log of total employment within an occupation\n",
      "and log of the median annual wage for occupations. While some discrepancies exist, both human and GPT-4\n",
      "assessments indicate that higher wage occupations tend to be more exposed to LLMs. Additionally, numerous\n",
      "lower wage occupations demonstrate high exposure based on our rubric. Core tasks receive twice the weight of\n",
      "supplemental tasks within occupations when calculating average exposure scores. Employment and wage data\n",
      "are sourced from the BLS-OES survey conducted in May 2021. In aggregating tasks to the occupation-level,\n",
      "we assign half the weight to O*NET supplemental tasks as we do for core tasks. All weights within an\n",
      "occupation sum to one.WORKING PAPER\n",
      "4.3 Skill Importance\n",
      "In this section\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      " our rubric. Core tasks receive twice the weight of\n",
      "supplemental tasks within occupations when calculating average exposure scores. Employment and wage data\n",
      "are sourced from the BLS-OES survey conducted in May 2021. In aggregating tasks to the occupation-level,\n",
      "we assign half the weight to O*NET supplemental tasks as we do for core tasks. All weights within an\n",
      "occupation sum to one.WORKING PAPER\n",
      "4.3 Skill Importance\n",
      "In this section, we explore the relationship between the importance of a skill for an occupation (as annotated\n",
      "in the O*NET dataset) and our exposure measures. First, we use the Basic Skills provided by O*NET (skill\n",
      "deﬁnitions can be found in Appendix B) and normalize the measure of skill importance for each occupation\n",
      "to improve the comprehensibility of the results. Next, we conduct a regression analysis on our exposure\n",
      "measures ( U,V,Z) to examine the strength of associations between skill importance and exposure.\n",
      "Our ﬁndings indicate that the importance of science andcritical thinking skills are strongly negatively\n",
      "associated with exposure, suggesting that occupations requiring these skills are less likely to be impacted\n",
      "by current LLMs. Conversely, programming andwriting skills show a strong positive association with\n",
      "exposure, implying that occupations involving these skills are more susceptible to being inﬂuenced by LLMs\n",
      "(see Table 5 for detailed results).\n",
      "4.4 Barriers to Entry\n",
      "Next, we examine barriers to entry to better understand if there is di ﬀerentiation in exposure due to types of\n",
      "jobs. One such proxy is an O*NET occupation-level descriptor called the \"Job Zone.\" A Job Zone groups\n",
      "occupations that are similar in (a) the level of education needed to get a job in the occupation, (b) the amount\n",
      "of related experience required to do the work, and (c) the extent of on-the-job training needed to do the work.\n",
      "In the O*NET database, there are 5 Job Zones, with Job Zone 1 requiring the least amount of preparation (3\n",
      "months) and Job Zone 5 requiring the most extensive amount of preparation, 4 or more years. We observe that\n",
      "median income increases monotonically across Job Zones as the level of preparation needed also increases,\n",
      "with the median worker in Job Zone 1 earning $30,230and the median worker in Job Zone 5 earning $80,980.\n",
      "All of our measures ( U,V, and Z) show an identical pattern, that is, exposure increases from Job Zone 1 to\n",
      "Job Zone 4, and either remains similar or decreases at Job Zone 5. Similar to Figure 3, in Figure 5, we plot\n",
      "the percentage of workers at every threshold of exposure. We ﬁnd that, on average, the percentage of workers\n",
      "in occupations with greater than 50% Vexposure in Job Zones 1 through 5 have Vat 0.00% (Job Zone 1),\n",
      "6.11% (Job Zone 2), 10.57% (Job Zone 3), 34.5% (Job Zone 4), and 26.45% (Job Zone 5), respectively. 8\n",
      "4.4.1 Typical Education Needed for Entry\n",
      "Since inclusion in a Job Zone accounts for both the education required—which itself is a proxy for skill\n",
      "acquisition—and the preparation required, we seek data to disentangle these variables. We use two variables\n",
      "from the Bureau of Labor Statistics’ Occupational data: \"Typical Education Needed for Entry\" and \"On-the-job\n",
      "Training Required to Attain Competency\" in an occupation. By examining these factors, we aim to uncover\n",
      "trends with potential implications for the workforce. There are 3,504,000 workers for whom we lack data on\n",
      "education and on-the-job training requirements, and they are therefore excluded from the summary tables.\n",
      "Our analysis suggests that individuals holding Bachelor’s, Master’s, and professional degrees are more\n",
      "exposed to LLMs and LLM-powered software than those without formal educational credentials (see Table 7).\n",
      "Interestingly, we also ﬁnd that individuals with some college education but no degree exhibit a high level of\n",
      "exposure to LLMs and LLM-powered software. Upon examining the table displaying barriers to entry, we\n",
      "observe that the jobs with the least exposure require the most training, potentially o ﬀering a lower payo ﬀ(in\n",
      "terms of median income) once competency is achieved. Conversely, jobs with no on-the-job training required\n",
      "or only internship/residency required appear to yield higher income but are more exposed to LLMs.\n",
      "8For this set of results, all tasks have equal weight within an occupation. Results do not change meaningfully with the\n",
      "core/supplemental weighting scheme.WORKING PAP\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      ", potentially o ﬀering a lower payo ﬀ(in\n",
      "terms of median income) once competency is achieved. Conversely, jobs with no on-the-job training required\n",
      "or only internship/residency required appear to yield higher income but are more exposed to LLMs.\n",
      "8For this set of results, all tasks have equal weight within an occupation. Results do not change meaningfully with the\n",
      "core/supplemental weighting scheme.WORKING PAPER\n",
      "Figure 5: Vexposure ratings of occupations in the ﬁve Job Zones, which are groups of similar occupations\n",
      "that are classiﬁed according to the level of education, experience, and on-the-job training needed to perform\n",
      "them. All tasks are weighted equally.WORKING PAPER\n",
      "Group Occupations with highest exposure % Exposure\n",
      "Human UUU Interpreters and Translators 76.5\n",
      "Survey Researchers 75.0\n",
      "Poets, Lyricists and Creative Writers 68.8\n",
      "Animal Scientists 66.7\n",
      "Public Relations Specialists 66.7\n",
      "Human VVV Survey Researchers 84.4\n",
      "Writers and Authors 82.5\n",
      "Interpreters and Translators 82.4\n",
      "Public Relations Specialists 80.6\n",
      "Animal Scientists 77.8\n",
      "Human ZZZ Mathematicians 100.0\n",
      "Tax Preparers 100.0\n",
      "Financial Quantitative Analysts 100.0\n",
      "Writers and Authors 100.0\n",
      "Web and Digital Interface Designers 100.0\n",
      "Humans labeled 15 occupations as \"fully exposed.\"\n",
      "Model UUU Mathematicians 100.0\n",
      "Correspondence Clerks 95.2\n",
      "Blockchain Engineers 94.1\n",
      "Court Reporters and Simultaneous Captioners 92.9\n",
      "Proofreaders and Copy Markers 90.9\n",
      "Model VVV Mathematicians 100.0\n",
      "Blockchain Engineers 97.1\n",
      "Court Reporters and Simultaneous Captioners 96.4\n",
      "Proofreaders and Copy Markers 95.5\n",
      "Correspondence Clerks 95.2\n",
      "Model ZZZ Accountants and Auditors 100.0\n",
      "News Analysts, Reporters, and Journalists 100.0\n",
      "Legal Secretaries and Administrative Assistants 100.0\n",
      "Clinical Data Managers 100.0\n",
      "Climate Change Policy Analysts 100.0\n",
      "The model labeled 86 occupations as \"fully exposed.\"\n",
      "Highest variance Search Marketing Strategists 14.5\n",
      "Graphic Designers 13.4\n",
      "Investment Fund Managers 13.0\n",
      "Financial Managers 13.0\n",
      "Insurance Appraisers, Auto Damage 12.6\n",
      "Table 4: Occupations with the highest exposure according to each measurement. The ﬁnal row lists the\n",
      "occupations with the highest f2value, indicating that they had the most variability in exposure scores.\n",
      "Exposure percentages indicate the share of an occupation’s task that are exposed to GPTs ( UUU) or GPT-powered\n",
      "software ( VVVandZZZ), where exposure is deﬁned as driving a reduction in time it takes to complete the task by at\n",
      "least 50% (see exposure rubric A.1). As such, occupations listed in this table are those where we estimate\n",
      "that GPTs and GPT-powered software are able to save workers a signiﬁcant amount of time completing a\n",
      "large share of their tasks, but it does not necessarily suggest that their tasks can be fully automated by these\n",
      "technologies. All tasks are assigned equal weight within an occupation.WORKING PAPER\n",
      "Basic Skill UUU\n",
      "(std err)VVV\n",
      "(std err)ZZZ\n",
      "(std err)\n",
      "All skill importance scores are normalized to be between 0 and 1.\n",
      "Constant 0.082*** -0.112*** 0.300***\n",
      "(0.011) (0.011) (0.057)\n",
      "Active Listening 0.128** 0.214*** 0.449***\n",
      "(0.047) (0.043) (0.027)\n",
      "Mathematics -0.127*** 0.161*** 0.787***\n",
      "(0.026) (0.021) (0.049)\n",
      "Reading Comprehension 0.153*** 0.470*** -0.346***\n",
      "(0.041) (0.037) (0.017)\n",
      "Science -0.114*** -0.230*** -0.346***\n",
      "(0.014) (0.012) (0.017)\n",
      "Speaking -0.028 0.133*** 0.294***\n",
      "(0.039) (0.033) (0.042)\n",
      "Writing 0.368*** 0.467*** 0.566***\n",
      "(0.042) (0.037) (0.047)\n",
      "Active Learning -0.157*** -0.0\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "230*** -0.346***\n",
      "(0.014) (0.012) (0.017)\n",
      "Speaking -0.028 0.133*** 0.294***\n",
      "(0.039) (0.033) (0.042)\n",
      "Writing 0.368*** 0.467*** 0.566***\n",
      "(0.042) (0.037) (0.047)\n",
      "Active Learning -0.157*** -0.065** 0.028\n",
      "(0.027) (0.024) (0.032)\n",
      "Critical Thinking -0.264*** -0.196*** -0.129**\n",
      "(0.036) (0.033) (0.042)\n",
      "Learning Strategies -0.072* -0.209*** -0.346***\n",
      "(0.028) (0.025) (0.034)\n",
      "Monitoring -0.067** -0.149*** -0.232***\n",
      "(0.023) 0.020) (0.026)\n",
      "Programming 0.637*** 0.623*** 0.609***\n",
      "(0.030) (0.022) (0.024)\n",
      "Table 5: Regression of occupation-level, human-annotated exposure to GPTs on skill importance for each\n",
      "skill in the O*NET Basic skills category, plus the programming skill. Descriptions of the skills may be found\n",
      "in Appendix B. Task ratings within each occupation for exposure have equal weight.\n",
      "Job\n",
      "ZonePreparation\n",
      "RequiredEducation\n",
      "RequiredExample Occupations Median\n",
      "IncomeTot Emp\n",
      "(000s )H\n",
      "UUUM\n",
      "UUUH\n",
      "VVVM\n",
      "VVVH\n",
      "ZZZM\n",
      "ZZZ\n",
      "1 None or little\n",
      "(0-3 months)High school\n",
      "diploma or GED\n",
      "(otional)Food preparation workers,\n",
      "dishwashers, ﬂoor sanders$30,230 13,100 0.03 0.04 0.06 0.06 0.09 0.08\n",
      "2 Some (3-12\n",
      "months)High school\n",
      "diplomaOrderlies, customer\n",
      "service representatives,\n",
      "tellers$38,215 73,962 0.07 0.12 0.16 0.20 0.24 0.27\n",
      "3 Medium (1-2\n",
      "years)Vocational school,\n",
      "on-the-job training,\n",
      "or associate’s\n",
      "degreeElectricians, barbers,\n",
      "medical assistants$54,815 37,881 0.11 0.14 0.26 0.32 0.41 0.51\n",
      "4 Considerable\n",
      "(2-4 years)Bachelor’s degree Database administrators,\n",
      "graphic designers, cost\n",
      "estimators$77,345 56,833 0.23 0.18 0.47 0.51 0.71 0.85\n",
      "5 Extensive (4+\n",
      "years)Master’s degree or\n",
      "higherPharmacists, lawyers,\n",
      "astronomers$81,980 21,221 0.23 0.13 0.43 0.45 0.63 0.76\n",
      "Table 6: Mean exposure to GPTs by job zone. For each job zone, we also present the median of median\n",
      "annual income for each constituting occupation in USD, and the total number of workers in all occupations\n",
      "for that job zone, in the thousands. Task weights are equal for all tasks.WORKING PAPER\n",
      "On The Job Training Required Median Income Tot Emp (000s) HUUU MUUU HVVVMVVV HZZZMZZZ\n",
      "None $77,440 90,776 0.20 0.16 0.42 0.46 0.63 0.76\n",
      "Apprenticeship $55,995 3,066 0.01 0.02 0.04 0.06 0.07 0.10\n",
      "Internship/residency $77,110 3,063 0.16 0.06 0.36 0.38 0.55 0.71\n",
      "Short-term on-the-job training $33,370 66,234 0.11 0.15 0.21 0.25 0.32 0.34\n",
      "Moderate-term on-the-job training $46,880 31,285 0.09 0.12 0.21 0.25 0.32 0.38\n",
      "Long-term on-the-job training $48,925 5,070 0.08 0.10 0.18 0.22 0.28 0.33\n",
      "Table 7: Mean exposure scores for occupations, grouped by level of on-the-job training required to attain\n",
      "competency in the job. Alongside exposure scores, we display the median of median annual income for each\n",
      "occupation, as well as the total number of workers in each group,\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      " 0.38\n",
      "Long-term on-the-job training $48,925 5,070 0.08 0.10 0.18 0.22 0.28 0.33\n",
      "Table 7: Mean exposure scores for occupations, grouped by level of on-the-job training required to attain\n",
      "competency in the job. Alongside exposure scores, we display the median of median annual income for each\n",
      "occupation, as well as the total number of workers in each group, in thousands. Task weights are equal within\n",
      "an occupation and sum to one.WORKING PAPER\n",
      "5 Validation of Measures\n",
      "5.1 Comparison to Earlier E ﬀorts\n",
      "This paper aims to build on a number of previous empirical studies examining the occupational exposure to\n",
      "advances in AI and/or automation. Previous studies have used a variety of methods, including:\n",
      "•Using occupational taxonomies like O*NET to characterize which occupations have routine vs.\n",
      "non-routine and manual vs. cognitive task content (Autor et al., 2003; Acemoglu and Autor, 2011a).\n",
      "•Mapping text descriptions of tasks to descriptions of technological advances in patents. (Kogan et al.,\n",
      "2021; Webb, 2020)\n",
      "•Linking capabilities of AI systems to occupational abilities and aggregating exposure estimates to the\n",
      "occupations where those abilities are required. (Felten et al., 2018, 2023)\n",
      "•Mapping the results of AI task benchmark evaluations (ImageNet, Robocup, etc.) to 59 worker tasks\n",
      "through a set of 14 cognitive abilities drawn from the cognitive science literature. (Tolan et al., 2021)\n",
      "•Expert labeling of automation potential for a set of O*NET occupations where experts had high\n",
      "conﬁdence, combined with a probabilistic classiﬁer to estimate automation potential for the remainder\n",
      "of O*NET occupations. (Frey and Osborne, 2017)\n",
      "•Developing a rubric for evaluating the \"suitability for machine learning\" (SML) of activities that\n",
      "workers are completing in the economy (Brynjolfsson and Mitchell, 2017; Brynjolfsson et al., 2018,\n",
      "2023).\n",
      "We provide a set of summary statistics on many of these prior e ﬀorts in Table 8.\n",
      "This paper’s methodology primarily builds upon the SML approach by developing a rubric to evaluate the\n",
      "overlap between LLM capabilities and worker tasks as reported in the O*NET database. Table 9 presents the\n",
      "results of OLS regressions of our new LLM exposure measurements on occupation-level exposure measures\n",
      "from (Felten et al., 2018) (\"AI Occupational Exposure Score\" in the table), (Frey and Osborne, 2017) (Frey\n",
      "& Osborne Automation), scores from all three technologies in (Webb, 2020), normalized routine manual\n",
      "and cognitive scores from (Acemoglu and Autor, 2011a), and (Brynjolfsson et al., 2018, 2023) (SML). We\n",
      "also use annualized occupational salaries from the most recent BLS Occupational Employment Survey as a\n",
      "control. There are four separate output variables representing new scores in this paper that are predicted by\n",
      "earlier e ﬀorts.\n",
      "GPT-4 Exposure Rating 1 corresponds to our overall exposure rubric as evaluated by GPT-4, where full\n",
      "exposure potential is coded as 1, no exposure potential is coded as 0, and partial exposure (E2 in our labeling\n",
      "scheme) is coded as 0.5. GPT-4 Exposure Rating 2 is scored similarly for overall exposure, but with a slightly\n",
      "diﬀerent prompt. The results are very similar across the two prompts. Human Exposure Rating represents the\n",
      "same rubric as in GPT-4 Exposure Rating 1 but is scored by humans, as discussed in an earlier section of the\n",
      "paper. These results correspond to the Vset of statistics presented above, with supplemental tasks having half\n",
      "the weight of core tasks within an occupation. These weights sum to one (core/supplemental distinctions are\n",
      "determined by O*NET).\n",
      "The results across each type of measurement are consistent. We ﬁnd generally positive and statistically\n",
      "signiﬁcant correlations between our LLM exposure measures and previous measurements targeting software\n",
      "and AI. Encouragingly, the SML exposure scores by occupation show signiﬁcant and positive associations\n",
      "with the exposure scores we develop in this paper, demonstrating a level of cohesion between the two studies\n",
      "with similar approaches. The Webb software and AI patent-based measures, SML, and normalized (demeanedWORKING PAPER\n",
      "Min 25th Perc. Median 75th Perc Max Mean Std. Dev. Count\n",
      "GPT-4 Exposure Rating 1 0.00 0.13 0.34 0.50 1.\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "iﬁcant and positive associations\n",
      "with the exposure scores we develop in this paper, demonstrating a level of cohesion between the two studies\n",
      "with similar approaches. The Webb software and AI patent-based measures, SML, and normalized (demeanedWORKING PAPER\n",
      "Min 25th Perc. Median 75th Perc Max Mean Std. Dev. Count\n",
      "GPT-4 Exposure Rating 1 0.00 0.13 0.34 0.50 1.00 0.33 0.22 750\n",
      "GPT-4 Exposure Rating 2 0.00 0.09 0.24 0.40 0.98 0.26 0.20 750\n",
      "Human Exposure Rating 0.00 0.09 0.29 0.47 0.84 0.29 0.21 750\n",
      "Software (Webb) 1.00 25.00 50.00 75.00 100.00 50.69 30.05 750\n",
      "Robot (Webb) 1.00 22.00 52.00 69.00 100.00 48.61 28.61 750\n",
      "AI (Webb) 1.00 28.00 55.00 82.00 100.00 54.53 29.65 750\n",
      "Suitability for Machine Learning 2.60 2.84 2.95 3.12 3.55 2.99 0.18 750\n",
      "Normalized Routine Cognitive -3.05 -0.46 0.10 0.63 3.42 0.07 0.86 750\n",
      "Normalized Routine Manual -1.81 -0.81 -0.11 0.73 2.96 0.05 1.01 750\n",
      "AI Occupational Exposure Score 1.42 3.09 3.56 4.04 6.54 3.56 0.70 750\n",
      "Frey & Osborne Automation 0.00 0.07 0.59 0.88 0.99 0.50 0.38 681\n",
      "Log Avg. Salary 10.13 10.67 11.00 11.34 12.65 11.02 0.45 749\n",
      "Table 8: Summary statistics for a suite of prior e ﬀorts to measure occupational exposure to AI and automation.\n",
      "We have also included summary statistics for measurements newly presented in this work. We include all\n",
      "measures from (Webb, 2020), normalized routine cognitive and manual scores from (Acemoglu and Autor,\n",
      "2011a) (means may deviate slightly from 0 due to imperfect matching of occupational groups), Suitability for\n",
      "Machine Learning from (Brynjolfsson and Mitchell, 2017; Brynjolfsson et al., 2018, 2023), AI Occupational\n",
      "Exposure from (Felten et al., 2018), and Automation exposure from (Frey and Osborne, 2017). We include as\n",
      "many occupations as we can match, but since O*NET taxonomies have changed as these measures have been\n",
      "developed, some of the roles may be missing from the most recent version of O*NET 6-digit occupations.\n",
      "and divided by standard deviation) routine cognitive scores all exhibit positive associations with some of our\n",
      "measures.\n",
      "Software, SML, and routine cognitive scores all show positive and statistically signiﬁcant associations\n",
      "with LLM exposure scores at a 1% level. Coe ﬃcients on AI scores from (Webb, 2020) are also positive and\n",
      "statistically signiﬁcant at a 5% level, but our secondary prompt on overall exposure to LLMs in columns 3\n",
      "and 4 does not exhibit a statistically signiﬁcant relationship. For the most part, the AI Occupational Exposure\n",
      "Score is not correlated with our exposure measures. Webb’s Robot exposure scores, routine manual task\n",
      "content, and the overall Automation metric from (Frey and Osborne, 2017) are all negatively correlated with\n",
      "our primary GPT-4 and human-assessed overall exposure ratings, conditional on the other measurements.\n",
      "This negative correlation reﬂects the limited exposure of physical tasks to LLMs. Manual work is not exposed\n",
      "to LLMs or even LLMs with additional systems integration for the time being.\n",
      "Low correlations with (Felten et al., 2018) and (Frey and Osborne, 2017) could potentially be explained\n",
      "by diﬀerences in approaches. Linking AI capabilities to worker abilities or scoring exposure directly based on\n",
      "the occupation’s characteristics, rather than aggregating up to the occupation from DWA or task-level scoring\n",
      "(as in the SML paper and our own), o ﬀer a slightly di ﬀerent perspective on the content of occupations.\n",
      "In all regressions, the '2ranges between 60.7% (column 3) and 72.8% (column 5). This suggests that\n",
      "our measure, which explicitly focuses on LLM capabilities, has between 28 and 40% unexplained variance\n",
      "compared to other measurements\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      " to the occupation from DWA or task-level scoring\n",
      "(as in the SML paper and our own), o ﬀer a slightly di ﬀerent perspective on the content of occupations.\n",
      "In all regressions, the '2ranges between 60.7% (column 3) and 72.8% (column 5). This suggests that\n",
      "our measure, which explicitly focuses on LLM capabilities, has between 28 and 40% unexplained variance\n",
      "compared to other measurements. Particularly in the case of AI-related exposure scores, we anticipate that a\n",
      "combination of other measurements would have a strong correlation with our scores. However, earlier e ﬀorts\n",
      "had limited information about the future progress of LLMs or LLM-powered software. We expect that our\n",
      "understanding of future machine learning technologies is similarly imperfectly captured by our rubric today.WORKING PAPER\n",
      "GPT-4 Exposure Rating 1 GPT-4 Exposure Rating 2 Human Exposure Rating\n",
      "(1) (2) (3) (4) (5) (6)\n",
      "Software (Webb) 0.00113⇤⇤⇤0.00123⇤⇤⇤0.00111⇤⇤⇤0.00119⇤⇤⇤0.00096⇤⇤⇤0.00101⇤⇤⇤\n",
      "(0.00031 )( 0.00031 )( 0.00031 )( 0.00031 )( 0.00031 )( 0.00031 )\n",
      "Robot (Webb) \u00000.00378⇤⇤⇤\u00000.00405⇤⇤⇤\u00000.00377⇤⇤⇤\u00000.00399⇤⇤⇤\u00000.00371⇤⇤⇤\u00000.00383⇤⇤⇤\n",
      "(0.00032 )( 0.00031 )( 0.00034 )( 0.00033 )( 0.00029 )( 0.00028 )\n",
      "AI (Webb) 0.00080⇤⇤⇤0.00090⇤⇤⇤0.00036 0 .00045 0 .00067⇤⇤0.00071⇤⇤\n",
      "(0.00030 )( 0.00029 )( 0.00030 )( 0.00030 )( 0.00030 )( 0.00030 )\n",
      "Suitability for Machine Learning 0.29522⇤⇤⇤0.26888⇤⇤⇤0.28468⇤⇤⇤0.26245⇤⇤⇤0.19514⇤⇤⇤0.18373⇤⇤⇤\n",
      "(0.04503 )( 0.04418 )( 0.04404 )( 0.04342 )( 0.03990 )( 0.03886 )\n",
      "Normalized Routine Cognitive 0.06601⇤⇤⇤0.06868⇤⇤⇤0.04743⇤⇤⇤0.05015⇤⇤⇤0.03568⇤⇤⇤0.03659⇤⇤⇤\n",
      "(0.00886 )( 0.00894 )( 0.00872 )( 0.00879 )( 0.00671 )( 0.00669 )\n",
      "Normalized Routine Manual \u00000.11147⇤⇤⇤\u00000.11371⇤⇤⇤\u00000.09390⇤⇤⇤\u00000.09561⇤⇤⇤\u00000.11045⇤⇤⇤\u00000.11152⇤⇤⇤\n",
      "(0.00785 )( 0.00789 )( 0.00817 )( 0.00818 )( 0.00741 )( 0.00744 )\n",
      "AI Occupational Exposure Score 0.00993 0 .02465⇤⇤\u00000.01537 \u00000.00265 0 .00630 0 .01252\n",
      "(0.01107 )( 0.01059 )( 0.01160 )( 0.01114 )( 0.00918 )( 0.00845 )\n",
      "Frey &\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "17 )( 0.00818 )( 0.00741 )( 0.00744 )\n",
      "AI Occupational Exposure Score 0.00993 0 .02465⇤⇤\u00000.01537 \u00000.00265 0 .00630 0 .01252\n",
      "(0.01107 )( 0.01059 )( 0.01160 )( 0.01114 )( 0.00918 )( 0.00845 )\n",
      "Frey & Osborne Automation \u00000.03024⇤\u00000.03950⇤⇤\u00000.00364 \u00000.01217 \u00000.03890⇤⇤\u00000.04253⇤⇤\n",
      "(0.01835 )( 0.01841 )( 0.02007 )( 0.01972 )( 0.01883 )( 0.01858 )\n",
      "Log Avg. Salary 0.05804⇤⇤⇤0.04863⇤⇤⇤0.02531\n",
      "(0.01870 )( 0.01860 )( 0.01727 )\n",
      "Constant \u00001.12937⇤⇤⇤\u00000.45743⇤⇤⇤\u00000.96117⇤⇤⇤\u00000.39935⇤⇤⇤\u00000.47078⇤\u00000.17706\n",
      "(0.26859 )( 0.15327 )( 0.26365 )( 0.15017 )( 0.24684 )( 0.13256 )\n",
      "N 680.00000 681 .00000 680 .00000 681 .00000 680 .00000 681 .00000\n",
      "'20.68741 0 .68212 0 .60737 0 .60198 0 .71213 0 .71126\n",
      "Table 9: Regression of LLM-exposure scores on prior measures of occupational exposure to AI and automation.\n",
      "We also include annualized wages from the BLS-OES survey in May 2021. Each measure is kept in its\n",
      "original scale, with the exception of routine cognitive and routine manual scores from (Acemoglu and Autor,\n",
      "2011a). Those two scores are standardized to mean zero and variance 1. Generally we ﬁnd strong positive\n",
      "associations with previous e ﬀorts, though large residual variance to still be explained by our new measures.\n",
      "Columns 1 and 2 are based on our main Vexposure measure from GPT-4 ratings. Columns 3 and 4 are\n",
      "based on a similar slightly di ﬀerent exposure rubric also rated by GPT-4 for robustness. Columns 5 and 6\n",
      "reﬂect human ratings on the same rubric as columns 1 and 2. Occupation-level scores are built using the\n",
      "core/supplemental task weights, assigning supplemental tasks as having half the weight of core tasks.WORKING PAPER\n",
      "6 Discussion\n",
      "6.1 GPTs as a General-Purpose Technology\n",
      "Earlier in this paper we discuss the possibility that LLMs could be classiﬁed as a general-purpose technology.\n",
      "This classiﬁcation requires LLMs to meet three core criteria: improvement over time, pervasiveness throughout\n",
      "the economy, and the ability to spawn complementary innovations (Lipsey et al., 2005). Evidence from the AI\n",
      "and machine learning literature thoroughly demonstrates that LLMs meet the ﬁrst criteria – they are improving\n",
      "in capabilities over time with the ability to complete or be helpful for an increasingly complex set of tasks and\n",
      "use-cases (see 2.1). This paper presents evidence to support the latter two criteria, ﬁnding that LLMs on their\n",
      "own can have pervasive impacts across the economy, and that complementary innovations enabled by LLMs –\n",
      "particularly via software and digital tools – can have widespread application to economic activity.\n",
      "Figure 3 o ﬀers one illustration of the potential economic impact of complementary software built on top of\n",
      "LLMs. Taking the di ﬀerence in the y-axis (the share of all occupations) between UandZat a given point along\n",
      "the x-axis (the share of tasks within an occupation that are exposed) gives the aggregate within-occupation\n",
      "exposure potential attributable to tools and software over and above direct exposure from LLMs on their\n",
      "own. The di ﬀerence in means across all tasks between UandZof 0.42 using the GPT-4 annotations and 0.32\n",
      "using the human annotations (see Figure 3), suggests that the average impact of LLM-powered software on\n",
      "task-exposure may be more than twice as large as the mean exposure from LLMs on their own (mean Zof 0\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "exposure potential attributable to tools and software over and above direct exposure from LLMs on their\n",
      "own. The di ﬀerence in means across all tasks between UandZof 0.42 using the GPT-4 annotations and 0.32\n",
      "using the human annotations (see Figure 3), suggests that the average impact of LLM-powered software on\n",
      "task-exposure may be more than twice as large as the mean exposure from LLMs on their own (mean Zof 0.14\n",
      "based on both human annotations and GPT-4 annotations). While our ﬁndings suggest that out-of-the-box\n",
      "these models are relevant to a meaningful share of workers and tasks, they also suggest that the software\n",
      "innovations they spawn could drive a much broader impact.\n",
      "One component of the pervasiveness of a technology is its level of adoption by businesses and users.\n",
      "This paper does not systematically analyze adoption of these models, however, there is early qualitative\n",
      "evidence that adoption and use of LLMs is becoming increasingly widespread. The power of relatively\n",
      "simple UI improvements on top of LLMs was evident in the rollout of ChatGPT – wherein versions of the\n",
      "underlying language model had been previously available via API, but usage skyrocketed after the release of\n",
      "the ChatGPT interface. (Chow, 2023; OpenAI, 2022) Following this release, a number of commercial surveys\n",
      "indicate that ﬁrm and worker adoption of LLMs has increased over the past several months. (Constantz, 2023;\n",
      "ResumeBuilder.com, 2023)\n",
      "Widespread adoption of these models requires addressing existing bottlenecks. A key determinant of\n",
      "their utility is the level of conﬁdence humans place in them and how humans adapt their habits. For instance,\n",
      "in the legal profession, the models’ usefulness depends on whether legal professionals can trust model\n",
      "outputs without verifying original documents or conducting independent research. The cost and ﬂexibility\n",
      "of the technology, worker and ﬁrm preferences, and incentives also signiﬁcantly inﬂuence the adoption of\n",
      "tools built on top of LLMs. In this way, adoption may be driven by progress on some of the ethical and\n",
      "safety risks associated with LLMs: bias, fabrication of facts, and misalignment, to name a few OpenAI\n",
      "(2023a). Moreover, the adoption of LLMs will vary across di ﬀerent economic sectors due to factors such\n",
      "as data availability, regulatory environment, and the distribution of power and interests. Consequently, a\n",
      "comprehensive understanding of the adoption and use of LLMs by workers and ﬁrms requires a more in-depth\n",
      "exploration of these intricacies.\n",
      "One possibility is that time savings and seamless application will hold greater importance than quality\n",
      "improvement for the majority of tasks. Another is that the initial focus will be on augmentation, followed byimprovement for the majority of tasks. Another is that the initial focus will be on augmentation, followed by\n",
      "automation (Huang and Rust, 2018). One way this might take shape is through an augmentation phase where\n",
      "jobs ﬁrst become more precarious (e.g., writers becoming freelancers) before transitioning to full automation.WORKING PAPER\n",
      "6.2 Implications for US Public Policy\n",
      "The introduction of automation technologies, including LLMs, has previously been linked to heightened\n",
      "economic disparity and labor disruption, which may give rise to adverse downstream e ﬀects (Acemoglu and\n",
      "Restrepo, 2022a; Acemoglu, 2002; Moll et al., 2021; Klinova and Korinek, 2021; Weidinger et al., 2021,\n",
      "2022). Our results examining worker exposure in the United States underscore the need for societal and policy\n",
      "preparedness to the potential economic disruption posed by LLMs and the complementary technologies\n",
      "that they spawn. While it is outside the scope of this paper to recommend speciﬁc policy prescriptions to\n",
      "smooth the transition to an economy with increasingly widespread LLM adoption, prior work such as (Autor\n",
      "et al., 2022b) has articulated several important directions for US policy related to education, worker training,\n",
      "reforms to safety net programs, and more.\n",
      "6.3 Limitations and Future Work\n",
      "In addition to those discussed above, we highlight some particular limitations of this work that warrant further\n",
      "investigation. Primarily, our focus on the United States restricts the generalizability of our ﬁndings to other\n",
      "nations where the adoption and impact of generative models may di ﬀer due to factors such as industrial\n",
      "organization, technological infrastructure, regulatory frameworks, linguistic diversity, and cultural contexts.\n",
      "We hope to address this limitation by extending the study’s scope and by sharing our methods\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      ", we highlight some particular limitations of this work that warrant further\n",
      "investigation. Primarily, our focus on the United States restricts the generalizability of our ﬁndings to other\n",
      "nations where the adoption and impact of generative models may di ﬀer due to factors such as industrial\n",
      "organization, technological infrastructure, regulatory frameworks, linguistic diversity, and cultural contexts.\n",
      "We hope to address this limitation by extending the study’s scope and by sharing our methods so other\n",
      "researchers can build on them.\n",
      "Subsequent research e ﬀorts should consider two additional studies: one exploring LLM adoption patterns\n",
      "across various sectors and occupations, and another scrutinizing the actual capabilities and limitations of\n",
      "state-of-the-art models in relation to worker activities beyond the scope of our exposure scores. For example,\n",
      "despite recent advances in multimodal capabilities with GPT-4, we did not consider vision capabilities in\n",
      "theUratings on direct LLMs-exposure (OpenAI, 2023b). Future work should consider the impact of such\n",
      "capability advances as they unfold. Furthermore, we acknowledge that there may be discrepancies between\n",
      "theoretical and practical performance, particularly in complex, open-ended, and domain-speciﬁc tasks.\n",
      "7 Conclusion\n",
      "In conclusion, this study o ﬀers an examination of the potential impact of LLMs on various occupations and\n",
      "industries within the U.S. economy. By applying a new rubric for understanding LLM capabilities and their\n",
      "potential e ﬀects on jobs, we have observed that most occupations exhibit some degree of exposure to LLMs,\n",
      "with higher-wage occupations generally presenting more tasks with high exposure. Our analysis indicates that\n",
      "approximately 19% of jobs have at least 50% of their tasks exposed to LLMs when considering both current\n",
      "model capabilities and anticipated LLM-powered software.\n",
      "Our research aims to highlight the general-purpose potential of LLMs and their possible implications for\n",
      "US workers. Previous literature demonstrates the impressive improvements of LLMs to date (see 2.1). Our\n",
      "ﬁndings conﬁrm the hypothesis that these technologies can have pervasive impacts across a wide swath of\n",
      "occupations in the US, and that additional advancements supported by LLMs, mainly through software and\n",
      "digital tools, can have signiﬁcant e ﬀects on a range of economic activities. However, while the technical\n",
      "capacity for LLMs to make human labor more e ﬃcient appears evident, it is important to recognize that social,\n",
      "economic, regulatory, and other factors will inﬂuence actual labor productivity outcomes. As capabilities\n",
      "continue to evolve, the impact of LLMs on the economy will likely persist and increase, posing challenges for\n",
      "policymakers in predicting and regulating their trajectory.\n",
      "Further research is necessary to explore the broader implications of LLM advancements, including\n",
      "their potential to augment or displace human labor, their impact on job quality, impacts on inequality, skilltheir potential to augment or displace human labor, their impact on job quality, impacts on inequality, skill\n",
      "development, and numerous other outcomes. By seeking to understand the capabilities and potential e ﬀectsWORKING PAPER\n",
      "of LLMs on the workforce, policymakers and stakeholders can make more informed decisions to navigate the\n",
      "complex landscape of AI and its role in shaping the future of work.\n",
      "7.1 LLM Conclusion (GPT-4’s Version)\n",
      "Generative Pre-trained Transformers (GPTs) generate profound transformations, garnering potential technolog-\n",
      "ical growth, permeating tasks, greatly impacting professions. This study probes GPTs’ potential trajectories,\n",
      "presenting a groundbreaking rubric to gauge tasks’ GPT exposure, particularly in the U.S. labor market.\n",
      "7.2 LLM Conclusion (Author-Augmented Version)\n",
      "Generative Pre-trained Transformers (GPTs) generate profound transformations, garnering potential techno-\n",
      "logical growth, permeating tasks, gutting professional management. Gauging possible trajectories? Generate\n",
      "pioneering taxonomies, gather policymakers together, generalize past today.\n",
      "Acknowledgments\n",
      "Thank you to the group of annotators who helped us annotate task exposure, including Muhammad Ahmed\n",
      "Saeed, Bongane Zitha, Merve Özen Şenen, J.J., and Peter Hoeschele. We also thank Lauryn Fuld, Ashley Glat,\n",
      "Michael Lampe, and Julia Susser for excellent research assistance. We thank Miles Brundage for signiﬁcant\n",
      "feedback on this paper.\n",
      "We thank Todor Markov and Vik Goel for setting up the infrastructure we use to run our rubrics with\n",
      "GPT-4. We thank Lama Ahmad, Donald Bakong,\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      ", J.J., and Peter Hoeschele. We also thank Lauryn Fuld, Ashley Glat,\n",
      "Michael Lampe, and Julia Susser for excellent research assistance. We thank Miles Brundage for signiﬁcant\n",
      "feedback on this paper.\n",
      "We thank Todor Markov and Vik Goel for setting up the infrastructure we use to run our rubrics with\n",
      "GPT-4. We thank Lama Ahmad, Donald Bakong, Seth Benzell, Erik Brynjolfsson, Parfait Eloundou-Enyegue,\n",
      "Carl Frey, Sarah Giroux, Gillian Hadﬁeld, Johannes Heidecke, Alan Hickey, Eric Horvitz, Shengli Hu,\n",
      "Ashyana Kachra, Christina Kim, Katya Klinova, Daniel Kokotajlo, Gretchen Krueger, Michael Lampe, Aalok\n",
      "Mehta, Larissa Schiavo, Daniel Selsam, Sarah Shoker, Prasanna Tambe, and Je ﬀWu for feedback and edits at\n",
      "various stages of the project.\n",
      "LLM assistance statement\n",
      "GPT-4 and ChatGPT were used for writing, coding, and formatting assistance in this project.\n",
      "A Rubric\n",
      "A.1 Exposure\n",
      "# E Exposure Taxonomy\n",
      "Consider the most powerful OpenAI large language model (LLM) This model can complete many tasks\n",
      "that can be formulated as having text input and text output where the context for the input can be captured in\n",
      "2000 words. The model also cannot draw up-to-date facts (those from <1 year ago) unless they are captured\n",
      "in the input.\n",
      "Assume you are a worker with an average level of expertise in your role trying to complete the given task.\n",
      "You have access to the LLM as well as any other existing software or computer hardware tools mentioned\n",
      "in the task. You also have access to any commonly available technical tools accessible via a laptop (e.g. a\n",
      "microphone, speakers, etc.). You do not have access to any other physical tools or materials.\n",
      "Please label the given task according to the taxonomy below.\n",
      "## E0 – No exposure\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchain/chains/llm.py:349: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chain = load_qa_chain(\n",
    "    llm, chain_type=\"map_reduce\", verbose=True, return_intermediate_steps=True\n",
    ")\n",
    "query = \"what are the skills that are not likely to be replaced by LLMs?\"\n",
    "\n",
    "result = chain({\"input_documents\": job_doc, \"question\": query}\n",
    ", return_only_outputs=True\n",
    ")\n",
    "result['output_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Science and critical thinking skills are strongly negatively associated with exposure, suggesting that occupations requiring these skills are less likely to be impacted by current LLMs.'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['output_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6962c2",
   "metadata": {},
   "source": [
    "### Question-Answering: Map Re-Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6aa32765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapRerankDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "WORKING PAPER\n",
      "GPTs are GPTs: An Early Look at the Labor Market Impact Potential\n",
      "of Large Language Models\n",
      "Tyna Eloundou1, Sam Manning1,2, Pamela Mishkin\u00001, and Daniel Rock3\n",
      "1OpenAI\n",
      "2OpenResearch\n",
      "3University of Pennsylvania\n",
      "August 22, 2023\n",
      "Abstract\n",
      "We investigate the potential implications of large language models (LLMs), such as Generative Pre-\n",
      "trained Transformers (GPTs), on the U.S. labor market, focusing on the increased capabilities arising from\n",
      "LLM-powered software compared to LLMs on their own. Using a new rubric, we assess occupations based\n",
      "on their alignment with LLM capabilities, integrating both human expertise and GPT-4 classiﬁcations.\n",
      "Our ﬁndings reveal that around 80% of the U.S. workforce could have at least 10% of their work tasks\n",
      "aﬀected by the introduction of LLMs, while approximately 19% of workers may see at least 50% of their\n",
      "tasks impacted. We do not make predictions about the development or adoption timeline of such LLMs.\n",
      "The projected e ﬀects span all wage levels, with higher-income jobs potentially facing greater exposure to\n",
      "LLM capabilities and LLM-powered software. Signiﬁcantly, these impacts are not restricted to industries\n",
      "with higher recent productivity growth. Our analysis suggests that, with access to an LLM, about 15%\n",
      "of all worker tasks in the US could be completed signiﬁcantly faster at the same level of quality. When\n",
      "incorporating software and tooling built on top of LLMs, this share increases to between 47 and 56%\n",
      "of all tasks. This ﬁnding implies that LLM-powered software will have a substantial e ﬀect on scaling\n",
      "the economic impacts of the underlying models. We conclude that LLMs such as GPTs exhibit traits of\n",
      "general-purpose technologies, indicating that they could have considerable economic, social, and policy\n",
      "implications.\n",
      "1 Introduction\n",
      "As shown in Figure 1, recent years, months, and weeks have seen remarkable progress in the ﬁeld of generative\n",
      "AI and large language models (LLMs). While the public often associates LLMs with various iterations of the\n",
      "Generative Pre-trained Transformer (GPT), LLMs can be trained using a range of architectures, and are not\n",
      "limited to transformer-based models (Devlin et al., 2019). LLMs can process and produce various forms of\n",
      "sequential data, including assembly language, protein sequences and chess games, extending beyond natural\n",
      "language applications alone. In this paper, we use LLMs and GPTs somewhat interchangeably, and specify in\n",
      "our rubric that these should be considered similar to the GPT-family of models available via ChatGPT or\n",
      "the OpenAI Playground (which at the time of labeling included models in the GPT-3.5 family but not in the\n",
      "GPT-4 family). We examine LLMs with text- and code-generating abilities, use the term \"generative AI\" to\n",
      "additionally include modalities such as images or audio, and use \"LLM-powered software\" to cover tools built\n",
      "on top of LLMs or that combine LLMs with other generative AI models.\n",
      "\u0000Corresponding author (pamela@openai.com). Authors contributed equally and are listed alphabetically.arXiv:2303.10130v5  [econ.GN]  21 Aug 2023WORKING PAPER\n",
      "Figure 1: Taken directly from GPT-4 Technical Report (OpenAI, 2023b). To get a sense of how quickly\n",
      "model capabilities are progressing – consider the jump in exam performance between GPT-3.5 and GPT-4\n",
      "(OpenAI, 2023b).\n",
      "Our study is motivated less by the progress of these models alone though, and more by the breadth,\n",
      "scale, and capabilities we’ve seen in the complementary technologies developed around them. The role of\n",
      "complementary technologies remains to be seen, but maximizing the impact of LLMs appears contingent\n",
      "on integrating them with larger systems (Bresnahan, 2019; Agrawal et al., 2021). While the focus of our\n",
      "discussion is primarily on the generative capabilities of LLMs, it is important to note that these models can\n",
      "also be utilized for various tasks beyond text generation. For example, embeddings from LLMs can be used\n",
      "for custom search applications, and LLMs can perform tasks such as summarization and classiﬁcation where\n",
      "the context may be largely contained in the prompt.\n",
      "To complement predictions of technology’s impacts on work and provide a framework for understanding\n",
      "the evolving landscape of language models and their associated technologies,\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      " LLMs, it is important to note that these models can\n",
      "also be utilized for various tasks beyond text generation. For example, embeddings from LLMs can be used\n",
      "for custom search applications, and LLMs can perform tasks such as summarization and classiﬁcation where\n",
      "the context may be largely contained in the prompt.\n",
      "To complement predictions of technology’s impacts on work and provide a framework for understanding\n",
      "the evolving landscape of language models and their associated technologies, we propose a new rubric\n",
      "for assessing LLM capabilities and their potential e ﬀects on jobs. This rubric (A.1) measures the overall\n",
      "exposure of tasks to LLMs, following the spirit of prior work on quantifying exposure to machine learning\n",
      "(Brynjolfsson et al., 2018; Felten et al., 2018; Webb, 2020). We deﬁne exposure as a proxy for potential\n",
      "economic impact without distinguishing between labor-augmenting or labor-displacing e ﬀects. We employ\n",
      "human annotators and GPT-4 itself as a classiﬁer to apply this rubric to occupational data in the U.S. economy,\n",
      "primarily sourced from the O*NET database. 12\n",
      "To construct our primary exposure dataset, we collected both human annotations and GPT-4 classiﬁcations,\n",
      "using a prompt tuned for agreement with a sample of labels from the authors. We observe similar agreement\n",
      "1This is distinct from recent social science research that makes use of LLMs to simulate human behavior (Horton, 2023; Sorensen\n",
      "et al., 2022)\n",
      "2While our exposure rubric does not necessarily tie the concept of language models to any particular model, we were strongly\n",
      "motivated by our observed capabilities of GPT-4 and the suite of capabilities we saw in development with OpenAI’s launch partners\n",
      "(OpenAI, 2023b).WORKING PAPER\n",
      "levels in GPT-4 responses and between human and machine evaluations, when aggregated to the task level.\n",
      "This exposure measure reﬂects an estimate of the technical capacity to make human labor more e ﬃcient;\n",
      "however, social, economic, regulatory, and other determinants imply that technical feasibility does not\n",
      "guarantee labor productivity or automation outcomes. Our analysis indicates that approximately 19% of jobs\n",
      "have at least 50% of their tasks exposed when considering both current model capabilities and anticipated\n",
      "tools built upon them. Human assessments suggest that only 3% of U.S. workers have over half of their tasks\n",
      "exposed to LLMs when considering existing language and code capabilities without additional software or\n",
      "modalities. Accounting for other generative models and complementary technologies, our human estimates\n",
      "indicate that up to 49% of workers could have half or more of their tasks exposed to LLMs.\n",
      "Our ﬁndings consistently show across both human and GPT-4 annotations that most occupations exhibit\n",
      "some degree of exposure to LLMs, with varying exposure levels across di ﬀerent types of work. Occupations\n",
      "with higher wages generally present with higher exposure, a result contrary to similar evaluations of overall\n",
      "exposure to machine learning (Brynjolfsson et al., 2023). When regressing exposure measures on skillsets\n",
      "using O*NET’s skill rubric, we discover that roles heavily reliant on science and critical thinking skills show\n",
      "a negative correlation with exposure, while programming and writing skills are positively associated with\n",
      "LLM exposure. Following Autor et al. (2022a), we examine barriers to entry by \"Job Zones\" and ﬁnd that\n",
      "occupational exposure to LLMs weakly increases with the di ﬃculty of job preparation. In other words,\n",
      "workers facing higher (lower) barriers to entry in their jobs tend to experience more (less) exposure to LLMs.\n",
      "We further compare our measurements to previous e ﬀorts documenting the distribution of automation\n",
      "exposure in the economy and ﬁnd broadly consistent results. Most other technology exposure measures we\n",
      "examine are statistically signiﬁcantly correlated with our preferred exposure measure, while measures of\n",
      "manual routineness and robotics exposure show negative correlations. The variance explained by these earlier\n",
      "eﬀorts (Acemoglu and Autor, 2011a; Frey and Osborne, 2017; Brynjolfsson et al., 2018; Felten et al., 2018;\n",
      "Webb, 2020; Brynjolfsson et al., 2023), along with wage controls, ranges from 60 to 72%, indicating that 28\n",
      "to 40% of the variation in our AI exposure measure remains unaccounted for by previous technology exposure\n",
      "measurements.\n",
      "We analyze exposure by industry and discover that information processing industries (4-digit NAICS)\n",
      "exhibit high exposure, while manufacturing,\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "njolfsson et al., 2018; Felten et al., 2018;\n",
      "Webb, 2020; Brynjolfsson et al., 2023), along with wage controls, ranges from 60 to 72%, indicating that 28\n",
      "to 40% of the variation in our AI exposure measure remains unaccounted for by previous technology exposure\n",
      "measurements.\n",
      "We analyze exposure by industry and discover that information processing industries (4-digit NAICS)\n",
      "exhibit high exposure, while manufacturing, agriculture, and mining demonstrate lower exposure. The\n",
      "connection between productivity growth in the past decade and overall LLM exposure appears weak, suggesting\n",
      "a potential optimistic case that future productivity gains from LLMs may not exacerbate possible cost disease\n",
      "eﬀects (Baumol, 2012; Aghion et al., 2018). 3\n",
      "Our analysis indicates that the impacts of LLMs like GPT-4, are likely to be pervasive. While LLMs\n",
      "have consistently improved in capabilities over time, their growing economic e ﬀect is expected to persist and\n",
      "increase even if we halt the development of new capabilities today. We also ﬁnd that the potential impact of\n",
      "LLMs expands signiﬁcantly when we take into account the development of complementary technologies.\n",
      "Collectively, these characteristics imply that Generative Pre-trained Transformers (GPTs) are general-purpose\n",
      "technologies (GPTs). 4(Bresnahan and Trajtenberg, 1995; Lipsey et al., 2005).\n",
      "(Goldfarb et al., 2023) argue that machine learning as a broad category is likely a general-purpose\n",
      "technology. Our evidence supports a wider impact, as even subsets of machine learning software meet thetechnology. Our evidence supports a wider impact, as even subsets of machine learning software meet the\n",
      "criteria for general-purpose technology status independently. This paper’s primary contributions are to provide\n",
      "a set of measurements of LLM impact potential and to demonstrate the use case of applying LLMs to develop\n",
      "such measurements e ﬃciently and at scale. Additionally, we showcase the general-purpose potential of LLMs.\n",
      "If \"GPTs are GPTs,\" the eventual trajectory of LLM development and application may be challenging for\n",
      "3Baumol’s cost disease is a theory that explains why the cost of labor-intensive services, such as healthcare and education,\n",
      "increases over time. This happens because wages for skilled workers in other industries increase, but there is no corresponding\n",
      "increase in productivity or e ﬃciency in these service industries. Therefore, the cost of labor in these industries becomes relatively\n",
      "more expensive compared to other goods and services in the economy.\n",
      "4For the remainder of the paper we spell out general-purpose technologies when it is used outside of stating \"GPTs are GPTs.\"WORKING PAPER\n",
      "policymakers to predict and regulate. As with other general-purpose technologies, much of these algorithms’\n",
      "potential will emerge across a broad range of economically valuable use cases, including the creation of new\n",
      "types of work (Acemoglu and Restrepo, 2018; Autor et al., 2022a). Our research serves to measure what is\n",
      "technically feasible now, but necessarily will miss the evolving impact potential of the LLMs over time.\n",
      "The paper is structured as follows: Section 2 reviews relevant prior work, Section 3 discusses methods\n",
      "and data collection, Section 4 presents summary statistics and results, Section 5 relates our measurements to\n",
      "earlier e ﬀorts, Section 6 discusses the results, and Section 7 o ﬀers concluding remarks.\n",
      "2 Literature Review\n",
      "2.1 The Advancement of Large Language Models\n",
      "In recent years, generative AI models have gained signiﬁcant attention from both the artiﬁcial intelligence\n",
      "(AI) research community and the general public, due to their ability to tackle a wide array of complex\n",
      "language-based tasks. The progress in these models’ abilities has been fueled by multiple factors, including\n",
      "increased model parameter count, greater training data volume, and enhanced training conﬁgurations (Brown\n",
      "et al., 2020; Radford et al., 2019; Hernandez et al., 2021; Kaplan et al., 2020). Broad, state-of-the-art LLMs,\n",
      "such as LaMDA (Thoppilan et al., 2022) and GPT-4 (OpenAI, 2023b), excel in diverse applications like\n",
      "translation, classiﬁcation, creative writing, and code generation—capabilities that previously demanded\n",
      "specialized, task-speciﬁc models developed by expert engineers using domain-speciﬁc data.\n",
      "Concurrently, researchers have improved the steerability, reliability, and utility of these models using\n",
      "methods like ﬁne-tuning and reinforcement\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      " and GPT-4 (OpenAI, 2023b), excel in diverse applications like\n",
      "translation, classiﬁcation, creative writing, and code generation—capabilities that previously demanded\n",
      "specialized, task-speciﬁc models developed by expert engineers using domain-speciﬁc data.\n",
      "Concurrently, researchers have improved the steerability, reliability, and utility of these models using\n",
      "methods like ﬁne-tuning and reinforcement learning with human feedback (Ouyang et al., 2022; Bai et al.,\n",
      "2022). These advancements enhance the models’ ability to discern user intent, rendering them more\n",
      "user-friendly and practical. Moreover, recent studies reveal the potential of LLMs to program and control\n",
      "other digital tools, such as APIs, search engines, and even other generative AI systems (Schick et al., 2023;\n",
      "Mialon et al., 2023; Chase, 2022). This enables seamless integration of individual components for better\n",
      "utility, performance, and generalization. At their limit, these trends suggest a world where LLMs may be\n",
      "capable of executing any task typically performed at a computer.\n",
      "Generative AI models have mostly been deployed as modular specialists, performing speciﬁc tasks such as\n",
      "generating images from captions or transcribing text from speech. However, we argue that it is essential to view\n",
      "LLMs as versatile building blocks for creating additional tools. Developing these tools and integrating them\n",
      "into systems will require time and possibly signiﬁcant reconﬁguration of existing processes across various\n",
      "industries. Nevertheless, we are already witnessing emerging adoption trends. Despite their limitations,\n",
      "LLMs are increasingly being integrated into specialized applications in ﬁelds like writing assistance, coding,\n",
      "and legal research. These specialized applications then allow businesses and individuals to adopt LLMs into\n",
      "their workﬂows.\n",
      "We emphasize the signiﬁcance of these complementary technologies, partly because out-of-the-box\n",
      "general-purpose LLMs may continue to be unreliable for various tasks due to issues such as factual inaccuracies,\n",
      "inherent biases, privacy concerns, and disinformation risks (Abid et al., 2021; Schramowski et al., 2022;\n",
      "Goldstein et al., 2023; OpenAI, 2023a). However, specialized workﬂows—including tooling, software, or\n",
      "human-in-the-loop systems—can help address these shortcomings by incorporating domain-speciﬁc expertise.\n",
      "For example, Casetext o ﬀers LLM-based legal research tools that provide lawyers with quicker and more\n",
      "accurate legal research results, utilizing embeddings and summarization to counter the risk that GPT-4 couldaccurate legal research results, utilizing embeddings and summarization to counter the risk that GPT-4 could\n",
      "provide inaccurate details about a legal case or set of documents. GitHub Copilot is a coding assistant that\n",
      "employs LLMs to generate code snippets and auto-complete code, which users can then accept or reject based\n",
      "on their expertise. In other words, while it’s true that on its own GPT-4 does not \"know what time it is,\" it’s\n",
      "easy enough to give it a watch.WORKING PAPER\n",
      "Furthermore, a positive feedback loop may emerge as LLMs surpass a speciﬁc performance threshold,\n",
      "allowing them to assist in building the very tooling that enhances their usefulness and usability across various\n",
      "contexts. This could lower the cost and engineering expertise required to create such tools, potentially\n",
      "accelerating LLM adoption and integration even further (Chen et al., 2021; Peng et al., 2023). LLMs can also\n",
      "become valuable assets in machine learning model development—serving as coding assistants for researchers,\n",
      "data labeling services, or synthetic data generators. There is potential for such models to contribute to\n",
      "economic decision-making at the task level, for instance, by reﬁning methods for task and sub-task allocation\n",
      "between humans and machines (Singla et al., 2015; Shahaf and Horvitz, 2010). As LLMs advance over time\n",
      "and better align with user preferences, we can anticipate continuous improvement in performance. However, it\n",
      "is essential to recognize that these trends also bring a variety of serious risks. (Khlaaf et al., 2022; Weidinger\n",
      "et al., 2022; Solaiman et al., 2019)\n",
      "2.2 The Economic Impacts of Automation Technologies\n",
      "A large and growing body of literature addresses the labor market impacts of AI and automation technologies.\n",
      "The concept of skill-biased technological change and the task model of automation—often considered\n",
      "the standard framework for understanding technology’s inﬂuence on labor—originated from research\n",
      "\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      " risks. (Khlaaf et al., 2022; Weidinger\n",
      "et al., 2022; Solaiman et al., 2019)\n",
      "2.2 The Economic Impacts of Automation Technologies\n",
      "A large and growing body of literature addresses the labor market impacts of AI and automation technologies.\n",
      "The concept of skill-biased technological change and the task model of automation—often considered\n",
      "the standard framework for understanding technology’s inﬂuence on labor—originated from research\n",
      "demonstrating that technological progress raises the demand for skilled workers over unskilled workers (Katz\n",
      "and Murphy, 1992). Numerous studies have built upon this concept, exploring the e ﬀects of technological\n",
      "change and automation on workers within a task-based framework (Autor et al., 2003; Acemoglu and Autor,\n",
      "2011b; Acemoglu and Restrepo, 2018). This strand of research has shown that workers involved in routine and\n",
      "repetitive tasks are at a higher risk of technology-driven displacement, a phenomenon known as routine-biased\n",
      "technological change. More recent studies have distinguished between technology’s task-displacement and\n",
      "task-reinstatement e ﬀects (where new technology increases the need for a wider array of labor-intensive tasks)\n",
      "(Acemoglu and Restrepo, 2018, 2019). Several studies have shown that automation technologies have resulted\n",
      "in wage inequality in the US, driven by relative wage declines for workers specializing in routine tasks (Autor\n",
      "et al., 2006; Van Reenen, 2011; Acemoglu and Restrepo, 2022b).\n",
      "Prior research has employed various approaches to estimate the overlap between AI capabilities and\n",
      "the tasks and activities workers undertake in di ﬀerent occupations. These methods include mapping patent\n",
      "descriptions to worker task descriptions (Webb, 2020; Meindl et al., 2021), linking AI capabilities to\n",
      "occupational abilities documented in the O*NET database (Felten et al., 2018, 2023), aligning AI task\n",
      "benchmark evaluations with worker tasks via cognitive abilities (Tolan et al., 2021), labeling automation\n",
      "potential for a subset of US occupations and using machine learning classiﬁers to estimate this potential for\n",
      "all other US occupations (Frey and Osborne, 2017), modeling task-level automation and aggregating the\n",
      "results to occupation-level insights (Arntz et al., 2017), collecting expert forecasts (Grace et al., 2018), and\n",
      "most relevantly to this paper, devising a new rubric to assess worker activities for their suitability for machine\n",
      "learning (Brynjolfsson et al., 2018, 2023). Some of these approaches have found exposure to AI technologies\n",
      "at the task-level tends to be diversiﬁed within occupation. Considering each job as a bundle of tasks, it would\n",
      "be rare to ﬁnd any occupation for which AI tools could do nearly all of the work. (Autor et al., 2022a) ﬁnds as\n",
      "well that automation and augmentation exposures tend to be positively correlated. There is also a growing setwell that automation and augmentation exposures tend to be positively correlated. There is also a growing set\n",
      "of studies examining speciﬁc economic impacts and opportunities for LLMs (Bommasani et al., 2021; Felten\n",
      "et al., 2023; Korinek, 2023; Mollick and Mollick, 2022; Noy and Zhang, 2023; Peng et al., 2023). Alongside\n",
      "this work, our measurements help characterize the broader potential relevance of language models to the\n",
      "labor market.\n",
      "General-purpose technologies (e.g. printing, the steam engine) are characterized by widespread prolifera-\n",
      "tion, continuous improvement, and the generation of complementary innovations (Bresnahan and Trajtenberg,\n",
      "1995; Lipsey et al., 2005). Their far-reaching consequences, which unfold over decades, are di ﬃcult to\n",
      "anticipate, particularly in relation to labor demand (Bessen, 2018; Korinek and Stiglitz, 2018; Acemoglu et al.,WORKING PAPER\n",
      "2020; Benzell et al., 2021). The realization of general purpose technologies’ full potential requires extensive\n",
      "co-invention (Bresnahan and Trajtenberg, 1995; Bresnahan et al., 1996, 2002; Lipsey et al., 2005; Dixon et al.,\n",
      "2021), a costly and time-consuming process involving the discovery of new business procedures (David, 1990;\n",
      "Bresnahan, 1999; Frey, 2019; Brynjolfsson et al., 2021; Feigenbaum and Gross, 2021). Consequently, many\n",
      "studies of machine learning technologies focus on systems-level adoption, arguing that organizational systems\n",
      "may require redesign to e �\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "ahan et al., 1996, 2002; Lipsey et al., 2005; Dixon et al.,\n",
      "2021), a costly and time-consuming process involving the discovery of new business procedures (David, 1990;\n",
      "Bresnahan, 1999; Frey, 2019; Brynjolfsson et al., 2021; Feigenbaum and Gross, 2021). Consequently, many\n",
      "studies of machine learning technologies focus on systems-level adoption, arguing that organizational systems\n",
      "may require redesign to e ﬀectively take advantage of novel machine learning advancements (Bresnahan,\n",
      "2019; Agrawal et al., 2021; Goldfarb et al., 2023). Appropriately designed systems can yield considerable\n",
      "business value and improve ﬁrm performance (Rock, 2019; Babina et al., 2021; Zolas et al., 2021), with AI\n",
      "tools facilitating the discovery process (Cockburn et al., 2018; Cheng et al., 2022). By employing task-level\n",
      "information to assess whether LLMs fulﬁll the criteria of a general purpose technology, we seek to merge the\n",
      "two perspectives for understanding the technology-labor relationship.\n",
      "We attempt to build on these diverse literature streams in several ways. Echoing (Felten et al., 2023), we\n",
      "focus our analysis on the impact of LLMs, rather than addressing machine learning or automation technologies\n",
      "more broadly. Additionally, we propose a novel method that employs LLMs, speciﬁcally GPT-4, to assess tasks\n",
      "for exposure and automation potential, thereby bolstering human scoring e ﬀorts. Subsequently, we aggregate\n",
      "our ﬁndings to occupations and industries, capturing the overall potential exposure in the contemporary U.S.\n",
      "labor market.\n",
      "3 Methods and Data Collection\n",
      "3.1 Data on Activities and Tasks Performed by Occupation in the US\n",
      "We use the O*NET 27.2 database (O*NET, 2023), which contains information on 1,016 occupations, including\n",
      "their respective Detailed Work Activities (DWAs) and tasks. A DWA is a comprehensive action that is part of\n",
      "completing task, such as \"Study scripts to determine project requirements.\" A task, on the other hand, is an\n",
      "occupation-speciﬁc unit of work that may be associated with zero, one, or multiple DWAs. We o ﬀer a sample\n",
      "of tasks and DWAs in Table 1. The two datasets we use consist of:\n",
      "•19,265 tasks, consisting of a \"task description\" and a corresponding occupation, and\n",
      "•2,087 DWAs, where most DWAs are connected to one or more tasks, and tasks may be associated with\n",
      "one or more DWAs, though some tasks lack any associated DWAs.\n",
      "3.2 Data on Wages, Employment, and Demographics\n",
      "We obtain employment and wage data from the 2020 and 2021 Occupational Employment series provided by\n",
      "the Bureau of Labor Statistics. This dataset encompasses occupational titles, the number of workers in each\n",
      "occupation, and occupation-level employment projections for 2031, typical education required for entry in an\n",
      "occupation and on-the-job training required to attain competency in an occupation (BLS, 2022). We use the\n",
      "BLS-recommended crosswalk to O*NET (BLS, 2023b) to link the O*NET task and DWA dataset and the\n",
      "BLS Labor Force Demographics (BLS, 2023a), which is derived from the Current Population Survey (CPS).\n",
      "Both of these data sources are collected by the U.S. government and primarily capture workers who are not\n",
      "self-employed, are documented, and are working in the so-called formal economy.\n",
      "3.3 Exposure\n",
      "We present our results based on an exposure rubric, in which we deﬁne exposure as a measure of whether\n",
      "access to an LLM or LLM-powered system would reduce the time required for a human to perform a speciﬁcWORKING PAPER\n",
      "Task ID Occupation Title DWAs Task Description\n",
      "14675 Computer Systems\n",
      "Engineers/ArchitectsMonitor computer system performance\n",
      "to ensure proper operation.Monitor system operation to detect potential\n",
      "problems.\n",
      "18310 Acute Care Nurses Operate diagnostic or therapeutic\n",
      "medical instruments or equipment.\n",
      "Prepare medical supplies or equipment\n",
      "for use.Set up, operate, or monitor invasive equipment\n",
      "and devices, such as colostomy or tracheotomy\n",
      "equipment, mechanical ventilators, catheters,\n",
      "gastrointestinal tubes, and central lines.\n",
      "4668.0 Gambling Cage\n",
      "WorkersExecute sales or other ﬁnancial\n",
      "transactions.Cash checks and process credit card advances\n",
      "for patrons.\n",
      "15709 Online Merchants Execute sales or other ﬁnancial\n",
      "transactions.Deliver\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      " operate, or monitor invasive equipment\n",
      "and devices, such as colostomy or tracheotomy\n",
      "equipment, mechanical ventilators, catheters,\n",
      "gastrointestinal tubes, and central lines.\n",
      "4668.0 Gambling Cage\n",
      "WorkersExecute sales or other ﬁnancial\n",
      "transactions.Cash checks and process credit card advances\n",
      "for patrons.\n",
      "15709 Online Merchants Execute sales or other ﬁnancial\n",
      "transactions.Deliver e-mail conﬁrmation of completed\n",
      "transactions and shipment.\n",
      "6529 Kindergarten\n",
      "Teachers, Except\n",
      "Special Education– Involve parent volunteers and older students in\n",
      "children’s activities to facilitate involvement in\n",
      "focused, complex play.\n",
      "6568 Elementary School\n",
      "Teachers, Except\n",
      "Special Education– Involve parent volunteers and older students in\n",
      "children’s activities to facilitate involvement in\n",
      "focused, complex play.\n",
      "Table 1: Sample of occupations, tasks, and Detailed Work Activities from the O*NET database. We see\n",
      "that aggregating over activities alone is imprecise, as evidenced by the fact that we’d expect Gambling Cage\n",
      "Workers to complete the given DWA in person, using some physicality while we’d expect Online Merchants\n",
      "to complete the same activity solely with a computer.\n",
      "DWA or complete a task by at least 50 percent. Though GPT-4 has vision capabilities OpenAI (2023b) and\n",
      "\"LLM\" is often used to refer to a much wider range of modalities, vision and image capabilities were only\n",
      "included in our deﬁnition of LLM-powered software. We provide a summary of our rubric below, while the\n",
      "complete rubric can be found in A.1. When we have labels for DWAs, we ﬁrst aggregate them to the task\n",
      "level before aggregating to the occupation level.\n",
      "No exposure (E0) if:\n",
      "•using the described LLM results in no or minimal reduction in the time required to\n",
      "complete the activity or task while maintaining equivalent qualityaor\n",
      "•using the described LLM results in a decrease in the quality of the activity/task output.\n",
      "Direct exposure (E1) if:\n",
      "•using the described LLM via ChatGPT or the OpenAI playground can decrease the time\n",
      "required to complete the DWA or task by at least half (50%).\n",
      "LLM+ Exposed (E2) if:\n",
      "•access to the described LLM alone would not reduce the time required to complete the\n",
      "activity/task by at least half, but\n",
      "•additional software could be developed on top of the LLM that could reduce the time it\n",
      "takes to complete the speciﬁc activity/task with quality by at least half. Among these\n",
      "systems, we count access to image generation systems.b\n",
      "aEquivalent quality means that a third party, typically the recipient of the output, would not notice or\n",
      "care about LLM assistance.\n",
      "bIn practice, as can be seen in the full rubric in Appendix A.1, we categorize access to image capabilities\n",
      "separately (E3) to facilitate annotation, though we combine E2 and E3 for all analyses.Summary of exposure rubric\n",
      "We set the exposure threshold at a potential 50% reduction in time required to complete a speciﬁc DWAWORKING PAPER\n",
      "or task while maintaining consistent quality. We anticipate that adoption will be highest and most immediate\n",
      "for applications that realize a considerable increase in productivity. Although this threshold is somewhat\n",
      "arbitrary, it was selected for ease of interpretation by annotators. Moreover, regardless of the chosen threshold,\n",
      "we guessed that the real-world reduction in task time would likely be slightly or signiﬁcantly lower than our\n",
      "estimates, leading us to opt for a relatively high threshold. In our own validation labeling, we found that this\n",
      "corresponded closely to whether an LLM or LLM-powered software could perform the core part of a task or\n",
      "nearly the entire task.\n",
      "Comparison WWeighting Agreement Pearson’s\n",
      "GPT-4, Rubric 1; Human UE1 80.8% 0.223\n",
      "VE1 + .5*E2 65.6% 0.591\n",
      "ZE1 + E2 82.1% 0.654\n",
      "GPT-4, Rubric 2; Human UE1 81.8% 0.221\n",
      "VE1 + .5*E2 65.6% 0.538\n",
      "ZE1 + E2 79.5% 0.589\n",
      "GPT-4, Rubric 1; GPT-4, Rubric 2 UE1 91.1% 0.611\n",
      "VE1 + .5*E2 76.0% 0.705\n",
      "ZE1 + E2 82.4\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "PT-4, Rubric 2; Human UE1 81.8% 0.221\n",
      "VE1 + .5*E2 65.6% 0.538\n",
      "ZE1 + E2 79.5% 0.589\n",
      "GPT-4, Rubric 1; GPT-4, Rubric 2 UE1 91.1% 0.611\n",
      "VE1 + .5*E2 76.0% 0.705\n",
      "ZE1 + E2 82.4% 0.680\n",
      "Table 2: Model and human comparison of agreement and Pearson’s correlation scores. The agreement score\n",
      "is determined by looking at how often the two groups agree on the annotation (e.g. E0, E1 or E2). In the\n",
      "paper we use GPT-4, Rubric 1. Core tasks are given twice the weight at the occupation-level as supplemental\n",
      "tasks. All weights sum to one.\n",
      "We then collected both human and GPT-4-generated annotations using the exposure rubric, which underlie\n",
      "the bulk of the analyses in this paper.\n",
      "•Human Ratings: We obtained human annotations by applying the rubric to each O*NET Detailed\n",
      "Worker Activity (DWA) and a subset of all O*NET tasks and then aggregated those DWA and task\n",
      "scores 5at the task and occupation levels. The authors personally labeled a large sample of tasks and\n",
      "DWAs and enlisted experienced human annotators who have reviewed GPT-3, GPT-3.5 and GPT-4\n",
      "outputs as part of OpenAI’s alignment work (Ouyang et al., 2022).\n",
      "•GPT-4 Ratings: We administered a similar rubric to an early version of GPT-4 (OpenAI, 2023b) but on\n",
      "all task/occupation pairs rather than DWAs. We made slight modiﬁcations to the rubric (which was\n",
      "used as a \"prompt\" to the model in this case) to enhance agreement with a set of human labels. Full\n",
      "agreement rates are given in Table 2.\n",
      "We construct three primary measures for our dependent variable of interest: (i) U, corresponding to E1 in\n",
      "the exposure rubric above, anticipated to represent the lower bound of the proportion of exposed tasks within\n",
      "an occupation, (ii) V, which is the sum of E1 and 0.5*E2, where the 0.5 weight on E2 is intended to account\n",
      "for exposure when deploying the technology via complementary tools and applications necessitates additional\n",
      "investment, and (iii) Z, the sum of E1 and E2, an upper bound of exposure that provides an assessment of\n",
      "maximal exposure to an LLLM and LLM-powered software. We summarize agreement between annotation\n",
      "groups and measures in Table 2. For the remainder of the analysis, if not speciﬁed, the reader may assume that\n",
      "5The authors annotated DWAs that clearly required a high degree of physicality or manual dexterity, and the contracted annotators\n",
      "labeled the remaining activities, along with a subset of tasks including those without associated DWAs and those for which there was\n",
      "no clear task-level annotation after aggregating the DWA annotations.WORKING PAPER\n",
      "we refer to Vexposure – meaning all tasks directly exposed via tools like ChatGPT or the OpenAI Playground\n",
      "are considered twice as exposed as tasks requiring some complementary innovation.\n",
      "3.4 Limitations of our methodology\n",
      "3.4.1 Subjective human judgments\n",
      "A fundamental limitation of our approach lies in the subjectivity of the labeling. In our study, we employ\n",
      "annotators who are familiar with LLM capabilities. However, this group is not occupationally diverse,\n",
      "potentially leading to biased judgments regarding LLMs’ reliability and e ﬀectiveness in performing tasks\n",
      "within unfamiliar occupations. We acknowledge that obtaining high-quality labels for each task in an\n",
      "occupation requires workers engaged in those occupations or, at a minimum, possessing in-depth knowledge\n",
      "of the diverse tasks within those occupations. This represents an important area for future work in validating\n",
      "these results.\n",
      "3.4.2 Measuring LLMs with GPT-4\n",
      "Recent research indicates that GPT-4 serves as an e ﬀective discriminator, capable of applying intricate\n",
      "taxonomies and responding to changes in wording and emphasis (OpenAI, 2023b). The outcomes of GPT-4\n",
      "task classiﬁcation are sensitive to alterations in the rubric’s wording, the prompt’s order and composition, the\n",
      "presence or absence of speciﬁc examples in the rubric, the level of detail provided, and the deﬁnitions given\n",
      "for key terms. Iterating on the prompt, based on observed outcomes in a small validation set, can\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "OpenAI, 2023b). The outcomes of GPT-4\n",
      "task classiﬁcation are sensitive to alterations in the rubric’s wording, the prompt’s order and composition, the\n",
      "presence or absence of speciﬁc examples in the rubric, the level of detail provided, and the deﬁnitions given\n",
      "for key terms. Iterating on the prompt, based on observed outcomes in a small validation set, can enhance the\n",
      "agreement between model outputs and the rubric’s intent. Consequently, there are slight di ﬀerences between\n",
      "the rubric presented to humans and the one used for GPT-4. This decision was made deliberately to guide\n",
      "the model towards reasonable labels without excessively inﬂuencing human annotators. As a result, we use\n",
      "multiple annotation sources, but none should be considered the deﬁnitive ground truth relative to the others.\n",
      "In this analysis, we present results from human annotators as our primary results. Further improvement and\n",
      "innovation in crafting e ﬀective rubrics for LLM classiﬁcation remains possible. Still, we observe a high\n",
      "degree of agreement between human ratings and GPT-4 ratings at the occupation level concerning overall\n",
      "exposure to LLM systems (see Table 2, Figure 2).\n",
      "3.4.3 Additional Weaknesses\n",
      "•Validity of task-based framework. It is unclear to what extent occupations can be entirely broken\n",
      "down into tasks, and whether this approach systematically omits certain categories of skills or tasks\n",
      "that are tacitly required for competent performance of a job. Additionally, tasks can be composed of\n",
      "sub-tasks, some of which are more automatable than others. Some tasks may function as pre-cursor to\n",
      "other tasks, such that the completion of downstream tasks is dependent on precursor tasks. If indeed,\n",
      "the task-based breakdown is not a valid representation of how most work in an occupation is performed,\n",
      "our exposure analysis would largely be invalidated.\n",
      "•Lack of expertise and task interpretation. Human annotators were mostly unaware of the speciﬁc\n",
      "occupations mapped to each DWA during the labeling process. This led to unclear logic for aggregating\n",
      "tasks and occupations, as well as some evident discrepancies in labels, demonstrated in Table 1. We\n",
      "experimented with various aggregation methods and discovered that even with a maximum-matching\n",
      "approach (taking the matching human<>model label if one existed), the agreement remained relatively\n",
      "consistent. Ultimately, we collected additional labels for task/occupation pairs where there was\n",
      "signiﬁcant disagreement.WORKING PAPER\n",
      "Figure 2: Human raters (x-axis) and GPT-4 ratings (y-axis) show a high degree of agreement about LLM\n",
      "exposure by occupation. We compute occupation-level exposure in these ﬁgures by averaging the task-level\n",
      "exposures under the Vmethod. O*NET designates some tasks as \"core\" and others \"supplemental\". Core\n",
      "tasks are given twice the weight of supplemental tasks, and all weights sum to one. Near the highest levels of\n",
      "exposure following the Vmethod of aggregating exposure scores to occupations, GPT-4 ratings tend to be\n",
      "lower than Human ratings. We present the raw scatter plot and the binscatter. Near the top end of exposure\n",
      "ratings, humans are on average more likely to rate an occupation as exposed.\n",
      "•Forward-looking and subject to change, with some early evidence. Accurately predicting future\n",
      "LLM applications remains a signiﬁcant challenge, even for experts (OpenAI, 2023b). The discovery of\n",
      "new emergent capabilities, changes in human perception biases, and shifts in technological development\n",
      "can all a ﬀect the accuracy and reliability of predictions regarding the potential impact of LLMs\n",
      "on worker tasks and the development of LLM-powered software. Our projections are inherently\n",
      "forward-looking and based on current trends, evidence, and perceptions of technological possibilities.\n",
      "As a result, they may change as new advancements arise in the ﬁeld. For example, some tasks that\n",
      "seem unlikely for LLMs or LLM-powered software to impact today might change with the introduction\n",
      "of new model capabilities. Conversely, tasks that appear exposed might face unforeseen challenges\n",
      "limiting language model applications.\n",
      "•Sources of disagreement. While we did not rigorously examine sources of disagreement, we found a\n",
      "few places where humans and the model tended to get \"stuck\" in their assessments:\n",
      "–Tasks or activities where while an LLM could theoretically help or accomplish the task, adopting\n",
      "it to do so would require multiple people to change their habits or expectations (e.g. meetings,\n",
      "negotiations),\n",
      "–Tasks or\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      " unforeseen challenges\n",
      "limiting language model applications.\n",
      "•Sources of disagreement. While we did not rigorously examine sources of disagreement, we found a\n",
      "few places where humans and the model tended to get \"stuck\" in their assessments:\n",
      "–Tasks or activities where while an LLM could theoretically help or accomplish the task, adopting\n",
      "it to do so would require multiple people to change their habits or expectations (e.g. meetings,\n",
      "negotiations),\n",
      "–Tasks or activities where there is currently some regulation or norm that requires or suggests\n",
      "human oversight, judgment or empathy (e.g. making decisions, counseling), and\n",
      "–Tasks or activities where there already exists a technology that can reasonably automate the task\n",
      "(e.g. making reservations).\n",
      "4 Results\n",
      "General-purpose technologies are relatively rare and characterized by their pervasiveness, improvement over\n",
      "time, and the development of signiﬁcant co-invention and spillovers (Lipsey et al., 2005). Our assessment ofWORKING PAPER\n",
      "LLMs’ potential impact on the labor market is limited since it does not consider total factor productivity or\n",
      "capital input potential. In addition to their inﬂuence on labor, LLMs may also inﬂuence these dimensions.\n",
      "At this stage, some general-purpose technology criteria are easier to evaluate than others. Our primary\n",
      "focus at this early stage is to test the hypothesis that LLMs have a pervasive inﬂuence on the economy,\n",
      "similar to the approach taken by (Goldfarb et al., 2023), who analyzed machine learning di ﬀusion through\n",
      "job postings to assess its status as a general-purpose technology. Instead of using job postings or studying\n",
      "machine learning in general, we employ the task evaluation approach with both human and GPT-4 annotations.\n",
      "This analysis may reveal whether the impacts are limited to a speciﬁc set of similar tasks or occupations or if\n",
      "they will be more widespread.\n",
      "Our ﬁndings suggest that, based on their task-level capabilities, LLMs have the potential to signiﬁcantly\n",
      "aﬀect a diverse range of occupations within the U.S. economy, demonstrating a key attribute of general-purpose\n",
      "technologies. In the following sections, we discuss results across various roles and wage structures. Additional\n",
      "results on the relative exposure of industries within the U.S. economy can be found in Appendix C.\n",
      "4.1 Summary Statistics\n",
      "Summary statistics for these measures can be found in Table 3. Both human and GPT-4 annotations indicate\n",
      "that average occupation-level Uvalues fall between 0.14 and 0.15, suggesting that, on average, approximately\n",
      "15% of tasks within an occupation are directly exposed to LLMs. 6This ﬁgure increases to over 30% for V\n",
      "and surpasses 50% for Z. Coincidentally, human and GPT-4 annotations also tag between 15% and 14% of\n",
      "total tasks in the dataset as being exposed to LLMs. Based on the Vvalues, we estimate that 80% of workers\n",
      "belong to an occupation with at least 10% of its tasks exposed to LLMs, while 19% of workers are in an\n",
      "occupation where over half of its tasks are labeled as exposed.\n",
      "We ran one set of analyses using O*NET’s \"Importance\" scores but did not ﬁnd signiﬁcant changes to our\n",
      "ﬁndings. Though we do acknowledge that not weighting relative importance of a task to a given occupation\n",
      "yields some curious results (e.g. ranking Barbers as having reasonably high exposure).\n",
      "Although the potential for tasks to be a ﬀected is vast, LLMs and LLM-powered software must be\n",
      "incorporated into broader systems to fully realize this potential. As is common with general-purpose\n",
      "technologies, co-invention barriers may initially impede the rapid di ﬀusion of GPTs into economic applications.\n",
      "Furthermore, predicting the need for human oversight is challenging, especially for tasks where model\n",
      "capabilities equal or surpass human levels. While the requirement for human supervision may initially slow\n",
      "down the speed at which these systems di ﬀuse through the economy, users of LLMs and LLM-powered\n",
      "systems are likely to become increasingly acquainted with the technology over time, particularly in terms of\n",
      "understanding when and how to trust its outputs.\n",
      "4.2 Wages and Employment\n",
      "In Figure 3, we present exposure intensity across the economy. Each point on the plot displays occupational\n",
      "exposure, where the point’s x-axis value represents the share of an occupation’s tasks that are exposed (at\n",
      "each level U,V, and Z) and the point’s y-axis value represents the share of all\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      " over time, particularly in terms of\n",
      "understanding when and how to trust its outputs.\n",
      "4.2 Wages and Employment\n",
      "In Figure 3, we present exposure intensity across the economy. Each point on the plot displays occupational\n",
      "exposure, where the point’s x-axis value represents the share of an occupation’s tasks that are exposed (at\n",
      "each level U,V, and Z) and the point’s y-axis value represents the share of all US occupations with that share\n",
      "of tasks exposed. For example, human annotators determined that 2.3% of occupations are U50-exposed,\n",
      "21.6% are V50-exposed, and 47.3% are Z50-exposed, where the threshold of 50% comes from the x-axis and\n",
      "the percentage of occupations comes from the y axis. At any given point on the x-axis, the vertical distance\n",
      "between the Uand the Zrepresents the exposure potential attributable to tools and applications beyond direct\n",
      "exposure to LLMs. All tasks within an occupation in this ﬁgure are given equal weight.between the Uand the Zrepresents the exposure potential attributable to tools and applications beyond direct\n",
      "exposure to LLMs. All tasks within an occupation in this ﬁgure are given equal weight.\n",
      "6We compute occupation-level scores for Table 3 assigning double the weight to tasks designated as \"core\" by O*NET as tasks\n",
      "designated \"supplemental\". All tasks weights sum to one within an occupation.WORKING PAPER\n",
      "Occupation Level Exposure\n",
      "Human GPT-4\n",
      "mean std mean std\n",
      "UUU0.14 0.14 0.14 0.16\n",
      "VVV0.30 0.21 0.34 0.22\n",
      "ZZZ0.46 0.30 0.55 0.34\n",
      "Task Level Exposure\n",
      "Human GPT-4\n",
      "mean std mean std\n",
      "UUU0.15 0.36 0.14 0.35\n",
      "VVV0.31 0.37 0.35 0.35\n",
      "ZZZ0.47 0.50 0.56 0.50\n",
      "Table 3: Summary statistics of our human and model exposure data. Tasks designated as core tasks for an\n",
      "occupation are given twice the weight as those indicated to be supplemental in the O*NET task ﬁle.\n",
      "Figure 3: Exposure intensity across the economy, displayed in terms of percent of a ﬀected occupations. A\n",
      "given data point gives the percent of occupations with exposure below the given threshold. A previous version\n",
      "of this paper had two labels reversed in the chart, ﬂipping human and model responses. In this ﬁgure, all tasks\n",
      "within an occupation are given equal weight.\n",
      "Aggregated at the occupation level, human and GPT-4 annotations exhibit qualitative similarities and\n",
      "tend to correlate, as demonstrated in Figure 4. Human annotations estimate marginally lower exposure for\n",
      "high-wage occupations compared to GPT-4 annotations. While there are numerous low-wage occupations\n",
      "with high exposure and high-wage occupations with low exposure, the overall trend in the binscatter plot\n",
      "reveals that higher wages are associated with increased exposure to LLMs. 7\n",
      "The potential exposure to LLMs seems to have little correlation with current employment levels. In\n",
      "Figure 4, both human and GPT-4 ratings of overall exposure are aggregated to the occupation-level (y-axis)\n",
      "and compared with the log of total employment (x-axis). Neither plot reveals signiﬁcant di ﬀerences in LLM\n",
      "exposure across varying employment levels.\n",
      "7In aggregating tasks to the occupation-level, we assign half the weight to O*NET supplemental tasks as we do for core tasks.WORKING PAPER\n",
      "Figure 4: The binscatter plots depict the exposure to language models (LLMs) in various occupations, as\n",
      "assessed by both human evaluators and GPT-4. These plots compare the exposure to LLM and partial\n",
      "LLM-powered software ( V) at the occupation level against the log of total employment within an occupation\n",
      "and log of the median annual wage for occupations. While some discrepancies exist, both human and GPT-4\n",
      "assessments indicate that higher wage occupations tend to be more exposed to LLMs. Additionally, numerous\n",
      "lower wage occupations demonstrate high exposure based on our rubric. Core tasks receive twice the weight of\n",
      "supplemental tasks within occupations when calculating average exposure scores. Employment and wage data\n",
      "are sourced from the BLS-OES survey conducted in May 2021. In aggregating tasks to the occupation-level,\n",
      "we assign half the weight to O*NET supplemental tasks as we do for core tasks. All weights within an\n",
      "occupation sum to one.WORKING PAPER\n",
      "4.3 Skill Importance\n",
      "In this section\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      " our rubric. Core tasks receive twice the weight of\n",
      "supplemental tasks within occupations when calculating average exposure scores. Employment and wage data\n",
      "are sourced from the BLS-OES survey conducted in May 2021. In aggregating tasks to the occupation-level,\n",
      "we assign half the weight to O*NET supplemental tasks as we do for core tasks. All weights within an\n",
      "occupation sum to one.WORKING PAPER\n",
      "4.3 Skill Importance\n",
      "In this section, we explore the relationship between the importance of a skill for an occupation (as annotated\n",
      "in the O*NET dataset) and our exposure measures. First, we use the Basic Skills provided by O*NET (skill\n",
      "deﬁnitions can be found in Appendix B) and normalize the measure of skill importance for each occupation\n",
      "to improve the comprehensibility of the results. Next, we conduct a regression analysis on our exposure\n",
      "measures ( U,V,Z) to examine the strength of associations between skill importance and exposure.\n",
      "Our ﬁndings indicate that the importance of science andcritical thinking skills are strongly negatively\n",
      "associated with exposure, suggesting that occupations requiring these skills are less likely to be impacted\n",
      "by current LLMs. Conversely, programming andwriting skills show a strong positive association with\n",
      "exposure, implying that occupations involving these skills are more susceptible to being inﬂuenced by LLMs\n",
      "(see Table 5 for detailed results).\n",
      "4.4 Barriers to Entry\n",
      "Next, we examine barriers to entry to better understand if there is di ﬀerentiation in exposure due to types of\n",
      "jobs. One such proxy is an O*NET occupation-level descriptor called the \"Job Zone.\" A Job Zone groups\n",
      "occupations that are similar in (a) the level of education needed to get a job in the occupation, (b) the amount\n",
      "of related experience required to do the work, and (c) the extent of on-the-job training needed to do the work.\n",
      "In the O*NET database, there are 5 Job Zones, with Job Zone 1 requiring the least amount of preparation (3\n",
      "months) and Job Zone 5 requiring the most extensive amount of preparation, 4 or more years. We observe that\n",
      "median income increases monotonically across Job Zones as the level of preparation needed also increases,\n",
      "with the median worker in Job Zone 1 earning $30,230and the median worker in Job Zone 5 earning $80,980.\n",
      "All of our measures ( U,V, and Z) show an identical pattern, that is, exposure increases from Job Zone 1 to\n",
      "Job Zone 4, and either remains similar or decreases at Job Zone 5. Similar to Figure 3, in Figure 5, we plot\n",
      "the percentage of workers at every threshold of exposure. We ﬁnd that, on average, the percentage of workers\n",
      "in occupations with greater than 50% Vexposure in Job Zones 1 through 5 have Vat 0.00% (Job Zone 1),\n",
      "6.11% (Job Zone 2), 10.57% (Job Zone 3), 34.5% (Job Zone 4), and 26.45% (Job Zone 5), respectively. 8\n",
      "4.4.1 Typical Education Needed for Entry\n",
      "Since inclusion in a Job Zone accounts for both the education required—which itself is a proxy for skill\n",
      "acquisition—and the preparation required, we seek data to disentangle these variables. We use two variables\n",
      "from the Bureau of Labor Statistics’ Occupational data: \"Typical Education Needed for Entry\" and \"On-the-job\n",
      "Training Required to Attain Competency\" in an occupation. By examining these factors, we aim to uncover\n",
      "trends with potential implications for the workforce. There are 3,504,000 workers for whom we lack data on\n",
      "education and on-the-job training requirements, and they are therefore excluded from the summary tables.\n",
      "Our analysis suggests that individuals holding Bachelor’s, Master’s, and professional degrees are more\n",
      "exposed to LLMs and LLM-powered software than those without formal educational credentials (see Table 7).\n",
      "Interestingly, we also ﬁnd that individuals with some college education but no degree exhibit a high level of\n",
      "exposure to LLMs and LLM-powered software. Upon examining the table displaying barriers to entry, we\n",
      "observe that the jobs with the least exposure require the most training, potentially o ﬀering a lower payo ﬀ(in\n",
      "terms of median income) once competency is achieved. Conversely, jobs with no on-the-job training required\n",
      "or only internship/residency required appear to yield higher income but are more exposed to LLMs.\n",
      "8For this set of results, all tasks have equal weight within an occupation. Results do not change meaningfully with the\n",
      "core/supplemental weighting scheme.WORKING PAP\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      ", potentially o ﬀering a lower payo ﬀ(in\n",
      "terms of median income) once competency is achieved. Conversely, jobs with no on-the-job training required\n",
      "or only internship/residency required appear to yield higher income but are more exposed to LLMs.\n",
      "8For this set of results, all tasks have equal weight within an occupation. Results do not change meaningfully with the\n",
      "core/supplemental weighting scheme.WORKING PAPER\n",
      "Figure 5: Vexposure ratings of occupations in the ﬁve Job Zones, which are groups of similar occupations\n",
      "that are classiﬁed according to the level of education, experience, and on-the-job training needed to perform\n",
      "them. All tasks are weighted equally.WORKING PAPER\n",
      "Group Occupations with highest exposure % Exposure\n",
      "Human UUU Interpreters and Translators 76.5\n",
      "Survey Researchers 75.0\n",
      "Poets, Lyricists and Creative Writers 68.8\n",
      "Animal Scientists 66.7\n",
      "Public Relations Specialists 66.7\n",
      "Human VVV Survey Researchers 84.4\n",
      "Writers and Authors 82.5\n",
      "Interpreters and Translators 82.4\n",
      "Public Relations Specialists 80.6\n",
      "Animal Scientists 77.8\n",
      "Human ZZZ Mathematicians 100.0\n",
      "Tax Preparers 100.0\n",
      "Financial Quantitative Analysts 100.0\n",
      "Writers and Authors 100.0\n",
      "Web and Digital Interface Designers 100.0\n",
      "Humans labeled 15 occupations as \"fully exposed.\"\n",
      "Model UUU Mathematicians 100.0\n",
      "Correspondence Clerks 95.2\n",
      "Blockchain Engineers 94.1\n",
      "Court Reporters and Simultaneous Captioners 92.9\n",
      "Proofreaders and Copy Markers 90.9\n",
      "Model VVV Mathematicians 100.0\n",
      "Blockchain Engineers 97.1\n",
      "Court Reporters and Simultaneous Captioners 96.4\n",
      "Proofreaders and Copy Markers 95.5\n",
      "Correspondence Clerks 95.2\n",
      "Model ZZZ Accountants and Auditors 100.0\n",
      "News Analysts, Reporters, and Journalists 100.0\n",
      "Legal Secretaries and Administrative Assistants 100.0\n",
      "Clinical Data Managers 100.0\n",
      "Climate Change Policy Analysts 100.0\n",
      "The model labeled 86 occupations as \"fully exposed.\"\n",
      "Highest variance Search Marketing Strategists 14.5\n",
      "Graphic Designers 13.4\n",
      "Investment Fund Managers 13.0\n",
      "Financial Managers 13.0\n",
      "Insurance Appraisers, Auto Damage 12.6\n",
      "Table 4: Occupations with the highest exposure according to each measurement. The ﬁnal row lists the\n",
      "occupations with the highest f2value, indicating that they had the most variability in exposure scores.\n",
      "Exposure percentages indicate the share of an occupation’s task that are exposed to GPTs ( UUU) or GPT-powered\n",
      "software ( VVVandZZZ), where exposure is deﬁned as driving a reduction in time it takes to complete the task by at\n",
      "least 50% (see exposure rubric A.1). As such, occupations listed in this table are those where we estimate\n",
      "that GPTs and GPT-powered software are able to save workers a signiﬁcant amount of time completing a\n",
      "large share of their tasks, but it does not necessarily suggest that their tasks can be fully automated by these\n",
      "technologies. All tasks are assigned equal weight within an occupation.WORKING PAPER\n",
      "Basic Skill UUU\n",
      "(std err)VVV\n",
      "(std err)ZZZ\n",
      "(std err)\n",
      "All skill importance scores are normalized to be between 0 and 1.\n",
      "Constant 0.082*** -0.112*** 0.300***\n",
      "(0.011) (0.011) (0.057)\n",
      "Active Listening 0.128** 0.214*** 0.449***\n",
      "(0.047) (0.043) (0.027)\n",
      "Mathematics -0.127*** 0.161*** 0.787***\n",
      "(0.026) (0.021) (0.049)\n",
      "Reading Comprehension 0.153*** 0.470*** -0.346***\n",
      "(0.041) (0.037) (0.017)\n",
      "Science -0.114*** -0.230*** -0.346***\n",
      "(0.014) (0.012) (0.017)\n",
      "Speaking -0.028 0.133*** 0.294***\n",
      "(0.039) (0.033) (0.042)\n",
      "Writing 0.368*** 0.467*** 0.566***\n",
      "(0.042) (0.037) (0.047)\n",
      "Active Learning -0.157*** -0.0\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "230*** -0.346***\n",
      "(0.014) (0.012) (0.017)\n",
      "Speaking -0.028 0.133*** 0.294***\n",
      "(0.039) (0.033) (0.042)\n",
      "Writing 0.368*** 0.467*** 0.566***\n",
      "(0.042) (0.037) (0.047)\n",
      "Active Learning -0.157*** -0.065** 0.028\n",
      "(0.027) (0.024) (0.032)\n",
      "Critical Thinking -0.264*** -0.196*** -0.129**\n",
      "(0.036) (0.033) (0.042)\n",
      "Learning Strategies -0.072* -0.209*** -0.346***\n",
      "(0.028) (0.025) (0.034)\n",
      "Monitoring -0.067** -0.149*** -0.232***\n",
      "(0.023) 0.020) (0.026)\n",
      "Programming 0.637*** 0.623*** 0.609***\n",
      "(0.030) (0.022) (0.024)\n",
      "Table 5: Regression of occupation-level, human-annotated exposure to GPTs on skill importance for each\n",
      "skill in the O*NET Basic skills category, plus the programming skill. Descriptions of the skills may be found\n",
      "in Appendix B. Task ratings within each occupation for exposure have equal weight.\n",
      "Job\n",
      "ZonePreparation\n",
      "RequiredEducation\n",
      "RequiredExample Occupations Median\n",
      "IncomeTot Emp\n",
      "(000s )H\n",
      "UUUM\n",
      "UUUH\n",
      "VVVM\n",
      "VVVH\n",
      "ZZZM\n",
      "ZZZ\n",
      "1 None or little\n",
      "(0-3 months)High school\n",
      "diploma or GED\n",
      "(otional)Food preparation workers,\n",
      "dishwashers, ﬂoor sanders$30,230 13,100 0.03 0.04 0.06 0.06 0.09 0.08\n",
      "2 Some (3-12\n",
      "months)High school\n",
      "diplomaOrderlies, customer\n",
      "service representatives,\n",
      "tellers$38,215 73,962 0.07 0.12 0.16 0.20 0.24 0.27\n",
      "3 Medium (1-2\n",
      "years)Vocational school,\n",
      "on-the-job training,\n",
      "or associate’s\n",
      "degreeElectricians, barbers,\n",
      "medical assistants$54,815 37,881 0.11 0.14 0.26 0.32 0.41 0.51\n",
      "4 Considerable\n",
      "(2-4 years)Bachelor’s degree Database administrators,\n",
      "graphic designers, cost\n",
      "estimators$77,345 56,833 0.23 0.18 0.47 0.51 0.71 0.85\n",
      "5 Extensive (4+\n",
      "years)Master’s degree or\n",
      "higherPharmacists, lawyers,\n",
      "astronomers$81,980 21,221 0.23 0.13 0.43 0.45 0.63 0.76\n",
      "Table 6: Mean exposure to GPTs by job zone. For each job zone, we also present the median of median\n",
      "annual income for each constituting occupation in USD, and the total number of workers in all occupations\n",
      "for that job zone, in the thousands. Task weights are equal for all tasks.WORKING PAPER\n",
      "On The Job Training Required Median Income Tot Emp (000s) HUUU MUUU HVVVMVVV HZZZMZZZ\n",
      "None $77,440 90,776 0.20 0.16 0.42 0.46 0.63 0.76\n",
      "Apprenticeship $55,995 3,066 0.01 0.02 0.04 0.06 0.07 0.10\n",
      "Internship/residency $77,110 3,063 0.16 0.06 0.36 0.38 0.55 0.71\n",
      "Short-term on-the-job training $33,370 66,234 0.11 0.15 0.21 0.25 0.32 0.34\n",
      "Moderate-term on-the-job training $46,880 31,285 0.09 0.12 0.21 0.25 0.32 0.38\n",
      "Long-term on-the-job training $48,925 5,070 0.08 0.10 0.18 0.22 0.28 0.33\n",
      "Table 7: Mean exposure scores for occupations, grouped by level of on-the-job training required to attain\n",
      "competency in the job. Alongside exposure scores, we display the median of median annual income for each\n",
      "occupation, as well as the total number of workers in each group,\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      " 0.38\n",
      "Long-term on-the-job training $48,925 5,070 0.08 0.10 0.18 0.22 0.28 0.33\n",
      "Table 7: Mean exposure scores for occupations, grouped by level of on-the-job training required to attain\n",
      "competency in the job. Alongside exposure scores, we display the median of median annual income for each\n",
      "occupation, as well as the total number of workers in each group, in thousands. Task weights are equal within\n",
      "an occupation and sum to one.WORKING PAPER\n",
      "5 Validation of Measures\n",
      "5.1 Comparison to Earlier E ﬀorts\n",
      "This paper aims to build on a number of previous empirical studies examining the occupational exposure to\n",
      "advances in AI and/or automation. Previous studies have used a variety of methods, including:\n",
      "•Using occupational taxonomies like O*NET to characterize which occupations have routine vs.\n",
      "non-routine and manual vs. cognitive task content (Autor et al., 2003; Acemoglu and Autor, 2011a).\n",
      "•Mapping text descriptions of tasks to descriptions of technological advances in patents. (Kogan et al.,\n",
      "2021; Webb, 2020)\n",
      "•Linking capabilities of AI systems to occupational abilities and aggregating exposure estimates to the\n",
      "occupations where those abilities are required. (Felten et al., 2018, 2023)\n",
      "•Mapping the results of AI task benchmark evaluations (ImageNet, Robocup, etc.) to 59 worker tasks\n",
      "through a set of 14 cognitive abilities drawn from the cognitive science literature. (Tolan et al., 2021)\n",
      "•Expert labeling of automation potential for a set of O*NET occupations where experts had high\n",
      "conﬁdence, combined with a probabilistic classiﬁer to estimate automation potential for the remainder\n",
      "of O*NET occupations. (Frey and Osborne, 2017)\n",
      "•Developing a rubric for evaluating the \"suitability for machine learning\" (SML) of activities that\n",
      "workers are completing in the economy (Brynjolfsson and Mitchell, 2017; Brynjolfsson et al., 2018,\n",
      "2023).\n",
      "We provide a set of summary statistics on many of these prior e ﬀorts in Table 8.\n",
      "This paper’s methodology primarily builds upon the SML approach by developing a rubric to evaluate the\n",
      "overlap between LLM capabilities and worker tasks as reported in the O*NET database. Table 9 presents the\n",
      "results of OLS regressions of our new LLM exposure measurements on occupation-level exposure measures\n",
      "from (Felten et al., 2018) (\"AI Occupational Exposure Score\" in the table), (Frey and Osborne, 2017) (Frey\n",
      "& Osborne Automation), scores from all three technologies in (Webb, 2020), normalized routine manual\n",
      "and cognitive scores from (Acemoglu and Autor, 2011a), and (Brynjolfsson et al., 2018, 2023) (SML). We\n",
      "also use annualized occupational salaries from the most recent BLS Occupational Employment Survey as a\n",
      "control. There are four separate output variables representing new scores in this paper that are predicted by\n",
      "earlier e ﬀorts.\n",
      "GPT-4 Exposure Rating 1 corresponds to our overall exposure rubric as evaluated by GPT-4, where full\n",
      "exposure potential is coded as 1, no exposure potential is coded as 0, and partial exposure (E2 in our labeling\n",
      "scheme) is coded as 0.5. GPT-4 Exposure Rating 2 is scored similarly for overall exposure, but with a slightly\n",
      "diﬀerent prompt. The results are very similar across the two prompts. Human Exposure Rating represents the\n",
      "same rubric as in GPT-4 Exposure Rating 1 but is scored by humans, as discussed in an earlier section of the\n",
      "paper. These results correspond to the Vset of statistics presented above, with supplemental tasks having half\n",
      "the weight of core tasks within an occupation. These weights sum to one (core/supplemental distinctions are\n",
      "determined by O*NET).\n",
      "The results across each type of measurement are consistent. We ﬁnd generally positive and statistically\n",
      "signiﬁcant correlations between our LLM exposure measures and previous measurements targeting software\n",
      "and AI. Encouragingly, the SML exposure scores by occupation show signiﬁcant and positive associations\n",
      "with the exposure scores we develop in this paper, demonstrating a level of cohesion between the two studies\n",
      "with similar approaches. The Webb software and AI patent-based measures, SML, and normalized (demeanedWORKING PAPER\n",
      "Min 25th Perc. Median 75th Perc Max Mean Std. Dev. Count\n",
      "GPT-4 Exposure Rating 1 0.00 0.13 0.34 0.50 1.\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "iﬁcant and positive associations\n",
      "with the exposure scores we develop in this paper, demonstrating a level of cohesion between the two studies\n",
      "with similar approaches. The Webb software and AI patent-based measures, SML, and normalized (demeanedWORKING PAPER\n",
      "Min 25th Perc. Median 75th Perc Max Mean Std. Dev. Count\n",
      "GPT-4 Exposure Rating 1 0.00 0.13 0.34 0.50 1.00 0.33 0.22 750\n",
      "GPT-4 Exposure Rating 2 0.00 0.09 0.24 0.40 0.98 0.26 0.20 750\n",
      "Human Exposure Rating 0.00 0.09 0.29 0.47 0.84 0.29 0.21 750\n",
      "Software (Webb) 1.00 25.00 50.00 75.00 100.00 50.69 30.05 750\n",
      "Robot (Webb) 1.00 22.00 52.00 69.00 100.00 48.61 28.61 750\n",
      "AI (Webb) 1.00 28.00 55.00 82.00 100.00 54.53 29.65 750\n",
      "Suitability for Machine Learning 2.60 2.84 2.95 3.12 3.55 2.99 0.18 750\n",
      "Normalized Routine Cognitive -3.05 -0.46 0.10 0.63 3.42 0.07 0.86 750\n",
      "Normalized Routine Manual -1.81 -0.81 -0.11 0.73 2.96 0.05 1.01 750\n",
      "AI Occupational Exposure Score 1.42 3.09 3.56 4.04 6.54 3.56 0.70 750\n",
      "Frey & Osborne Automation 0.00 0.07 0.59 0.88 0.99 0.50 0.38 681\n",
      "Log Avg. Salary 10.13 10.67 11.00 11.34 12.65 11.02 0.45 749\n",
      "Table 8: Summary statistics for a suite of prior e ﬀorts to measure occupational exposure to AI and automation.\n",
      "We have also included summary statistics for measurements newly presented in this work. We include all\n",
      "measures from (Webb, 2020), normalized routine cognitive and manual scores from (Acemoglu and Autor,\n",
      "2011a) (means may deviate slightly from 0 due to imperfect matching of occupational groups), Suitability for\n",
      "Machine Learning from (Brynjolfsson and Mitchell, 2017; Brynjolfsson et al., 2018, 2023), AI Occupational\n",
      "Exposure from (Felten et al., 2018), and Automation exposure from (Frey and Osborne, 2017). We include as\n",
      "many occupations as we can match, but since O*NET taxonomies have changed as these measures have been\n",
      "developed, some of the roles may be missing from the most recent version of O*NET 6-digit occupations.\n",
      "and divided by standard deviation) routine cognitive scores all exhibit positive associations with some of our\n",
      "measures.\n",
      "Software, SML, and routine cognitive scores all show positive and statistically signiﬁcant associations\n",
      "with LLM exposure scores at a 1% level. Coe ﬃcients on AI scores from (Webb, 2020) are also positive and\n",
      "statistically signiﬁcant at a 5% level, but our secondary prompt on overall exposure to LLMs in columns 3\n",
      "and 4 does not exhibit a statistically signiﬁcant relationship. For the most part, the AI Occupational Exposure\n",
      "Score is not correlated with our exposure measures. Webb’s Robot exposure scores, routine manual task\n",
      "content, and the overall Automation metric from (Frey and Osborne, 2017) are all negatively correlated with\n",
      "our primary GPT-4 and human-assessed overall exposure ratings, conditional on the other measurements.\n",
      "This negative correlation reﬂects the limited exposure of physical tasks to LLMs. Manual work is not exposed\n",
      "to LLMs or even LLMs with additional systems integration for the time being.\n",
      "Low correlations with (Felten et al., 2018) and (Frey and Osborne, 2017) could potentially be explained\n",
      "by diﬀerences in approaches. Linking AI capabilities to worker abilities or scoring exposure directly based on\n",
      "the occupation’s characteristics, rather than aggregating up to the occupation from DWA or task-level scoring\n",
      "(as in the SML paper and our own), o ﬀer a slightly di ﬀerent perspective on the content of occupations.\n",
      "In all regressions, the '2ranges between 60.7% (column 3) and 72.8% (column 5). This suggests that\n",
      "our measure, which explicitly focuses on LLM capabilities, has between 28 and 40% unexplained variance\n",
      "compared to other measurements\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      " to the occupation from DWA or task-level scoring\n",
      "(as in the SML paper and our own), o ﬀer a slightly di ﬀerent perspective on the content of occupations.\n",
      "In all regressions, the '2ranges between 60.7% (column 3) and 72.8% (column 5). This suggests that\n",
      "our measure, which explicitly focuses on LLM capabilities, has between 28 and 40% unexplained variance\n",
      "compared to other measurements. Particularly in the case of AI-related exposure scores, we anticipate that a\n",
      "combination of other measurements would have a strong correlation with our scores. However, earlier e ﬀorts\n",
      "had limited information about the future progress of LLMs or LLM-powered software. We expect that our\n",
      "understanding of future machine learning technologies is similarly imperfectly captured by our rubric today.WORKING PAPER\n",
      "GPT-4 Exposure Rating 1 GPT-4 Exposure Rating 2 Human Exposure Rating\n",
      "(1) (2) (3) (4) (5) (6)\n",
      "Software (Webb) 0.00113⇤⇤⇤0.00123⇤⇤⇤0.00111⇤⇤⇤0.00119⇤⇤⇤0.00096⇤⇤⇤0.00101⇤⇤⇤\n",
      "(0.00031 )( 0.00031 )( 0.00031 )( 0.00031 )( 0.00031 )( 0.00031 )\n",
      "Robot (Webb) \u00000.00378⇤⇤⇤\u00000.00405⇤⇤⇤\u00000.00377⇤⇤⇤\u00000.00399⇤⇤⇤\u00000.00371⇤⇤⇤\u00000.00383⇤⇤⇤\n",
      "(0.00032 )( 0.00031 )( 0.00034 )( 0.00033 )( 0.00029 )( 0.00028 )\n",
      "AI (Webb) 0.00080⇤⇤⇤0.00090⇤⇤⇤0.00036 0 .00045 0 .00067⇤⇤0.00071⇤⇤\n",
      "(0.00030 )( 0.00029 )( 0.00030 )( 0.00030 )( 0.00030 )( 0.00030 )\n",
      "Suitability for Machine Learning 0.29522⇤⇤⇤0.26888⇤⇤⇤0.28468⇤⇤⇤0.26245⇤⇤⇤0.19514⇤⇤⇤0.18373⇤⇤⇤\n",
      "(0.04503 )( 0.04418 )( 0.04404 )( 0.04342 )( 0.03990 )( 0.03886 )\n",
      "Normalized Routine Cognitive 0.06601⇤⇤⇤0.06868⇤⇤⇤0.04743⇤⇤⇤0.05015⇤⇤⇤0.03568⇤⇤⇤0.03659⇤⇤⇤\n",
      "(0.00886 )( 0.00894 )( 0.00872 )( 0.00879 )( 0.00671 )( 0.00669 )\n",
      "Normalized Routine Manual \u00000.11147⇤⇤⇤\u00000.11371⇤⇤⇤\u00000.09390⇤⇤⇤\u00000.09561⇤⇤⇤\u00000.11045⇤⇤⇤\u00000.11152⇤⇤⇤\n",
      "(0.00785 )( 0.00789 )( 0.00817 )( 0.00818 )( 0.00741 )( 0.00744 )\n",
      "AI Occupational Exposure Score 0.00993 0 .02465⇤⇤\u00000.01537 \u00000.00265 0 .00630 0 .01252\n",
      "(0.01107 )( 0.01059 )( 0.01160 )( 0.01114 )( 0.00918 )( 0.00845 )\n",
      "Frey &\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "17 )( 0.00818 )( 0.00741 )( 0.00744 )\n",
      "AI Occupational Exposure Score 0.00993 0 .02465⇤⇤\u00000.01537 \u00000.00265 0 .00630 0 .01252\n",
      "(0.01107 )( 0.01059 )( 0.01160 )( 0.01114 )( 0.00918 )( 0.00845 )\n",
      "Frey & Osborne Automation \u00000.03024⇤\u00000.03950⇤⇤\u00000.00364 \u00000.01217 \u00000.03890⇤⇤\u00000.04253⇤⇤\n",
      "(0.01835 )( 0.01841 )( 0.02007 )( 0.01972 )( 0.01883 )( 0.01858 )\n",
      "Log Avg. Salary 0.05804⇤⇤⇤0.04863⇤⇤⇤0.02531\n",
      "(0.01870 )( 0.01860 )( 0.01727 )\n",
      "Constant \u00001.12937⇤⇤⇤\u00000.45743⇤⇤⇤\u00000.96117⇤⇤⇤\u00000.39935⇤⇤⇤\u00000.47078⇤\u00000.17706\n",
      "(0.26859 )( 0.15327 )( 0.26365 )( 0.15017 )( 0.24684 )( 0.13256 )\n",
      "N 680.00000 681 .00000 680 .00000 681 .00000 680 .00000 681 .00000\n",
      "'20.68741 0 .68212 0 .60737 0 .60198 0 .71213 0 .71126\n",
      "Table 9: Regression of LLM-exposure scores on prior measures of occupational exposure to AI and automation.\n",
      "We also include annualized wages from the BLS-OES survey in May 2021. Each measure is kept in its\n",
      "original scale, with the exception of routine cognitive and routine manual scores from (Acemoglu and Autor,\n",
      "2011a). Those two scores are standardized to mean zero and variance 1. Generally we ﬁnd strong positive\n",
      "associations with previous e ﬀorts, though large residual variance to still be explained by our new measures.\n",
      "Columns 1 and 2 are based on our main Vexposure measure from GPT-4 ratings. Columns 3 and 4 are\n",
      "based on a similar slightly di ﬀerent exposure rubric also rated by GPT-4 for robustness. Columns 5 and 6\n",
      "reﬂect human ratings on the same rubric as columns 1 and 2. Occupation-level scores are built using the\n",
      "core/supplemental task weights, assigning supplemental tasks as having half the weight of core tasks.WORKING PAPER\n",
      "6 Discussion\n",
      "6.1 GPTs as a General-Purpose Technology\n",
      "Earlier in this paper we discuss the possibility that LLMs could be classiﬁed as a general-purpose technology.\n",
      "This classiﬁcation requires LLMs to meet three core criteria: improvement over time, pervasiveness throughout\n",
      "the economy, and the ability to spawn complementary innovations (Lipsey et al., 2005). Evidence from the AI\n",
      "and machine learning literature thoroughly demonstrates that LLMs meet the ﬁrst criteria – they are improving\n",
      "in capabilities over time with the ability to complete or be helpful for an increasingly complex set of tasks and\n",
      "use-cases (see 2.1). This paper presents evidence to support the latter two criteria, ﬁnding that LLMs on their\n",
      "own can have pervasive impacts across the economy, and that complementary innovations enabled by LLMs –\n",
      "particularly via software and digital tools – can have widespread application to economic activity.\n",
      "Figure 3 o ﬀers one illustration of the potential economic impact of complementary software built on top of\n",
      "LLMs. Taking the di ﬀerence in the y-axis (the share of all occupations) between UandZat a given point along\n",
      "the x-axis (the share of tasks within an occupation that are exposed) gives the aggregate within-occupation\n",
      "exposure potential attributable to tools and software over and above direct exposure from LLMs on their\n",
      "own. The di ﬀerence in means across all tasks between UandZof 0.42 using the GPT-4 annotations and 0.32\n",
      "using the human annotations (see Figure 3), suggests that the average impact of LLM-powered software on\n",
      "task-exposure may be more than twice as large as the mean exposure from LLMs on their own (mean Zof 0\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      "exposure potential attributable to tools and software over and above direct exposure from LLMs on their\n",
      "own. The di ﬀerence in means across all tasks between UandZof 0.42 using the GPT-4 annotations and 0.32\n",
      "using the human annotations (see Figure 3), suggests that the average impact of LLM-powered software on\n",
      "task-exposure may be more than twice as large as the mean exposure from LLMs on their own (mean Zof 0.14\n",
      "based on both human annotations and GPT-4 annotations). While our ﬁndings suggest that out-of-the-box\n",
      "these models are relevant to a meaningful share of workers and tasks, they also suggest that the software\n",
      "innovations they spawn could drive a much broader impact.\n",
      "One component of the pervasiveness of a technology is its level of adoption by businesses and users.\n",
      "This paper does not systematically analyze adoption of these models, however, there is early qualitative\n",
      "evidence that adoption and use of LLMs is becoming increasingly widespread. The power of relatively\n",
      "simple UI improvements on top of LLMs was evident in the rollout of ChatGPT – wherein versions of the\n",
      "underlying language model had been previously available via API, but usage skyrocketed after the release of\n",
      "the ChatGPT interface. (Chow, 2023; OpenAI, 2022) Following this release, a number of commercial surveys\n",
      "indicate that ﬁrm and worker adoption of LLMs has increased over the past several months. (Constantz, 2023;\n",
      "ResumeBuilder.com, 2023)\n",
      "Widespread adoption of these models requires addressing existing bottlenecks. A key determinant of\n",
      "their utility is the level of conﬁdence humans place in them and how humans adapt their habits. For instance,\n",
      "in the legal profession, the models’ usefulness depends on whether legal professionals can trust model\n",
      "outputs without verifying original documents or conducting independent research. The cost and ﬂexibility\n",
      "of the technology, worker and ﬁrm preferences, and incentives also signiﬁcantly inﬂuence the adoption of\n",
      "tools built on top of LLMs. In this way, adoption may be driven by progress on some of the ethical and\n",
      "safety risks associated with LLMs: bias, fabrication of facts, and misalignment, to name a few OpenAI\n",
      "(2023a). Moreover, the adoption of LLMs will vary across di ﬀerent economic sectors due to factors such\n",
      "as data availability, regulatory environment, and the distribution of power and interests. Consequently, a\n",
      "comprehensive understanding of the adoption and use of LLMs by workers and ﬁrms requires a more in-depth\n",
      "exploration of these intricacies.\n",
      "One possibility is that time savings and seamless application will hold greater importance than quality\n",
      "improvement for the majority of tasks. Another is that the initial focus will be on augmentation, followed byimprovement for the majority of tasks. Another is that the initial focus will be on augmentation, followed by\n",
      "automation (Huang and Rust, 2018). One way this might take shape is through an augmentation phase where\n",
      "jobs ﬁrst become more precarious (e.g., writers becoming freelancers) before transitioning to full automation.WORKING PAPER\n",
      "6.2 Implications for US Public Policy\n",
      "The introduction of automation technologies, including LLMs, has previously been linked to heightened\n",
      "economic disparity and labor disruption, which may give rise to adverse downstream e ﬀects (Acemoglu and\n",
      "Restrepo, 2022a; Acemoglu, 2002; Moll et al., 2021; Klinova and Korinek, 2021; Weidinger et al., 2021,\n",
      "2022). Our results examining worker exposure in the United States underscore the need for societal and policy\n",
      "preparedness to the potential economic disruption posed by LLMs and the complementary technologies\n",
      "that they spawn. While it is outside the scope of this paper to recommend speciﬁc policy prescriptions to\n",
      "smooth the transition to an economy with increasingly widespread LLM adoption, prior work such as (Autor\n",
      "et al., 2022b) has articulated several important directions for US policy related to education, worker training,\n",
      "reforms to safety net programs, and more.\n",
      "6.3 Limitations and Future Work\n",
      "In addition to those discussed above, we highlight some particular limitations of this work that warrant further\n",
      "investigation. Primarily, our focus on the United States restricts the generalizability of our ﬁndings to other\n",
      "nations where the adoption and impact of generative models may di ﬀer due to factors such as industrial\n",
      "organization, technological infrastructure, regulatory frameworks, linguistic diversity, and cultural contexts.\n",
      "We hope to address this limitation by extending the study’s scope and by sharing our methods\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      ", we highlight some particular limitations of this work that warrant further\n",
      "investigation. Primarily, our focus on the United States restricts the generalizability of our ﬁndings to other\n",
      "nations where the adoption and impact of generative models may di ﬀer due to factors such as industrial\n",
      "organization, technological infrastructure, regulatory frameworks, linguistic diversity, and cultural contexts.\n",
      "We hope to address this limitation by extending the study’s scope and by sharing our methods so other\n",
      "researchers can build on them.\n",
      "Subsequent research e ﬀorts should consider two additional studies: one exploring LLM adoption patterns\n",
      "across various sectors and occupations, and another scrutinizing the actual capabilities and limitations of\n",
      "state-of-the-art models in relation to worker activities beyond the scope of our exposure scores. For example,\n",
      "despite recent advances in multimodal capabilities with GPT-4, we did not consider vision capabilities in\n",
      "theUratings on direct LLMs-exposure (OpenAI, 2023b). Future work should consider the impact of such\n",
      "capability advances as they unfold. Furthermore, we acknowledge that there may be discrepancies between\n",
      "theoretical and practical performance, particularly in complex, open-ended, and domain-speciﬁc tasks.\n",
      "7 Conclusion\n",
      "In conclusion, this study o ﬀers an examination of the potential impact of LLMs on various occupations and\n",
      "industries within the U.S. economy. By applying a new rubric for understanding LLM capabilities and their\n",
      "potential e ﬀects on jobs, we have observed that most occupations exhibit some degree of exposure to LLMs,\n",
      "with higher-wage occupations generally presenting more tasks with high exposure. Our analysis indicates that\n",
      "approximately 19% of jobs have at least 50% of their tasks exposed to LLMs when considering both current\n",
      "model capabilities and anticipated LLM-powered software.\n",
      "Our research aims to highlight the general-purpose potential of LLMs and their possible implications for\n",
      "US workers. Previous literature demonstrates the impressive improvements of LLMs to date (see 2.1). Our\n",
      "ﬁndings conﬁrm the hypothesis that these technologies can have pervasive impacts across a wide swath of\n",
      "occupations in the US, and that additional advancements supported by LLMs, mainly through software and\n",
      "digital tools, can have signiﬁcant e ﬀects on a range of economic activities. However, while the technical\n",
      "capacity for LLMs to make human labor more e ﬃcient appears evident, it is important to recognize that social,\n",
      "economic, regulatory, and other factors will inﬂuence actual labor productivity outcomes. As capabilities\n",
      "continue to evolve, the impact of LLMs on the economy will likely persist and increase, posing challenges for\n",
      "policymakers in predicting and regulating their trajectory.\n",
      "Further research is necessary to explore the broader implications of LLM advancements, including\n",
      "their potential to augment or displace human labor, their impact on job quality, impacts on inequality, skilltheir potential to augment or displace human labor, their impact on job quality, impacts on inequality, skill\n",
      "development, and numerous other outcomes. By seeking to understand the capabilities and potential e ﬀectsWORKING PAPER\n",
      "of LLMs on the workforce, policymakers and stakeholders can make more informed decisions to navigate the\n",
      "complex landscape of AI and its role in shaping the future of work.\n",
      "7.1 LLM Conclusion (GPT-4’s Version)\n",
      "Generative Pre-trained Transformers (GPTs) generate profound transformations, garnering potential technolog-\n",
      "ical growth, permeating tasks, greatly impacting professions. This study probes GPTs’ potential trajectories,\n",
      "presenting a groundbreaking rubric to gauge tasks’ GPT exposure, particularly in the U.S. labor market.\n",
      "7.2 LLM Conclusion (Author-Augmented Version)\n",
      "Generative Pre-trained Transformers (GPTs) generate profound transformations, garnering potential techno-\n",
      "logical growth, permeating tasks, gutting professional management. Gauging possible trajectories? Generate\n",
      "pioneering taxonomies, gather policymakers together, generalize past today.\n",
      "Acknowledgments\n",
      "Thank you to the group of annotators who helped us annotate task exposure, including Muhammad Ahmed\n",
      "Saeed, Bongane Zitha, Merve Özen Şenen, J.J., and Peter Hoeschele. We also thank Lauryn Fuld, Ashley Glat,\n",
      "Michael Lampe, and Julia Susser for excellent research assistance. We thank Miles Brundage for signiﬁcant\n",
      "feedback on this paper.\n",
      "We thank Todor Markov and Vik Goel for setting up the infrastructure we use to run our rubrics with\n",
      "GPT-4. We thank Lama Ahmad, Donald Bakong,\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
      "\n",
      "Question: [question here]\n",
      "Helpful Answer: [answer here]\n",
      "Score: [score between 0 and 100]\n",
      "\n",
      "How to determine the score:\n",
      "- Higher is a better answer\n",
      "- Better responds fully to the asked question, with sufficient level of detail\n",
      "- If you do not know the answer based on the context, that should be a score of 0\n",
      "- Don't be overconfident!\n",
      "\n",
      "Example #1\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Apples are red\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: red\n",
      "Score: 100\n",
      "\n",
      "Example #2\n",
      "\n",
      "Context:\n",
      "---------\n",
      "it was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\n",
      "---------\n",
      "Question: what type was the car?\n",
      "Helpful Answer: a sports car or an suv\n",
      "Score: 60\n",
      "\n",
      "Example #3\n",
      "\n",
      "Context:\n",
      "---------\n",
      "Pears are either red or orange\n",
      "---------\n",
      "Question: what color are apples?\n",
      "Helpful Answer: This document does not answer the question\n",
      "Score: 0\n",
      "\n",
      "Begin!\n",
      "\n",
      "Context:\n",
      "---------\n",
      ", J.J., and Peter Hoeschele. We also thank Lauryn Fuld, Ashley Glat,\n",
      "Michael Lampe, and Julia Susser for excellent research assistance. We thank Miles Brundage for signiﬁcant\n",
      "feedback on this paper.\n",
      "We thank Todor Markov and Vik Goel for setting up the infrastructure we use to run our rubrics with\n",
      "GPT-4. We thank Lama Ahmad, Donald Bakong, Seth Benzell, Erik Brynjolfsson, Parfait Eloundou-Enyegue,\n",
      "Carl Frey, Sarah Giroux, Gillian Hadﬁeld, Johannes Heidecke, Alan Hickey, Eric Horvitz, Shengli Hu,\n",
      "Ashyana Kachra, Christina Kim, Katya Klinova, Daniel Kokotajlo, Gretchen Krueger, Michael Lampe, Aalok\n",
      "Mehta, Larissa Schiavo, Daniel Selsam, Sarah Shoker, Prasanna Tambe, and Je ﬀWu for feedback and edits at\n",
      "various stages of the project.\n",
      "LLM assistance statement\n",
      "GPT-4 and ChatGPT were used for writing, coding, and formatting assistance in this project.\n",
      "A Rubric\n",
      "A.1 Exposure\n",
      "# E Exposure Taxonomy\n",
      "Consider the most powerful OpenAI large language model (LLM) This model can complete many tasks\n",
      "that can be formulated as having text input and text output where the context for the input can be captured in\n",
      "2000 words. The model also cannot draw up-to-date facts (those from <1 year ago) unless they are captured\n",
      "in the input.\n",
      "Assume you are a worker with an average level of expertise in your role trying to complete the given task.\n",
      "You have access to the LLM as well as any other existing software or computer hardware tools mentioned\n",
      "in the task. You also have access to any commonly available technical tools accessible via a laptop (e.g. a\n",
      "microphone, speakers, etc.). You do not have access to any other physical tools or materials.\n",
      "Please label the given task according to the taxonomy below.\n",
      "## E0 – No exposure\n",
      "---------\n",
      "Question: what are the skills that are not likely to be replaced by LLMs?\n",
      "Helpful Answer:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchain/chains/llm.py:349: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Roles heavily reliant on science and critical thinking skills show a negative correlation with exposure to LLMs, indicating that these skills are less likely to be replaced by LLMs. '"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = load_qa_chain(\n",
    "    llm, chain_type=\"map_rerank\", verbose=True, return_intermediate_steps=True\n",
    ")\n",
    "query = \"what are the skills that are not likely to be replaced by LLMs?\"\n",
    "\n",
    "result = chain(\n",
    "    {\"input_documents\": job_doc, \"question\": query}, return_only_outputs=True\n",
    ")\n",
    "result[\"output_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question-Answering: Document embedding with RetrievalQA and Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", potentially o ﬀering a lower payo ﬀ(in\n",
      "terms of median income) once competency is achieved. Conversely, jobs with no on-the-job training required\n",
      "or only internship/residency required appear to yield higher income but are more exposed to LLMs.\n",
      "8For this set of results, all tasks have equal weight within an occupation. Results do not change meaningfully with the\n",
      "core/supplemental weighting scheme.WORKING PAPER\n",
      "Figure 5: Vexposure ratings of occupations in the ﬁve Job Zones, which are groups of similar occupations\n",
      "that are classiﬁed according to the level of education, experience, and on-the-job training needed to perform\n",
      "them. All tasks are weighted equally.WORKING PAPER\n",
      "Group Occupations with highest exposure % Exposure\n",
      "Human UUU Interpreters and Translators 76.5\n",
      "Survey Researchers 75.0\n",
      "Poets, Lyricists and Creative Writers 68.8\n",
      "Animal Scientists 66.7\n",
      "Public Relations Specialists 66.7\n",
      "Human VVV Survey Researchers 84.4\n",
      "Writers and Authors 82.5\n",
      "Interpreters and Translators 82.4\n",
      "Public Relations Specialists 80.6\n",
      "Animal Scientists 77.8\n",
      "Human ZZZ Mathematicians 100.0\n",
      "Tax Preparers 100.0\n",
      "Financial Quantitative Analysts 100.0\n",
      "Writers and Authors 100.0\n",
      "Web and Digital Interface Designers 100.0\n",
      "Humans labeled 15 occupations as \"fully exposed.\"\n",
      "Model UUU Mathematicians 100.0\n",
      "Correspondence Clerks 95.2\n",
      "Blockchain Engineers 94.1\n",
      "Court Reporters and Simultaneous Captioners 92.9\n",
      "Proofreaders and Copy Markers 90.9\n",
      "Model VVV Mathematicians 100.0\n",
      "Blockchain Engineers 97.1\n",
      "Court Reporters and Simultaneous Captioners 96.4\n",
      "Proofreaders and Copy Markers 95.5\n",
      "Correspondence Clerks 95.2\n",
      "Model ZZZ Accountants and Auditors 100.0\n",
      "News Analysts, Reporters, and Journalists 100.0\n",
      "Legal Secretaries and Administrative Assistants 100.0\n",
      "Clinical Data Managers 100.0\n",
      "Climate Change Policy Analysts 100.0\n",
      "The model labeled 86 occupations as \"fully exposed.\"\n",
      "Highest variance Search Marketing Strategists 14.5\n",
      "Graphic Designers 13.4\n",
      "Investment Fund Managers 13.0\n",
      "Financial Managers 13.0\n",
      "Insurance Appraisers, Auto Damage 12.6\n",
      "Table 4: Occupations with the highest exposure according to each measurement. The ﬁnal row lists the\n",
      "occupations with the highest f2value, indicating that they had the most variability in exposure scores.\n",
      "Exposure percentages indicate the share of an occupation’s task that are exposed to GPTs ( UUU) or GPT-powered\n",
      "software ( VVVandZZZ), where exposure is deﬁned as driving a reduction in time it takes to complete the task by at\n",
      "least 50% (see exposure rubric A.1). As such, occupations listed in this table are those where we estimate\n",
      "that GPTs and GPT-powered software are able to save workers a signiﬁcant amount of time completing a\n",
      "large share of their tasks, but it does not necessarily suggest that their tasks can be fully automated by these\n",
      "technologies. All tasks are assigned equal weight within an occupation.WORKING PAPER\n",
      "Basic Skill UUU\n",
      "(std err)VVV\n",
      "(std err)ZZZ\n",
      "(std err)\n",
      "All skill importance scores are normalized to be between 0 and 1.\n",
      "Constant 0.082*** -0.112*** 0.300***\n",
      "(0.011) (0.011) (0.057)\n",
      "Active Listening 0.128** 0.214*** 0.449***\n",
      "(0.047) (0.043) (0.027)\n",
      "Mathematics -0.127*** 0.161*** 0.787***\n",
      "(0.026) (0.021) (0.049)\n",
      "Reading Comprehension 0.153*** 0.470*** -0.346***\n",
      "(0.041) (0.037) (0.017)\n",
      "Science -0.114*** -0.230*** -0.346***\n",
      "(0.014) (0.012) (0.017)\n",
      "Speaking -0.028 0.133*** 0.294***\n",
      "(0.039) (0.033) (0.042)\n",
      "Writing 0.368*** 0.467*** 0.566***\n",
      "(0.042) (0.037) (0.047)\n",
      "Active Learning -0.157*** -0.0\n",
      "\n",
      "Score: 0.8072871788204853\n",
      "\n",
      "---\n",
      "\n",
      " LLMs, it is important to note that these models can\n",
      "also be utilized for various tasks beyond text generation. For example, embeddings from LLMs can be used\n",
      "for custom search applications, and LLMs can perform tasks such as summarization and classiﬁcation where\n",
      "the context may be largely contained in the prompt.\n",
      "To complement predictions of technology’s impacts on work and provide a framework for understanding\n",
      "the evolving landscape of language models and their associated technologies, we propose a new rubric\n",
      "for assessing LLM capabilities and their potential e ﬀects on jobs. This rubric (A.1) measures the overall\n",
      "exposure of tasks to LLMs, following the spirit of prior work on quantifying exposure to machine learning\n",
      "(Brynjolfsson et al., 2018; Felten et al., 2018; Webb, 2020). We deﬁne exposure as a proxy for potential\n",
      "economic impact without distinguishing between labor-augmenting or labor-displacing e ﬀects. We employ\n",
      "human annotators and GPT-4 itself as a classiﬁer to apply this rubric to occupational data in the U.S. economy,\n",
      "primarily sourced from the O*NET database. 12\n",
      "To construct our primary exposure dataset, we collected both human annotations and GPT-4 classiﬁcations,\n",
      "using a prompt tuned for agreement with a sample of labels from the authors. We observe similar agreement\n",
      "1This is distinct from recent social science research that makes use of LLMs to simulate human behavior (Horton, 2023; Sorensen\n",
      "et al., 2022)\n",
      "2While our exposure rubric does not necessarily tie the concept of language models to any particular model, we were strongly\n",
      "motivated by our observed capabilities of GPT-4 and the suite of capabilities we saw in development with OpenAI’s launch partners\n",
      "(OpenAI, 2023b).WORKING PAPER\n",
      "levels in GPT-4 responses and between human and machine evaluations, when aggregated to the task level.\n",
      "This exposure measure reﬂects an estimate of the technical capacity to make human labor more e ﬃcient;\n",
      "however, social, economic, regulatory, and other determinants imply that technical feasibility does not\n",
      "guarantee labor productivity or automation outcomes. Our analysis indicates that approximately 19% of jobs\n",
      "have at least 50% of their tasks exposed when considering both current model capabilities and anticipated\n",
      "tools built upon them. Human assessments suggest that only 3% of U.S. workers have over half of their tasks\n",
      "exposed to LLMs when considering existing language and code capabilities without additional software or\n",
      "modalities. Accounting for other generative models and complementary technologies, our human estimates\n",
      "indicate that up to 49% of workers could have half or more of their tasks exposed to LLMs.\n",
      "Our ﬁndings consistently show across both human and GPT-4 annotations that most occupations exhibit\n",
      "some degree of exposure to LLMs, with varying exposure levels across di ﬀerent types of work. Occupations\n",
      "with higher wages generally present with higher exposure, a result contrary to similar evaluations of overall\n",
      "exposure to machine learning (Brynjolfsson et al., 2023). When regressing exposure measures on skillsets\n",
      "using O*NET’s skill rubric, we discover that roles heavily reliant on science and critical thinking skills show\n",
      "a negative correlation with exposure, while programming and writing skills are positively associated with\n",
      "LLM exposure. Following Autor et al. (2022a), we examine barriers to entry by \"Job Zones\" and ﬁnd that\n",
      "occupational exposure to LLMs weakly increases with the di ﬃculty of job preparation. In other words,\n",
      "workers facing higher (lower) barriers to entry in their jobs tend to experience more (less) exposure to LLMs.\n",
      "We further compare our measurements to previous e ﬀorts documenting the distribution of automation\n",
      "exposure in the economy and ﬁnd broadly consistent results. Most other technology exposure measures we\n",
      "examine are statistically signiﬁcantly correlated with our preferred exposure measure, while measures of\n",
      "manual routineness and robotics exposure show negative correlations. The variance explained by these earlier\n",
      "eﬀorts (Acemoglu and Autor, 2011a; Frey and Osborne, 2017; Brynjolfsson et al., 2018; Felten et al., 2018;\n",
      "Webb, 2020; Brynjolfsson et al., 2023), along with wage controls, ranges from 60 to 72%, indicating that 28\n",
      "to 40% of the variation in our AI exposure measure remains unaccounted for by previous technology exposure\n",
      "measurements.\n",
      "We analyze exposure by industry and discover that information processing industries (4-digit NAICS)\n",
      "exhibit high exposure, while manufacturing,\n",
      "\n",
      "Score: 0.7960785670391277\n",
      "\n",
      "---\n",
      "\n",
      " unforeseen challenges\n",
      "limiting language model applications.\n",
      "•Sources of disagreement. While we did not rigorously examine sources of disagreement, we found a\n",
      "few places where humans and the model tended to get \"stuck\" in their assessments:\n",
      "–Tasks or activities where while an LLM could theoretically help or accomplish the task, adopting\n",
      "it to do so would require multiple people to change their habits or expectations (e.g. meetings,\n",
      "negotiations),\n",
      "–Tasks or activities where there is currently some regulation or norm that requires or suggests\n",
      "human oversight, judgment or empathy (e.g. making decisions, counseling), and\n",
      "–Tasks or activities where there already exists a technology that can reasonably automate the task\n",
      "(e.g. making reservations).\n",
      "4 Results\n",
      "General-purpose technologies are relatively rare and characterized by their pervasiveness, improvement over\n",
      "time, and the development of signiﬁcant co-invention and spillovers (Lipsey et al., 2005). Our assessment ofWORKING PAPER\n",
      "LLMs’ potential impact on the labor market is limited since it does not consider total factor productivity or\n",
      "capital input potential. In addition to their inﬂuence on labor, LLMs may also inﬂuence these dimensions.\n",
      "At this stage, some general-purpose technology criteria are easier to evaluate than others. Our primary\n",
      "focus at this early stage is to test the hypothesis that LLMs have a pervasive inﬂuence on the economy,\n",
      "similar to the approach taken by (Goldfarb et al., 2023), who analyzed machine learning di ﬀusion through\n",
      "job postings to assess its status as a general-purpose technology. Instead of using job postings or studying\n",
      "machine learning in general, we employ the task evaluation approach with both human and GPT-4 annotations.\n",
      "This analysis may reveal whether the impacts are limited to a speciﬁc set of similar tasks or occupations or if\n",
      "they will be more widespread.\n",
      "Our ﬁndings suggest that, based on their task-level capabilities, LLMs have the potential to signiﬁcantly\n",
      "aﬀect a diverse range of occupations within the U.S. economy, demonstrating a key attribute of general-purpose\n",
      "technologies. In the following sections, we discuss results across various roles and wage structures. Additional\n",
      "results on the relative exposure of industries within the U.S. economy can be found in Appendix C.\n",
      "4.1 Summary Statistics\n",
      "Summary statistics for these measures can be found in Table 3. Both human and GPT-4 annotations indicate\n",
      "that average occupation-level Uvalues fall between 0.14 and 0.15, suggesting that, on average, approximately\n",
      "15% of tasks within an occupation are directly exposed to LLMs. 6This ﬁgure increases to over 30% for V\n",
      "and surpasses 50% for Z. Coincidentally, human and GPT-4 annotations also tag between 15% and 14% of\n",
      "total tasks in the dataset as being exposed to LLMs. Based on the Vvalues, we estimate that 80% of workers\n",
      "belong to an occupation with at least 10% of its tasks exposed to LLMs, while 19% of workers are in an\n",
      "occupation where over half of its tasks are labeled as exposed.\n",
      "We ran one set of analyses using O*NET’s \"Importance\" scores but did not ﬁnd signiﬁcant changes to our\n",
      "ﬁndings. Though we do acknowledge that not weighting relative importance of a task to a given occupation\n",
      "yields some curious results (e.g. ranking Barbers as having reasonably high exposure).\n",
      "Although the potential for tasks to be a ﬀected is vast, LLMs and LLM-powered software must be\n",
      "incorporated into broader systems to fully realize this potential. As is common with general-purpose\n",
      "technologies, co-invention barriers may initially impede the rapid di ﬀusion of GPTs into economic applications.\n",
      "Furthermore, predicting the need for human oversight is challenging, especially for tasks where model\n",
      "capabilities equal or surpass human levels. While the requirement for human supervision may initially slow\n",
      "down the speed at which these systems di ﬀuse through the economy, users of LLMs and LLM-powered\n",
      "systems are likely to become increasingly acquainted with the technology over time, particularly in terms of\n",
      "understanding when and how to trust its outputs.\n",
      "4.2 Wages and Employment\n",
      "In Figure 3, we present exposure intensity across the economy. Each point on the plot displays occupational\n",
      "exposure, where the point’s x-axis value represents the share of an occupation’s tasks that are exposed (at\n",
      "each level U,V, and Z) and the point’s y-axis value represents the share of all\n",
      "\n",
      "Score: 0.7911093910150122\n",
      "\n",
      "---\n",
      "\n",
      " and GPT-4 (OpenAI, 2023b), excel in diverse applications like\n",
      "translation, classiﬁcation, creative writing, and code generation—capabilities that previously demanded\n",
      "specialized, task-speciﬁc models developed by expert engineers using domain-speciﬁc data.\n",
      "Concurrently, researchers have improved the steerability, reliability, and utility of these models using\n",
      "methods like ﬁne-tuning and reinforcement learning with human feedback (Ouyang et al., 2022; Bai et al.,\n",
      "2022). These advancements enhance the models’ ability to discern user intent, rendering them more\n",
      "user-friendly and practical. Moreover, recent studies reveal the potential of LLMs to program and control\n",
      "other digital tools, such as APIs, search engines, and even other generative AI systems (Schick et al., 2023;\n",
      "Mialon et al., 2023; Chase, 2022). This enables seamless integration of individual components for better\n",
      "utility, performance, and generalization. At their limit, these trends suggest a world where LLMs may be\n",
      "capable of executing any task typically performed at a computer.\n",
      "Generative AI models have mostly been deployed as modular specialists, performing speciﬁc tasks such as\n",
      "generating images from captions or transcribing text from speech. However, we argue that it is essential to view\n",
      "LLMs as versatile building blocks for creating additional tools. Developing these tools and integrating them\n",
      "into systems will require time and possibly signiﬁcant reconﬁguration of existing processes across various\n",
      "industries. Nevertheless, we are already witnessing emerging adoption trends. Despite their limitations,\n",
      "LLMs are increasingly being integrated into specialized applications in ﬁelds like writing assistance, coding,\n",
      "and legal research. These specialized applications then allow businesses and individuals to adopt LLMs into\n",
      "their workﬂows.\n",
      "We emphasize the signiﬁcance of these complementary technologies, partly because out-of-the-box\n",
      "general-purpose LLMs may continue to be unreliable for various tasks due to issues such as factual inaccuracies,\n",
      "inherent biases, privacy concerns, and disinformation risks (Abid et al., 2021; Schramowski et al., 2022;\n",
      "Goldstein et al., 2023; OpenAI, 2023a). However, specialized workﬂows—including tooling, software, or\n",
      "human-in-the-loop systems—can help address these shortcomings by incorporating domain-speciﬁc expertise.\n",
      "For example, Casetext o ﬀers LLM-based legal research tools that provide lawyers with quicker and more\n",
      "accurate legal research results, utilizing embeddings and summarization to counter the risk that GPT-4 couldaccurate legal research results, utilizing embeddings and summarization to counter the risk that GPT-4 could\n",
      "provide inaccurate details about a legal case or set of documents. GitHub Copilot is a coding assistant that\n",
      "employs LLMs to generate code snippets and auto-complete code, which users can then accept or reject based\n",
      "on their expertise. In other words, while it’s true that on its own GPT-4 does not \"know what time it is,\" it’s\n",
      "easy enough to give it a watch.WORKING PAPER\n",
      "Furthermore, a positive feedback loop may emerge as LLMs surpass a speciﬁc performance threshold,\n",
      "allowing them to assist in building the very tooling that enhances their usefulness and usability across various\n",
      "contexts. This could lower the cost and engineering expertise required to create such tools, potentially\n",
      "accelerating LLM adoption and integration even further (Chen et al., 2021; Peng et al., 2023). LLMs can also\n",
      "become valuable assets in machine learning model development—serving as coding assistants for researchers,\n",
      "data labeling services, or synthetic data generators. There is potential for such models to contribute to\n",
      "economic decision-making at the task level, for instance, by reﬁning methods for task and sub-task allocation\n",
      "between humans and machines (Singla et al., 2015; Shahaf and Horvitz, 2010). As LLMs advance over time\n",
      "and better align with user preferences, we can anticipate continuous improvement in performance. However, it\n",
      "is essential to recognize that these trends also bring a variety of serious risks. (Khlaaf et al., 2022; Weidinger\n",
      "et al., 2022; Solaiman et al., 2019)\n",
      "2.2 The Economic Impacts of Automation Technologies\n",
      "A large and growing body of literature addresses the labor market impacts of AI and automation technologies.\n",
      "The concept of skill-biased technological change and the task model of automation—often considered\n",
      "the standard framework for understanding technology’s inﬂuence on labor—originated from research\n",
      "\n",
      "\n",
      "Score: 0.7894104551103581\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.vectorstores import Qdrant\n",
    "embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "qdrant = Qdrant.from_documents(\n",
    "    job_doc,\n",
    "    embedding,\n",
    "    location=\":memory:\",  # Local mode with in-memory storage only\n",
    "    collection_name=\"my_documents\",\n",
    ")\n",
    "\n",
    "query = \"what are the important skills that are not likely to be replaced by LLMs?\"\n",
    "found_docs = qdrant.similarity_search_with_score(query)\n",
    "\n",
    "for document, score in found_docs:\n",
    "    print(document.page_content)\n",
    "    print(f\"\\nScore: {score}\")\n",
    "    print(\"\\n---\\n\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the study, roles heavily reliant on science and critical thinking skills show a negative correlation with exposure to LLMs, which means they are less likely to be impacted. On the other hand, programming and writing skills are positively associated with LLM exposure, so they are more likely to be impacted. However, it is important to note that this study only measures exposure to LLMs and does not necessarily predict labor-augmenting or labor-displacing effects. Additionally, social, economic, regulatory, and other determinants also play a role in determining the impact on labor productivity or automation outcomes.'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm, retriever=qdrant.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})\n",
    ")\n",
    "# Pass question to the qa_chain\n",
    "question = \"what are the skills that are not likely to be impacted by LLMs?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
